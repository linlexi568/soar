"""Ranking-based Value Network for Program Synthesis

åŸºäºè®ºæ–‡ï¼š"Ranking Policy Gradient" (Kwon et al., 2019)
æ ¸å¿ƒæ€æƒ³ï¼šä½¿ç”¨ç¨‹åºçš„ç›¸å¯¹æ’åºè€Œéç»å¯¹å¥–åŠ±æ¥è®­ç»ƒä»·å€¼ç½‘ç»œ

è§£å†³çš„é—®é¢˜ï¼š
1. å¥–åŠ±æ’å®šï¼ˆ-59.48ï¼‰å¯¼è‡´æ— æ³•åŒºåˆ†ç¨‹åºä¼˜åŠ£
2. Policy lossä¸º0ï¼ˆæ‰€æœ‰ç¨‹åºè¢«è®¤ä¸ºåŒæ ·å¥½ï¼‰
3. MCTSæœç´¢é€€åŒ–ï¼ˆvisit_countså…¨0æˆ–å‡åŒ€ï¼‰

æ–¹æ³•ï¼š
- æ”¶é›†ç¨‹åºå¯¹ï¼š(prog_better, prog_worse)
- è®­ç»ƒç½‘ç»œé¢„æµ‹ï¼šP(prog_a > prog_b)
- ä½¿ç”¨å­¦ä¹ åˆ°çš„æ’åºåˆ†æ•°å¼•å¯¼MCTS
"""
from __future__ import annotations
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List, Tuple, Optional
import numpy as np
from collections import deque
import random


class RankingValueNet(nn.Module):
    """åŸºäºæ’åºçš„ä»·å€¼ç½‘ç»œï¼ˆæ•´åˆåŠ¨ä½œç‰¹å¾ï¼‰
    
    ä¸æ ‡å‡†valueç½‘ç»œçš„åŒºåˆ«ï¼š
    - è¾“å…¥ï¼šä¸¤ä¸ªç¨‹åºçš„GNNåµŒå…¥ + åŠ¨ä½œå¹…åº¦ç‰¹å¾
    - è¾“å‡ºï¼šprog_aæ¯”prog_bæ›´å¥½çš„æ¦‚ç‡
    - è®­ç»ƒï¼šä½¿ç”¨pairwise ranking loss
    
    åŠ¨ä½œç‰¹å¾æ•´åˆï¼š
    - æ˜¾å¼è¾“å…¥åŠ¨ä½œç»Ÿè®¡é‡ï¼ˆmean/std/maxçš„fzå’Œtxï¼‰
    - ç½‘ç»œè‡ªåŠ¨å­¦ä¹ "é›¶åŠ¨ä½œç¨‹åºæ’åä½"
    - é¿å…æ‰‹å·¥è®¾è®¡æƒ©ç½šé¡¹
    """
    
    def __init__(self, embed_dim: int = 128, action_feature_dim: int = 6):
        """
        Args:
            embed_dim: GNNåµŒå…¥ç»´åº¦
            action_feature_dim: åŠ¨ä½œç‰¹å¾ç»´åº¦ï¼ˆé»˜è®¤6ï¼šfz_mean/std/max, tx_mean/std/maxï¼‰
        """
        super().__init__()
        self.embed_dim = embed_dim
        self.action_feature_dim = action_feature_dim
        
        # æ¯”è¾ƒç½‘ç»œï¼šèåˆä¸¤ä¸ªç¨‹åºçš„ç‰¹å¾ï¼ˆåµŒå…¥+åŠ¨ä½œï¼‰
        # è¾“å…¥ï¼š[embed_a, action_a, embed_b, action_b]
        input_dim = (embed_dim + action_feature_dim) * 2
        self.compare_net = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)  # è¾“å‡ºlogitï¼ˆprog_aæ›´å¥½çš„log-oddsï¼‰
        )
        
        # å•ç‹¬çš„ä»·å€¼å¤´ï¼šç”¨äºMCTSï¼ˆåµŒå…¥+åŠ¨ä½œâ†’ç»å¯¹åˆ†æ•°ï¼‰
        self.value_head = nn.Sequential(
            nn.Linear(embed_dim + action_feature_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Tanh()  # è¾“å‡º[-1, 1]
        )
    
    def forward_compare(self, embed_a: torch.Tensor, embed_b: torch.Tensor,
                       action_feat_a: Optional[torch.Tensor] = None,
                       action_feat_b: Optional[torch.Tensor] = None) -> torch.Tensor:
        """æ¯”è¾ƒä¸¤ä¸ªç¨‹åºï¼ˆæ•´åˆåŠ¨ä½œç‰¹å¾ï¼‰
        
        Args:
            embed_a: ç¨‹åºAçš„GNNåµŒå…¥ [B, embed_dim]
            embed_b: ç¨‹åºBçš„GNNåµŒå…¥ [B, embed_dim]
            action_feat_a: ç¨‹åºAçš„åŠ¨ä½œç‰¹å¾ [B, action_feature_dim]ï¼Œå¯é€‰
                          (fz_mean, fz_std, fz_max, tx_mean, tx_std, tx_max)
            action_feat_b: ç¨‹åºBçš„åŠ¨ä½œç‰¹å¾ [B, action_feature_dim]ï¼Œå¯é€‰
        
        Returns:
            logits: ç¨‹åºAæ¯”Bæ›´å¥½çš„log-odds [B, 1]
        
        Note:
            ç½‘ç»œé€šè¿‡åŠ¨ä½œç‰¹å¾è‡ªåŠ¨å­¦ä¹ ï¼š
            - å¤§æ¨åŠ›ç¨‹åº > é›¶æ¨åŠ›ç¨‹åº
            - ç¨³å®šæ§åˆ¶(ä½std) > æŠ–åŠ¨æ§åˆ¶(é«˜std)
            - æ— éœ€æ‰‹å·¥è®¾è®¡é›¶åŠ¨ä½œæƒ©ç½š
            
            å¦‚æœaction_featæœªæä¾›ï¼Œä½¿ç”¨é›¶ç‰¹å¾ï¼ˆé€€åŒ–æ¨¡å¼ï¼‰
        """
        # å¤„ç†å¯é€‰åŠ¨ä½œç‰¹å¾
        if action_feat_a is None:
            action_feat_a = torch.zeros(embed_a.size(0), self.action_feature_dim, 
                                       device=embed_a.device, dtype=embed_a.dtype)
        if action_feat_b is None:
            action_feat_b = torch.zeros(embed_b.size(0), self.action_feature_dim,
                                       device=embed_b.device, dtype=embed_b.dtype)
        
        input_a = torch.cat([embed_a, action_feat_a], dim=-1)  # [B, embed_dim+6]
        input_b = torch.cat([embed_b, action_feat_b], dim=-1)  # [B, embed_dim+6]
        combined = torch.cat([input_a, input_b], dim=-1)      # [B, 2*(embed_dim+6)]
        return self.compare_net(combined)
    
    def forward_value(self, embed: torch.Tensor, action_feat: Optional[torch.Tensor] = None) -> torch.Tensor:
        """å•ä¸ªç¨‹åºçš„ç»å¯¹ä»·å€¼ä¼°è®¡ï¼ˆç”¨äºMCTSï¼Œæ•´åˆåŠ¨ä½œç‰¹å¾ï¼‰
        
        Args:
            embed: ç¨‹åºçš„GNNåµŒå…¥ [B, embed_dim]
            action_feat: åŠ¨ä½œç‰¹å¾ [B, action_feature_dim]ï¼Œå¯é€‰
        
        Returns:
            value: ä»·å€¼ä¼°è®¡ [B, 1]ï¼ŒèŒƒå›´[-1, 1]
        """
        if action_feat is None:
            action_feat = torch.zeros(embed.size(0), self.action_feature_dim,
                                     device=embed.device, dtype=embed.dtype)
        combined = torch.cat([embed, action_feat], dim=-1)
        return self.value_head(combined)
    
    def forward(self, embed: torch.Tensor, action_feat: Optional[torch.Tensor] = None) -> torch.Tensor:
        """é»˜è®¤forwardï¼šè¿”å›ç»å¯¹ä»·å€¼ï¼ˆå…¼å®¹ç°æœ‰ä»£ç ï¼‰"""
        return self.forward_value(embed, action_feat)


class PairwiseRankingBuffer:
    """å­˜å‚¨ç¨‹åºå¯¹çš„replay bufferï¼ˆæ•´åˆåŠ¨ä½œç‰¹å¾ï¼‰
    
    ç»“æ„ï¼š(prog_a, prog_b, preference, action_feat_a, action_feat_b)
    - prog_a, prog_b: ç¨‹åºçš„graphæ•°æ®
    - preference: 1 if reward_a > reward_b, else 0
    - action_feat_a/b: åŠ¨ä½œå¹…åº¦ç‰¹å¾ [fz_mean, fz_std, fz_max, tx_mean, tx_std, tx_max]
    """
    
    def __init__(self, capacity: int = 10000):
        self.buffer = deque(maxlen=capacity)
        self.capacity = capacity
    
    def push(self, prog_a_graph, prog_b_graph, preference: float,
             action_feat_a: List[float], action_feat_b: List[float]):
        """æ·»åŠ ä¸€å¯¹ç¨‹åºï¼ˆåŒ…å«åŠ¨ä½œç‰¹å¾ï¼‰
        
        Args:
            prog_a_graph: PyG Dataå¯¹è±¡
            prog_b_graph: PyG Dataå¯¹è±¡
            preference: 1.0 if a>b, 0.5 if a=b, 0.0 if a<b
            action_feat_a: ç¨‹åºAçš„åŠ¨ä½œç‰¹å¾ [6]
            action_feat_b: ç¨‹åºBçš„åŠ¨ä½œç‰¹å¾ [6]
        """
        self.buffer.append({
            'prog_a': prog_a_graph,
            'prog_b': prog_b_graph,
            'preference': preference,
            'action_feat_a': action_feat_a,
            'action_feat_b': action_feat_b
        })
    
    def sample(self, batch_size: int) -> List[dict]:
        """é‡‡æ ·ä¸€æ‰¹ç¨‹åºå¯¹"""
        return random.sample(self.buffer, min(batch_size, len(self.buffer)))
    
    def __len__(self):
        return len(self.buffer)


def compute_ranking_loss(
    ranking_net: RankingValueNet,
    batch: List[dict],
    gnn_encoder,
    device: torch.device
) -> Tuple[torch.Tensor, dict]:
    """è®¡ç®—ranking lossï¼ˆæ•´åˆåŠ¨ä½œç‰¹å¾ï¼‰
    
    Args:
        ranking_net: RankingValueNetå®ä¾‹
        batch: ä»PairwiseRankingBufferé‡‡æ ·çš„batch
               æ¯ä¸ªitemåŒ…å«: prog_a, prog_b, preference, action_feat_a, action_feat_b
        gnn_encoder: GNNç¼–ç å™¨ï¼ˆæå–ç¨‹åºåµŒå…¥ï¼‰
        device: torch device
    
    Returns:
        loss: ranking loss
        metrics: è®­ç»ƒæŒ‡æ ‡å­—å…¸
    """
    from torch_geometric.data import Batch as PyGBatch
    
    # æ„å»ºæ‰¹æ¬¡
    graphs_a = [item['prog_a'] for item in batch]
    graphs_b = [item['prog_b'] for item in batch]
    preferences = torch.tensor(
        [item['preference'] for item in batch],
        dtype=torch.float32,
        device=device
    ).unsqueeze(1)
    
    # æå–åŠ¨ä½œç‰¹å¾
    action_feats_a = torch.tensor(
        [item['action_feat_a'] for item in batch],
        dtype=torch.float32,
        device=device
    )  # [B, 6]
    action_feats_b = torch.tensor(
        [item['action_feat_b'] for item in batch],
        dtype=torch.float32,
        device=device
    )  # [B, 6]
    
    # ğŸ”§ éªŒè¯å¹¶ä¿®å¤å›¾ç»“æ„ï¼ˆç¡®ä¿è¾¹ç´¢å¼•æœ‰æ•ˆï¼‰
    def ensure_valid_graph(graph):
        """
        ç¡®ä¿å›¾çš„è¾¹ç´¢å¼•æœ‰æ•ˆï¼Œé¿å…GATv2Convæ–­è¨€å¤±è´¥
        
        å¸¸è§é—®é¢˜ï¼š
        1. æ²¡æœ‰è¾¹ -> æ·»åŠ è‡ªç¯
        2. è¾¹ç´¢å¼•è¶…å‡ºèŠ‚ç‚¹èŒƒå›´ -> æ·»åŠ è‡ªç¯
        3. å­¤ç«‹èŠ‚ç‚¹ -> é€šè¿‡ add_self_loops ç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹è‡³å°‘æœ‰ä¸€æ¡è¾¹
        """
        from torch_geometric.utils import add_self_loops, remove_self_loops
        
        num_nodes = graph.x.size(0)
        edge_index = graph.edge_index
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹
        if edge_index is None or edge_index.numel() == 0 or edge_index.size(1) == 0:
            # æ²¡æœ‰è¾¹ï¼šæ·»åŠ è‡ªç¯
            graph.edge_index = torch.stack([
                torch.arange(num_nodes, dtype=torch.long, device=graph.x.device),
                torch.arange(num_nodes, dtype=torch.long, device=graph.x.device)
            ], dim=0)
            return graph
        
        # ç¡®ä¿edge_indexåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        if edge_index.device != graph.x.device:
            edge_index = edge_index.to(graph.x.device)
            graph.edge_index = edge_index
        
        # æ£€æŸ¥è¾¹ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
        try:
            min_idx = edge_index.min().item()
            max_idx = edge_index.max().item()
            
            # è¾¹ç´¢å¼•è¶…å‡ºèŒƒå›´æˆ–åŒ…å«è´Ÿæ•°
            if min_idx < 0 or max_idx >= num_nodes:
                print(f"[Ranking] âš ï¸ è¾¹ç´¢å¼•è¶Šç•Œ: min={min_idx}, max={max_idx}, num_nodes={num_nodes}ï¼Œé‡å»ºä¸ºè‡ªç¯")
                graph.edge_index = torch.stack([
                    torch.arange(num_nodes, dtype=torch.long, device=graph.x.device),
                    torch.arange(num_nodes, dtype=torch.long, device=graph.x.device)
                ], dim=0)
                return graph
            
            # æ£€æŸ¥è¾¹ç´¢å¼•å½¢çŠ¶
            if edge_index.size(0) != 2:
                print(f"[Ranking] âš ï¸ è¾¹ç´¢å¼•å½¢çŠ¶é”™è¯¯: {edge_index.shape}ï¼Œé‡å»ºä¸ºè‡ªç¯")
                graph.edge_index = torch.stack([
                    torch.arange(num_nodes, dtype=torch.long, device=graph.x.device),
                    torch.arange(num_nodes, dtype=torch.long, device=graph.x.device)
                ], dim=0)
                return graph
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šä½¿ç”¨PyGçš„add_self_loopsç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹è‡³å°‘æœ‰ä¸€æ¡è¾¹
            # è¿™è§£å†³äº†å­¤ç«‹èŠ‚ç‚¹å¯¼è‡´ GATv2Conv alpha=None çš„é—®é¢˜
            edge_index, _ = remove_self_loops(edge_index)
            edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)
            graph.edge_index = edge_index
                
        except Exception as e:
            print(f"[Ranking] âš ï¸ è¾¹ç´¢å¼•éªŒè¯å¤±è´¥: {e}ï¼Œé‡å»ºä¸ºè‡ªç¯")
            graph.edge_index = torch.stack([
                torch.arange(num_nodes, dtype=torch.long, device=graph.x.device),
                torch.arange(num_nodes, dtype=torch.long, device=graph.x.device)
            ], dim=0)
        
        return graph
    
    graphs_a = [ensure_valid_graph(g) for g in graphs_a]
    graphs_b = [ensure_valid_graph(g) for g in graphs_b]
    
    from torch_geometric.utils import remove_self_loops, add_self_loops, coalesce

    def _build_batch(graph_list, target_device=None):
        target = target_device or device
        batch = PyGBatch.from_data_list(graph_list).to(target)
        if batch.edge_index is None:
            return batch
        num_nodes = int(batch.x.size(0))
        if num_nodes == 0:
            return batch
        edge_index, _ = remove_self_loops(batch.edge_index)
        edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)
        batch.edge_index = coalesce(edge_index, num_nodes=num_nodes)
        return batch

    def _initial_chunk_limit(total_graphs: int) -> int:
        env_val = os.getenv('RANKING_GNN_CHUNK')
        if env_val is not None:
            try:
                limit = max(1, int(env_val))
            except ValueError:
                limit = 4
        else:
            limit = 4 if device.type == 'cuda' else total_graphs
        return max(1, min(total_graphs, limit))

    def _encode_on_cpu(graphs: List, tag: str) -> torch.Tensor:
        cpu_device = torch.device('cpu')
        prev_device = next(gnn_encoder.parameters()).device
        was_training = gnn_encoder.training
        print(f"[Ranking] âš ï¸ è§¦å‘CPU fallback({tag})ï¼šgraphs={len(graphs)}, nodesâ‰ˆ{sum(g.x.size(0) for g in graphs)}")
        gnn_encoder.eval()
        gnn_encoder.to(cpu_device)
        embeddings = []
        try:
            for start in range(0, len(graphs)):
                chunk = graphs[start:start + 1]
                batch = _build_batch(chunk, cpu_device)
                with torch.no_grad():
                    embed = gnn_encoder.get_embedding(batch)
                embeddings.append(embed.detach().float())
        finally:
            gnn_encoder.to(prev_device)
            gnn_encoder.train(was_training)
        concatenated = torch.cat(embeddings, dim=0)
        return concatenated.to(device)

    def _encode_graphs(graphs: List, tag: str) -> torch.Tensor:
        if not graphs:
            raise ValueError("encode_graphs received empty list")
        chunk_size = _initial_chunk_limit(len(graphs))
        was_training = gnn_encoder.training
        gnn_encoder.eval()
        try:
            while True:
                embeddings = []
                try:
                    for start in range(0, len(graphs), chunk_size):
                        chunk = graphs[start:start + chunk_size]
                        batch = _build_batch(chunk)
                        with torch.no_grad():
                            if device.type == 'cuda':
                                with torch.cuda.amp.autocast(dtype=torch.float16):
                                    embed = gnn_encoder.get_embedding(batch)
                            else:
                                embed = gnn_encoder.get_embedding(batch)
                        embeddings.append(embed.detach().float())
                    return torch.cat(embeddings, dim=0)
                except torch.cuda.OutOfMemoryError as oom:
                    if device.type != 'cuda':
                        raise
                    prev_chunk = chunk_size
                    chunk_size = max(1, chunk_size // 2)
                    print(f"[Ranking] âš ï¸ CUDA OOM({tag})ï¼šchunk {prev_chunk}â†’{chunk_size}. nodesâ‰ˆ{sum(g.x.size(0) for g in graphs)}")
                    torch.cuda.empty_cache()
                    if prev_chunk == 1:
                        return _encode_on_cpu(graphs, tag)
                except Exception as e:
                    print(f"[Ranking] âš ï¸ GNNç¼–ç å¤±è´¥({tag}): {e}")
                    print(f"  graphsæ ·æœ¬: nodes={[g.x.size(0) for g in graphs[:3]]}, edges={[g.edge_index.size(1) for g in graphs[:3]]}")
                    raise
                # chunk_size==1ä¸”æˆåŠŸä¼šåœ¨forå¾ªç¯ returnï¼›è‹¥é™åˆ°1åOOMï¼Œå°†åœ¨ä¸Šé¢raise
        finally:
            gnn_encoder.train(was_training)

    embed_a = _encode_graphs(graphs_a, 'A')
    embed_b = _encode_graphs(graphs_b, 'B')
    
    # æ¯”è¾ƒï¼ˆä¼ å…¥åŠ¨ä½œç‰¹å¾ï¼‰
    logits = ranking_net.forward_compare(embed_a, embed_b, action_feats_a, action_feats_b)
    probs = torch.sigmoid(logits)
    
    # Pairwise ranking loss (binary cross entropy)
    loss = F.binary_cross_entropy_with_logits(logits, preferences)
    
    # è®¡ç®—å‡†ç¡®ç‡ï¼ˆé¢„æµ‹æ˜¯å¦ä¸çœŸå®åå¥½ä¸€è‡´ï¼‰
    predictions = (probs > 0.5).float()
    accuracy = (predictions == preferences).float().mean()
    
    # åˆ†æåŠ¨ä½œç‰¹å¾çš„å½±å“
    fz_mean_diff = (action_feats_a[:, 0] - action_feats_b[:, 0]).abs().mean().item()
    
    metrics = {
        'ranking_loss': loss.item(),
        'ranking_accuracy': accuracy.item(),
        'mean_prob': probs.mean().item(),
        'action_fz_diff': fz_mean_diff  # è¯Šæ–­ï¼šåŠ¨ä½œå·®å¼‚å¤§å°
    }
    
    return loss, metrics


def generate_program_pairs(
    program_buffer: List[dict],
    reward_threshold: float = 0.1
) -> List[Tuple]:
    """ä»ç¨‹åºbufferç”Ÿæˆè®­ç»ƒå¯¹
    
    Args:
        program_buffer: åŒ…å«{'graph', 'reward', ...}çš„ç¨‹åºåˆ—è¡¨
        reward_threshold: æœ€å°å¥–åŠ±å·®è·ï¼ˆå°äºæ­¤å€¼è®¤ä¸ºç›¸ç­‰ï¼‰
    
    Returns:
        pairs: [(prog_a, prog_b, preference), ...]
    """
    pairs = []
    
    # éšæœºé‡‡æ ·pairs
    n = len(program_buffer)
    for _ in range(min(n * 2, 1000)):  # ç”Ÿæˆæœ€å¤š1000å¯¹
        i, j = random.sample(range(n), 2)
        prog_i = program_buffer[i]
        prog_j = program_buffer[j]
        
        reward_i = prog_i.get('reward', 0.0)
        reward_j = prog_j.get('reward', 0.0)
        
        # è®¡ç®—åå¥½
        if abs(reward_i - reward_j) < reward_threshold:
            preference = 0.5  # ç›¸ç­‰
        elif reward_i > reward_j:
            preference = 1.0  # iæ›´å¥½
            pairs.append((prog_i['graph'], prog_j['graph'], preference))
        else:
            preference = 1.0  # jæ›´å¥½
            pairs.append((prog_j['graph'], prog_i['graph'], preference))
    
    return pairs


def integrate_ranking_value_to_mcts(
    ranking_net: RankingValueNet,
    standard_value: float,
    program_embed: torch.Tensor,
    blend_factor: float = 0.5
) -> float:
    """å°†ranking-based valueèåˆåˆ°MCTSä¸­
    
    Args:
        ranking_net: æ’åºç½‘ç»œ
        standard_value: æ ‡å‡†valueç½‘ç»œçš„ä¼°è®¡
        program_embed: å½“å‰ç¨‹åºçš„GNNåµŒå…¥
        blend_factor: èåˆç³»æ•°ï¼ˆ0=ä»…ç”¨æ ‡å‡†valueï¼Œ1=ä»…ç”¨ranking valueï¼‰
    
    Returns:
        blended_value: èåˆåçš„ä»·å€¼ä¼°è®¡
    """
    with torch.no_grad():
        ranking_value = ranking_net.forward_value(program_embed).item()
    
    # èåˆä¸¤ä¸ªä¼°è®¡
    blended = (1 - blend_factor) * standard_value + blend_factor * ranking_value
    return blended


# ============================================================================
# é›†æˆåˆ°ç°æœ‰è®­ç»ƒå¾ªç¯çš„è¾…åŠ©å‡½æ•°
# ============================================================================

def setup_ranking_training(
    gnn_model,
    device: torch.device,
    learning_rate: float = 1e-4,
    embed_dim: int = 256  # GNN hidden size (é»˜è®¤256)
):
    """åˆå§‹åŒ–rankingè®­ç»ƒç»„ä»¶
    
    Args:
        gnn_model: GNNæ¨¡å‹ï¼ˆç”¨äºè·å–åµŒå…¥ç»´åº¦ï¼Œå¯é€‰ï¼‰
        device: torchè®¾å¤‡
        learning_rate: å­¦ä¹ ç‡
        embed_dim: åµŒå…¥ç»´åº¦ï¼ˆé»˜è®¤256ï¼ŒåŒ¹é…GNN v2çš„hidden sizeï¼‰
    
    Returns:
        ranking_net: RankingValueNetå®ä¾‹
        ranking_buffer: PairwiseRankingBufferå®ä¾‹
        ranking_optimizer: torchä¼˜åŒ–å™¨
    """
    ranking_net = RankingValueNet(embed_dim=embed_dim).to(device)
    ranking_buffer = PairwiseRankingBuffer(capacity=10000)
    ranking_optimizer = torch.optim.Adam(ranking_net.parameters(), lr=learning_rate)
    
    return ranking_net, ranking_buffer, ranking_optimizer


def train_ranking_step(
    ranking_net: RankingValueNet,
    ranking_buffer: PairwiseRankingBuffer,
    ranking_optimizer: torch.optim.Optimizer,
    gnn_encoder,
    device: torch.device,
    batch_size: int = 64
) -> Optional[dict]:
    """æ‰§è¡Œä¸€æ­¥rankingè®­ç»ƒ
    
    Returns:
        metrics: è®­ç»ƒæŒ‡æ ‡ï¼Œå¦‚æœbufferå¤ªå°åˆ™è¿”å›None
    """
    if len(ranking_buffer) < batch_size:
        return None
    
    batch = ranking_buffer.sample(batch_size)
    loss, metrics = compute_ranking_loss(ranking_net, batch, gnn_encoder, device)
    
    ranking_optimizer.zero_grad()
    loss.backward()
    torch.nn.utils.clip_grad_norm_(ranking_net.parameters(), 1.0)
    ranking_optimizer.step()
    
    return metrics


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹ï¼ˆé›†æˆåˆ°train_online.pyï¼‰
# ============================================================================

"""
åœ¨train_online.pyçš„Trainerç±»ä¸­æ·»åŠ ï¼š

class Trainer:
    def __init__(self, ...):
        # ç°æœ‰åˆå§‹åŒ–...
        
        # æ·»åŠ rankingè®­ç»ƒç»„ä»¶
        self.ranking_net, self.ranking_buffer, self.ranking_optimizer = \
            setup_ranking_training(self.nn_model, self.device)
        
        self.use_ranking_value = True  # æ˜¯å¦ä½¿ç”¨ranking value
        self.ranking_blend_factor = 0.3  # åˆæœŸä¿å®ˆèåˆ
    
    def train(self):
        for iter_idx in range(self.args.total_iters):
            # MCTSæœç´¢...
            children, visit_counts = self.mcts_search(...)
            
            # æ”¶é›†ç¨‹åºå¯¹åˆ°ranking buffer
            for i, child_i in enumerate(children):
                for j, child_j in enumerate(children[i+1:], i+1):
                    reward_i = child_i.reward  # å‡è®¾å­˜å‚¨äº†reward
                    reward_j = child_j.reward
                    
                    if abs(reward_i - reward_j) > 0.01:
                        graph_i = ast_to_pyg_graph(child_i.program)
                        graph_j = ast_to_pyg_graph(child_j.program)
                        pref = 1.0 if reward_i > reward_j else 0.0
                        self.ranking_buffer.push(graph_i, graph_j, pref)
            
            # è®­ç»ƒrankingç½‘ç»œï¼ˆæ¯æ¬¡è¿­ä»£ï¼‰
            if len(self.ranking_buffer) >= 64:
                metrics = train_ranking_step(
                    self.ranking_net,
                    self.ranking_buffer,
                    self.ranking_optimizer,
                    self.nn_model,
                    self.device
                )
                if metrics:
                    print(f"  Ranking: loss={metrics['ranking_loss']:.4f}, "
                          f"acc={metrics['ranking_accuracy']:.2%}")
            
            # é€æ­¥å¢åŠ rankingçš„å½±å“ï¼ˆè¯¾ç¨‹å­¦ä¹ ï¼‰
            if iter_idx % 50 == 0 and self.ranking_blend_factor < 0.8:
                self.ranking_blend_factor = min(0.8, self.ranking_blend_factor + 0.1)
"""


# ============================================================================
# åŠ¨ä½œç‰¹å¾æå–å·¥å…·
# ============================================================================

def extract_action_features_from_eval_result(eval_result: dict) -> List[float]:
    """ä»è¯„ä¼°ç»“æœä¸­æå–åŠ¨ä½œå¹…åº¦ç‰¹å¾
    
    Args:
        eval_result: BatchEvaluatorè¿”å›çš„è¯„ä¼°ç»“æœå­—å…¸
                    éœ€è¦åŒ…å«'action_stats'å­—æ®µ
    
    Returns:
        action_features: [fz_mean, fz_std, fz_max, tx_mean, tx_std, tx_max]
    
    Note:
        å¦‚æœeval_resultä¸­æ²¡æœ‰action_statsï¼Œè¿”å›å…¨é›¶ç‰¹å¾
    """
    if 'action_stats' not in eval_result:
        return [0.0] * 6  # å…¼å®¹æ—§ç‰ˆæœ¬
    
    stats = eval_result['action_stats']
    return [
        float(stats.get('fz_mean', 0.0)),
        float(stats.get('fz_std', 0.0)),
        float(stats.get('fz_max', 0.0)),
        float(stats.get('tx_mean', 0.0)),
        float(stats.get('tx_std', 0.0)),
        float(stats.get('tx_max', 0.0))
    ]


def compute_action_features_from_program(program, state_dict, num_samples=100):
    """ç›´æ¥ä»ç¨‹åºè®¡ç®—åŠ¨ä½œç‰¹å¾ï¼ˆç”¨äºç¼“å­˜missæ—¶ï¼‰
    
    Args:
        program: ç¨‹åºAST
        state_dict: ç¤ºä¾‹çŠ¶æ€å­—å…¸
        num_samples: é‡‡æ ·æ¬¡æ•°
    
    Returns:
        action_features: [fz_mean, fz_std, fz_max, tx_mean, tx_std, tx_max]
    """
    # è¿™æ˜¯ä¸€ä¸ªå ä½å®ç°ï¼Œå®é™…åº”è¯¥è°ƒç”¨evaluator
    # åœ¨train_online.pyé›†æˆæ—¶ï¼Œç›´æ¥ä½¿ç”¨evaluatorè¿”å›çš„action_stats
    return [0.0] * 6
