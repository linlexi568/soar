"""æ‰¹é‡ç¨‹åºè¯„ä¼°æ¨¡å— - Isaac Gym GPUå¹¶è¡ŒåŠ é€Ÿ

ä»…æ”¯æŒIsaac Gymæ‰¹é‡å¹¶è¡Œä»¿çœŸï¼ˆ512+ ç¯å¢ƒï¼‰
"""
from dataclasses import dataclass
from typing import List, Dict, Any, Tuple, Optional
import numpy as np
import hashlib
import time

# Isaac Gymæ£€æµ‹ï¼ˆå°è¯•ä»æœ¬ä»“åº“çš„ vendor ç›®å½•åŠ è½½ï¼‰
# âš ï¸ CRITICAL: Isaac Gymå¿…é¡»åœ¨torchå¯¼å…¥å‰åˆå§‹åŒ–
import sys, pathlib, os
ISAAC_GYM_AVAILABLE = False
try:
    # ä¼˜å…ˆç›´æ¥å¯¼å…¥
    from isaacgym import gymapi  # type: ignore
    ISAAC_GYM_AVAILABLE = True
except Exception:
    # å°è¯•å°† repo å†…ç½®è·¯å¾„åŠ å…¥ sys.path
    try:
        _HERE = pathlib.Path(__file__).resolve()
        _PKG_ROOT = _HERE.parent  # 01_soar
        _REPO_ROOT = _PKG_ROOT.parent  # repo root
        _GYM_PY = _REPO_ROOT / 'isaacgym' / 'python'
        if _GYM_PY.exists() and str(_GYM_PY) not in sys.path:
            sys.path.insert(0, str(_GYM_PY))
        from isaacgym import gymapi  # type: ignore
        ISAAC_GYM_AVAILABLE = True
        # é…ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡ä»¥å®šä½æ’ä»¶ä¿¡æ¯
        try:
            os.environ.setdefault('GYM_USD_PLUG_INFO_PATH', str(_GYM_PY / 'isaacgym' / '_bindings' / 'linux-x86_64' / 'usd' / 'plugInfo.json'))
        except Exception:
            pass
    except Exception:
        ISAAC_GYM_AVAILABLE = False

# âš ï¸ CRITICAL: torchå¿…é¡»åœ¨Isaac Gymä¹‹åå¯¼å…¥
import torch

# Stepwise å¥–åŠ±è®¡ç®—å™¨ä¸æƒé‡
try:
    from utils.reward_stepwise import StepwiseRewardCalculator  # type: ignore
except Exception:
    try:
        # æ·»åŠ è·¯å¾„ä»¥æ”¯æŒç›´æ¥è¿è¡Œ
        import sys, pathlib
        _parent = pathlib.Path(__file__).resolve().parent.parent
        if str(_parent) not in sys.path:
            sys.path.insert(0, str(_parent))
        from utils.reward_stepwise import StepwiseRewardCalculator  # type: ignore
    except Exception:
        StepwiseRewardCalculator = None  # type: ignore

# SCG ç²¾ç¡® reward è®¡ç®—å™¨
try:
    from utils.reward_scg_exact import SCGExactRewardCalculator  # type: ignore
except Exception:
    try:
        from reward_scg_exact import SCGExactRewardCalculator  # type: ignore
    except Exception:
        SCGExactRewardCalculator = None  # type: ignore
try:
    from utils.gpu_program_executor import GPUProgramExecutor  # type: ignore
except Exception:
    try:
        from gpu_program_executor import GPUProgramExecutor  # type: ignore
    except Exception:
        GPUProgramExecutor = None  # type: ignore
try:
    from utilities.reward_profiles import get_reward_profile  # type: ignore
except Exception:
    get_reward_profile = None  # type: ignore
try:
    from utilities.trajectory_presets import scg_position
except Exception:
    scg_position = None  # type: ignore
try:
    from utils.prior_scoring import compute_prior_scores  # type: ignore
except Exception:
    try:
        import sys, pathlib
        _parent = pathlib.Path(__file__).resolve().parent.parent
        if str(_parent) not in sys.path:
            sys.path.insert(0, str(_parent))
        from utils.prior_scoring import compute_prior_scores  # type: ignore
    except Exception:
        compute_prior_scores = None  # type: ignore

try:
    # ç”¨äºç»“æ„åŒ–åºåˆ—åŒ–ç¨‹åºï¼Œç”Ÿæˆç¨³å®šå“ˆå¸Œ
    from core.serialization import to_serializable_dict as _to_serializable_dict  # type: ignore
except Exception:
    _to_serializable_dict = None  # type: ignore

try:
    from core.serialization import serialize_program as _serialize_program  # type: ignore
except Exception:
    _serialize_program = None  # type: ignore

# é‡ç½® AST èŠ‚ç‚¹çŠ¶æ€ï¼ˆç¡®ä¿æ¯æ¬¡è¯„ä¼°çš„ç¡®å®šæ€§ï¼‰
try:
    from core.dsl import reset_program_state  # type: ignore
except Exception:
    try:
        from dsl import reset_program_state  # type: ignore
    except Exception:
        reset_program_state = None  # type: ignore


@dataclass
class ProgramParamCandidate:
    """è½»é‡çº§ BO å€™é€‰ï¼Œå»¶è¿Ÿæ³¨å…¥å‚æ•° & å»¶è¿Ÿæ„é€  DSL ASTã€‚"""

    base_program: List[Dict[str, Any]]
    param_paths: Tuple[str, ...]
    param_values: Tuple[float, ...]
    cache_key: Optional[str] = None
    allow_cache: bool = False
    _materialized: Optional[List[Dict[str, Any]]] = None

    def materialize(self) -> List[Dict[str, Any]]:
        if self._materialized is None:
            import copy
            try:
                from utils.bayesian_tuner import inject_tuned_params  # type: ignore
            except ImportError:
                from .bayesian_tuner import inject_tuned_params  # type: ignore
            prog_copy = copy.deepcopy(self.base_program)
            tuned_values = {path: self.param_values[idx] for idx, path in enumerate(self.param_paths)}
            inject_tuned_params(prog_copy, tuned_values)
            self._materialized = prog_copy
        return self._materialized


def _normalize_program_structure_for_cache(obj: Any):
    """é€’å½’å»é™¤ç¨‹åºå†…çš„å¸¸æ•°å€¼ï¼Œä»…ä¿ç•™ç»“æ„ä¿¡æ¯ç”¨äºç¼“å­˜é”®ã€‚

    - æ‰€æœ‰ dict ä¸­ key ä¸º 'value' çš„æ•°å€¼ä¼šè¢«å ä½ç¬¦æ›¿æ¢ï¼›
    - å…¶ä»–ä»»æ„ int/float ä¹Ÿç»Ÿä¸€æ›¿æ¢ï¼Œç¡®ä¿ç»“æ„ç›¸åŒå³å‘½ä¸­ç¼“å­˜ï¼›
    - å…¶ä½™ç±»å‹ä¿æŒä¸å˜ã€‚
    """
    if isinstance(obj, dict):
        normalized = {}
        for k, v in obj.items():
            if k == 'value' and isinstance(v, (int, float)):
                normalized[k] = '<CONST>'
            else:
                normalized[k] = _normalize_program_structure_for_cache(v)
        return normalized
    if isinstance(obj, list):
        return [_normalize_program_structure_for_cache(item) for item in obj]
    if isinstance(obj, (int, float)):
        return '<CONST>'
    return obj


try:
    from utils.program_constraints import validate_program, HARD_CONSTRAINT_PENALTY
except Exception:
    try:
        from program_constraints import validate_program, HARD_CONSTRAINT_PENALTY  # type: ignore
    except Exception:
        def validate_program(_program):  # type: ignore
            return True, ""
        HARD_CONSTRAINT_PENALTY = -1e6  # type: ignore

class BatchEvaluator:
    """æ‰¹é‡ç¨‹åºè¯„ä¼°å™¨ï¼ˆä»…æ”¯æŒIsaac Gymï¼‰"""

    def __init__(self, 
                 trajectory_config: Dict[str, Any],
                 duration: int = 20,
                 isaac_num_envs: int = 96,
                 device: str = 'cuda:0',
                 replicas_per_program: int = 5,
                 min_steps_frac: float = 0.0,
                 reward_reduction: str = 'mean',
                 reward_profile: str = 'control_law_discovery',
                 strict_no_prior: bool = True,
                 zero_action_penalty: float = 5.0,
                 use_fast_path: bool = True,
                 use_gpu_expression_executor: bool = True,
                 complexity_bonus: float = 0.1,
                 action_scale_multiplier: float = 1.0,
                 structure_prior_weight: float = 0.0,
                 stability_prior_weight: float = 0.0,
                 enable_output_mad: bool = True,
                 mad_min_fz: float = 0.0,
                 mad_max_fz: float = 7.5,
                 mad_max_xy: float = 1.0,           # æ‰©å¤§èŒƒå›´ä»¥å…è®¸æœ‰æ•ˆæ§åˆ¶å¢ç›Š
                 mad_max_yaw: float = 0.5,          # æ‰©å¤§èŒƒå›´
                 mad_max_delta_fz: float = 1.5,
                 mad_max_delta_xy: float = 0.5,     # æ‰©å¤§å˜åŒ–ç‡é™åˆ¶
                 mad_max_delta_yaw: float = 0.2,    # æ‰©å¤§å˜åŒ–ç‡é™åˆ¶
                 enable_bayesian_tuning: bool = False,
                 bo_batch_size: int = 50,
                 bo_iterations: int = 3,
                 bo_param_ranges: Optional[Dict[str, Tuple[float, float]]] = None,
                 gpu_control_loop: Optional[bool] = None,
                 use_scg_exact_reward: bool = False):
        """
        Args:
            trajectory_config: è½¨è¿¹é…ç½® {'type': 'figure8', 'params': {...}}
            duration: ä»¿çœŸæ—¶é•¿ï¼ˆç§’ï¼‰
            isaac_num_envs: Isaac Gymå¹¶è¡Œç¯å¢ƒæ•° (ä¼˜åŒ–åé»˜è®¤96)
            device: GPUè®¾å¤‡
            replicas_per_program: æ¯ä¸ªç¨‹åºè¯„ä¼°Næ¬¡å–å¹³å‡ï¼Œå‡å°‘æ–¹å·® (ä¼˜åŒ–åé»˜è®¤5)
            min_steps_frac: æ¯æ¬¡è¯„ä¼°è‡³å°‘æ‰§è¡Œçš„æ­¥æ•°æ¯”ä¾‹ï¼ˆ0-1ï¼‰ï¼Œé¿å…è¿‡æ—© done æå‰é€€å‡º
            reward_reduction: å¥–åŠ±å½’çº¦æ–¹å¼ï¼š'sum'ï¼ˆæ­¥æ¬¡æ±‚å’Œï¼‰æˆ– 'mean'ï¼ˆæ­¥æ¬¡å¹³å‡ï¼ŒæŠµæ¶ˆå­˜æ´»æ—¶é•¿åå·®ï¼‰
            reward_profile: å¥–åŠ±é…ç½®æ–‡ä»¶åç§°
            zero_action_penalty: é›¶åŠ¨ä½œæƒ©ç½š (ä¼˜åŒ–åé»˜è®¤5.0)
            complexity_bonus: å¤æ‚åº¦å¥–åŠ±ç³»æ•° (æ¯ä¸ªå”¯ä¸€å˜é‡+0.1, æ¯æ¡è§„åˆ™+0.05*bonus)
            structure_prior_weight: ç»“æ„å…ˆéªŒåŠ æˆæƒé‡ï¼ˆ0=å…³é—­ï¼‰
            stability_prior_weight: ç¨³å®šæ€§å…ˆéªŒåŠ æˆæƒé‡ï¼ˆ0=å…³é—­ï¼‰
            enable_bayesian_tuning: æ˜¯å¦å¯ç”¨è´å¶æ–¯ä¼˜åŒ–å¯¹ç¨‹åºå¸¸æ•°è¿›è¡Œè°ƒå‚
            bo_batch_size: BOæ¯æ¬¡å¹¶è¡Œè¯„ä¼°çš„å‚æ•°ç»„æ•°
            bo_iterations: BOè¿­ä»£æ¬¡æ•°
            bo_param_ranges: å‚æ•°èŒƒå›´å­—å…¸ {'const': (min, max), ...}
        """
        # ä¿é™©èµ·è§ï¼šè¿è¡ŒæœŸå†å°è¯•ä¸€æ¬¡å¯¼å…¥
        global ISAAC_GYM_AVAILABLE
        if not ISAAC_GYM_AVAILABLE:
            try:
                from isaacgym import gymapi  # type: ignore
                ISAAC_GYM_AVAILABLE = True
            except Exception:
                # å†å°è¯• vendor è·¯å¾„
                try:
                    _HERE = pathlib.Path(__file__).resolve()
                    _PKG_ROOT = _HERE.parent
                    _REPO_ROOT = _PKG_ROOT.parent
                    _GYM_PY = _REPO_ROOT / 'isaacgym' / 'python'
                    if _GYM_PY.exists() and str(_GYM_PY) not in sys.path:
                        sys.path.insert(0, str(_GYM_PY))
                    from isaacgym import gymapi  # type: ignore
                    os.environ.setdefault('GYM_USD_PLUG_INFO_PATH', str(_GYM_PY / 'isaacgym' / '_bindings' / 'linux-x86_64' / 'usd' / 'plugInfo.json'))
                    ISAAC_GYM_AVAILABLE = True
                except Exception:
                    ISAAC_GYM_AVAILABLE = False
        # ä¸åœ¨æ­¤å¤„ç¡¬æ€§å¤±è´¥ï¼›åœ¨çœŸæ­£åˆ›å»ºç¯å¢ƒæ—¶å†è¿›è¡Œæ£€æµ‹å¹¶æŠ¥é”™
        
        self.trajectory_config = trajectory_config
        self.duration = duration
        self.isaac_num_envs = isaac_num_envs
        self.device = device
        self.replicas_per_program = max(1, int(replicas_per_program))
        self.min_steps_frac = float(min_steps_frac) if 0.0 <= float(min_steps_frac) <= 1.0 else 0.0
        self.reward_reduction = reward_reduction if reward_reduction in ('sum', 'mean') else 'sum'
        self.reward_profile = reward_profile
        # ä¸¥æ ¼æ— å…ˆéªŒï¼ˆé»˜è®¤å¼€å¯ï¼‰ï¼šå¼ºåˆ¶ä½¿ç”¨ç›´æ¥ u_* åŠ¨ä½œè·¯å¾„ï¼Œå®Œå…¨ä¸ä¾èµ–å†…ç½® PID æ¡†æ¶
        self.strict_no_prior = bool(strict_no_prior)
        # å¯¹æ•´é›†å§‹ç»ˆä¸ºâ€œé›¶åŠ¨ä½œâ€çš„ç¨‹åºåŠ ç½šï¼Œé¿å…æœç´¢åœç•™åœ¨ç©ºç¨‹åº
        try:
            self.zero_action_penalty = float(zero_action_penalty)
        except Exception:
            self.zero_action_penalty = 0.0  # AlphaZero: è®©NNè‡ªå·±å­¦ä¹ 
        
        # å¤æ‚åº¦å¥–åŠ±ç³»æ•°ï¼ˆé¼“åŠ±ä½¿ç”¨å¤šå˜é‡å’Œå¤šè§„åˆ™ï¼‰
        try:
            self.complexity_bonus = float(complexity_bonus)
        except Exception:
            self.complexity_bonus = 0.0  # AlphaZero: è®©NNè‡ªå·±å­¦ä¹ å¤æ‚åº¦æƒè¡¡
        
        # åŠ¨ä½œå…¨å±€ç¼©æ”¾ç³»æ•°ï¼ˆè¯Šæ–­ç”¨ï¼‰
        try:
            self.action_scale_multiplier = float(action_scale_multiplier)
        except Exception:
            self.action_scale_multiplier = 1.0

        self.structure_prior_weight = float(structure_prior_weight)
        self.stability_prior_weight = float(stability_prior_weight)
        self.metric_export_keys: Tuple[str, ...] = (
            'position_rmse',
            'control_effort',
        )

        # MADï¼ˆMagnitude-Angle-Deltaï¼‰å®‰å…¨å£³å‚æ•°
        self.enable_output_mad = bool(enable_output_mad)
        self.mad_min_fz = float(mad_min_fz)
        self.mad_max_fz = float(mad_max_fz)
        self.mad_max_xy = float(abs(mad_max_xy))
        self.mad_max_yaw = float(abs(mad_max_yaw))
        self.mad_max_delta_fz = float(abs(mad_max_delta_fz))
        self.mad_max_delta_xy = float(abs(mad_max_delta_xy))
        self.mad_max_delta_yaw = float(abs(mad_max_delta_yaw))
        self._mad_eps = 1e-6
        
        # ğŸ¯ é€‰æ‹© reward è®¡ç®—å™¨
        self.use_scg_exact_reward = bool(use_scg_exact_reward)
        if self.reward_profile == 'safe_control_tracking':
            # Force SCG exact reward path so we faithfully mirror the benchmark.
            self.use_scg_exact_reward = True
            self.metric_export_keys = ('state_cost', 'action_cost')
        self._step_reward_calc = None
        self._scg_reward_calc = None
        
        if self.use_scg_exact_reward and SCGExactRewardCalculator is not None:
            # ä½¿ç”¨ç²¾ç¡® SCG reward è®¡ç®—å™¨
            try:
                self._scg_reward_calc = SCGExactRewardCalculator(
                    num_envs=self.isaac_num_envs,
                    device=self.device
                )
                print(f"[BatchEvaluator] âœ… ä½¿ç”¨ç²¾ç¡® SCG reward è®¡ç®—å™¨")
            except Exception as e:
                print(f"[BatchEvaluator] âš ï¸ SCG reward åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå›é€€ Stepwise")
                self.use_scg_exact_reward = False
        
        if not self.use_scg_exact_reward:
            # åˆå§‹åŒ– Stepwise å¥–åŠ±è®¡ç®—å™¨
            try:
                weights, ks = get_reward_profile(self.reward_profile)
                # ä¼°è®¡ dt: Isaac é»˜è®¤ç‰©ç†é¢‘ç‡ 240 Hzï¼Œæ§åˆ¶é¢‘ç‡ 48 Hz -> dt â‰ˆ 1/48
                self._step_dt = 1.0 / 48.0
                self._step_reward_calc = StepwiseRewardCalculator(weights, ks, dt=self._step_dt, num_envs=self.isaac_num_envs, device=self.device)
            except Exception:
                self._step_reward_calc = None

        # è®°å½•æœ€è¿‘ä¸€æ¬¡å®‰å…¨è£å‰ªåçš„ [fz, tx, ty, tz]
        self._last_safe_actions = torch.zeros((self.isaac_num_envs, 4), device=self.device)

        # Isaac Gymç¯å¢ƒæ± ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self._isaac_env_pool = None
        self._envs_ready = False  # ç¯å¢ƒæ± æŒä¹…åŒ–æ ‡è®°
        self._last_reset_size = 0  # ä¸Šæ¬¡resetçš„ç¯å¢ƒæ•°
        
        # ğŸš€ å¿«é€Ÿè·¯å¾„ä¼˜åŒ–
        self.use_fast_path = use_fast_path
        self._program_cache = {}  # é¢„ç¼–è¯‘ç¼“å­˜: {prog_hash: (fz,tx,ty,tz)}
        disable_gpu_env = os.getenv('DISABLE_GPU_EXPRESSION', '').lower()
        if disable_gpu_env in ('1', 'true', 'yes'):
            use_gpu_expression_executor = False
        self.use_gpu_expression_executor = bool(use_gpu_expression_executor)
        self._gpu_executor = None
        if self.use_gpu_expression_executor and GPUProgramExecutor is not None:
            try:
                self._gpu_executor = GPUProgramExecutor(device=self.device)
                print("[BatchEvaluator] âœ… GPUè¡¨è¾¾å¼æ‰§è¡Œå™¨å·²å¯ç”¨")
            except Exception as gpu_exc:
                self._gpu_executor = None
                self.use_gpu_expression_executor = False
                print(f"[BatchEvaluator] âš ï¸ GPUè¡¨è¾¾å¼æ‰§è¡Œå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€CPU: {gpu_exc}")
        elif self.use_gpu_expression_executor:
            print("[BatchEvaluator] âš ï¸ GPUProgramExecutor ä¸å¯ç”¨ï¼Œå›é€€CPU")
            self.use_gpu_expression_executor = False

        env_gpu_loop = os.getenv('ENABLE_GPU_CONTROL_LOOP', '0').lower() in ('1', 'true', 'yes')
        if gpu_control_loop is None:
            self._use_gpu_control_loop = bool(env_gpu_loop)
        else:
            self._use_gpu_control_loop = bool(gpu_control_loop)
        if self._use_gpu_control_loop and (self._gpu_executor is None or not self.use_gpu_expression_executor):
            self._use_gpu_control_loop = False
        if self._use_gpu_control_loop:
            print("[BatchEvaluator] ğŸš€ æ§åˆ¶å¾ªç¯å…¨GPUè·¯å¾„å·²å¯ç”¨")
        
        # ğŸš€ğŸš€ è¶…é«˜æ€§èƒ½æ‰§è¡Œå™¨ (å®Œå…¨å‘é‡åŒ– + JIT)
        if use_fast_path:
            try:
                from .ultra_fast_executor import UltraFastExecutor
                self._ultra_executor = UltraFastExecutor()
            except Exception as e:
                try:
                    from ultra_fast_executor import UltraFastExecutor
                    self._ultra_executor = UltraFastExecutor()
                except Exception:
                    print(f"[BatchEvaluator] âš ï¸ è¶…é«˜æ€§èƒ½æ‰§è¡Œå™¨åŠ è½½å¤±è´¥: {e}")
                    self._ultra_executor = None
        else:
            self._ultra_executor = None
            # æ¸…ç†å¯èƒ½æ®‹ç•™çš„ç¼–è¯‘ç¼“å­˜
            if hasattr(self, '_compiled_forces'):
                delattr(self, '_compiled_forces')
        
        # ğŸ”¥ è´å¶æ–¯ä¼˜åŒ–è°ƒå‚æ¨¡å—
        self.enable_bayesian_tuning = bool(enable_bayesian_tuning)
        self.bo_batch_size = int(bo_batch_size)
        self.bo_iterations = int(bo_iterations)
        self.bo_param_ranges = bo_param_ranges or {'default': (-3.0, 3.0)}
        self._bo_tuner = None  # å»¶è¿Ÿåˆ›å»ºï¼ˆå› ä¸ºä¾èµ–ç¨‹åºå®é™…å‚æ•°ï¼‰
        # ç¨‹åºè¯„ä¼°ç»“æœç¼“å­˜ï¼šé¿å…å¯¹å®Œå…¨ç›¸åŒçš„ç¨‹åºé‡å¤ä»¿çœŸ
        self._eval_cache: Dict[str, float] = {}
        self._eval_cache_limit: int = 5000
        
        print(f"[BatchEvaluator] åˆå§‹åŒ–å®Œæˆ")
        print(f"  - Isaac Gym: {'âœ… å¯ç”¨' if ISAAC_GYM_AVAILABLE else 'âŒ æœªå¯ç”¨'}")
        print(f"  - å¹¶è¡Œç¯å¢ƒæ•°: {self.isaac_num_envs}")
        print(f"  - GPUè®¾å¤‡: {self.device}")
        print(f"  - å•ç¨‹åºå‰¯æœ¬æ•°: {self.replicas_per_program}")
        if self.enable_bayesian_tuning:
            print(f"  - è´å¶æ–¯è°ƒå‚: âœ… å¯ç”¨ (batch={self.bo_batch_size}, iters={self.bo_iterations})")
        print(f"  - æœ€å°æ­¥æ•°æ¯”ä¾‹: {self.min_steps_frac}")
        print(f"  - å¥–åŠ±å½’çº¦: {self.reward_reduction}")
        print(f"  - ä¸¥æ ¼æ— å…ˆéªŒ(u_*ç›´æ¥æ§åˆ¶): {'âœ… æ˜¯' if self.strict_no_prior else 'âŒ å¦'}")
        if self.strict_no_prior:
            print(f"  - é›¶åŠ¨ä½œæƒ©ç½š: {self.zero_action_penalty}")

    # ---------------------- ç¨‹åºè¯„ä¼°ç¼“å­˜è¾…åŠ© ----------------------
    def _program_eval_key(self, program: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆç¨³å®šçš„ç¨‹åºé”®ï¼Œç”¨äºè¯„ä¼°ç¼“å­˜ã€‚

        ä½¿ç”¨ core.serialization.to_serializable_dict çš„ JSON è¡¨ç¤ºï¼Œå†åš blake2s å“ˆå¸Œï¼›
        è‹¥ä¸å¯ç”¨åˆ™é€€åŒ–ä¸º str(program)ã€‚
        """
        if isinstance(program, ProgramParamCandidate):
            if not program.allow_cache:
                return None
            if program.cache_key:
                return program.cache_key

        try:
            import json
            if isinstance(program, ProgramParamCandidate):
                base_prog = program.base_program
                if _serialize_program is not None:
                    serial_source = _serialize_program(base_prog)  # type: ignore
                elif _to_serializable_dict is not None:
                    serial_source = _to_serializable_dict(base_prog)
                else:
                    serial_source = base_prog
            elif _serialize_program is not None:
                serial_source = _serialize_program(program)  # type: ignore
            elif _to_serializable_dict is not None:
                serial_source = _to_serializable_dict(program)
            else:
                serial_source = program
            serial = _normalize_program_structure_for_cache(serial_source)
            s = json.dumps(serial, sort_keys=True, ensure_ascii=False, separators=(",", ":"))
            digest = hashlib.blake2s(s.encode("utf-8")).hexdigest()
            if isinstance(program, ProgramParamCandidate):
                program.cache_key = digest
            return digest
        except Exception:
            try:
                return str(program)
            except Exception:
                return str(id(program))

    
    def _init_isaac_gym_pool(self):
        """å»¶è¿Ÿåˆå§‹åŒ–Isaac Gymç¯å¢ƒæ± """
        if self._isaac_env_pool is not None:
            return
        
        print(f"[BatchEvaluator] åˆå§‹åŒ–Isaac Gymç¯å¢ƒæ± ...")
        
        # å¯¼å…¥Isaac Gymç¯å¢ƒ
        try:
            from envs.isaac_gym_drone_env import IsaacGymDroneEnv
        except ImportError:
            try:
                # æ·»åŠ è·¯å¾„ä»¥æ”¯æŒç›´æ¥è¿è¡Œ
                import sys, pathlib
                _parent = pathlib.Path(__file__).resolve().parent.parent
                if str(_parent) not in sys.path:
                    sys.path.insert(0, str(_parent))
                from envs.isaac_gym_drone_env import IsaacGymDroneEnv
            except ImportError:
                raise ImportError("æ— æ³•å¯¼å…¥IsaacGymDroneEnvï¼Œè¯·æ£€æŸ¥envsç›®å½•")
        
        # åˆ›å»ºç¯å¢ƒæ± 
        self._isaac_env_pool = IsaacGymDroneEnv(
            num_envs=self.isaac_num_envs,
            device=self.device,
            headless=True,
            duration_sec=self.duration
        )
        # ä¿å­˜æ§åˆ¶å‘¨æœŸ
        try:
            self._control_freq = int(self._isaac_env_pool.control_freq)
        except Exception:
            self._control_freq = 48
        self._control_dt = 1.0 / float(self._control_freq)
        
        print(f"[BatchEvaluator] âœ… Isaac Gymç¯å¢ƒæ± å°±ç»ªï¼ˆ{self.isaac_num_envs} ç¯å¢ƒï¼‰")

    # ---------------------- è´å¶æ–¯ä¼˜åŒ–è°ƒå‚æ¨¡å— ----------------------
    def _batch_tune_programs_with_bo(self, programs: List[List[Dict[str, Any]]]) -> List[List[Dict[str, Any]]]:
        """ğŸš€ çœŸæ­£çš„æ‰¹é‡è´å¶æ–¯ä¼˜åŒ–ï¼šå¯¹å¤šä¸ªç¨‹åºåŒæ—¶è¿›è¡Œ GP-UCB è¿­ä»£ä¼˜åŒ–
        
        æ ¸å¿ƒæ”¹è¿›ï¼ˆç›¸æ¯”ä¹‹å‰çš„Sobolé‡‡æ ·ï¼‰ï¼š
        1. ä½¿ç”¨ Gaussian Process å»ºæ¨¡å‚æ•°ç©ºé—´
        2. æ¯è½®è¿­ä»£æ ¹æ® UCB é‡‡é›†å‡½æ•°æ™ºèƒ½é€‰æ‹©ä¸‹ä¸€æ‰¹å€™é€‰
        3. æ‰€æœ‰ç¨‹åºçš„å€™é€‰ä»ç„¶æ‰¹é‡å¹¶è¡Œè¯„ä¼°ï¼ˆåˆ©ç”¨Isaac Gymï¼‰
        
        å·¥ä½œæµç¨‹ï¼š
        - Iteration 1: åˆå§‹åŒ–é‡‡æ ·ï¼ˆSobolï¼‰â†’ æ‰¹é‡è¯„ä¼° â†’ æ›´æ–° GP
        - Iteration 2+: UCB é€‰æ‹©å€™é€‰ â†’ æ‰¹é‡è¯„ä¼° â†’ æ›´æ–° GP
        - æœ€ç»ˆï¼šæ¯ä¸ªç¨‹åºè¿”å›æœ€ä½³å‚æ•°
        
        Args:
            programs: å¾…è°ƒä¼˜çš„ç¨‹åºåˆ—è¡¨
            
        Returns:
            tuned_programs: è°ƒä¼˜åçš„ç¨‹åºåˆ—è¡¨
        """
        try:
            from utils.bayesian_tuner import (
                BayesianTuner, ParameterSpec, 
                extract_tunable_params, inject_tuned_params
            )
        except ImportError:
            print("[BatchEvaluator] Warning: BayesianTuner not available, skipping BO")
            return programs
        
        # ç¦ç”¨é€’å½’BO
        old_bo_flag = self.enable_bayesian_tuning
        self.enable_bayesian_tuning = False
        
        try:
            # ğŸ”§ ç¬¬ä¸€æ­¥ï¼šä¸ºæ¯ä¸ªç¨‹åºåˆå§‹åŒ–ç‹¬ç«‹çš„ BayesianTuner
            program_tuners = []  # [(prog_idx, tuner, params), ...]
            param_paths_map: Dict[int, Tuple[str, ...]] = {}
            cache_key_map: Dict[int, Optional[str]] = {}
            
            for prog_idx, program in enumerate(programs):
                params = extract_tunable_params(program)
                if not params:
                    # æ— å‚æ•°ï¼Œè·³è¿‡BO
                    program_tuners.append((prog_idx, None, None))
                    param_paths_map[prog_idx] = tuple()
                    cache_key_map[prog_idx] = self._program_eval_key(program)
                    continue
                
                # å®šä¹‰å‚æ•°ç©ºé—´
                param_specs = []
                for path, init_value in params:
                    if 'default' in self.bo_param_ranges:
                        low, high = self.bo_param_ranges['default']
                    else:
                        low = init_value - 2.0
                        high = init_value + 2.0
                    param_specs.append(ParameterSpec(name=path, low=low, high=high, log_scale=False))
                
                param_paths = tuple(path for path, _ in params)
                param_paths_map[prog_idx] = param_paths
                cache_key_map[prog_idx] = self._program_eval_key(program)
                
                # åˆ›å»º BayesianTuner å®ä¾‹
                tuner = BayesianTuner(
                    param_specs=param_specs,
                    batch_size=self.bo_batch_size,
                    n_iterations=self.bo_iterations,
                    ucb_kappa=2.0,
                    random_seed=hash(str(program)) % (2**31)
                )
                program_tuners.append((prog_idx, tuner, params))
            
            # ğŸ”§ ç¬¬äºŒæ­¥ï¼šè¿­ä»£å¼æ‰¹é‡BOï¼ˆçœŸæ­£çš„ Bayesian Optimizationï¼‰
            import time as time_module
            bo_start_time = time_module.time()
            print(f"[BatchEvaluator] ğŸ§  çœŸå®BO: {len([t for t in program_tuners if t[1] is not None])} ä¸ªç¨‹åº, "
                  f"{self.bo_iterations} è½®è¿­ä»£, {self.bo_batch_size} ä¸ªå€™é€‰/è½®")
            
            for iter_idx in range(self.bo_iterations):
                iter_start_time = time_module.time()
                # 2.1 æ”¶é›†æœ¬è½®æ‰€æœ‰ç¨‹åºçš„å€™é€‰å‚æ•°
                all_candidates = []  # [(prog_idx, candidate_program), ...]
                candidate_metadata = []  # [(prog_idx, X_raw_row), ...] ç”¨äºæ›´æ–°GP
                gen_start_time = time_module.time()
                
                for prog_idx, tuner, params in program_tuners:
                    if tuner is None:
                        # æ— å‚æ•°ç¨‹åºï¼Œåªåœ¨ç¬¬ä¸€è½®æ·»åŠ ä¸€æ¬¡
                        if iter_idx == 0:
                            all_candidates.append((prog_idx, programs[prog_idx]))
                            candidate_metadata.append((prog_idx, None))
                        continue
                    
                    # ç”Ÿæˆå€™é€‰ï¼šç¬¬ä¸€è½®ç”¨Sobolï¼Œåç»­ç”¨UCB
                    if iter_idx == 0:
                        X_norm = tuner._sobol_sample(tuner.batch_size)
                    else:
                        X_norm = tuner._select_next_batch()
                    
                    X_raw = tuner._denormalize(X_norm)
                    
                    # ä¸ºæ¯ç»„å‚æ•°åˆ›å»ºç¨‹åºå‰¯æœ¬
                    param_paths = param_paths_map.get(prog_idx, tuple())
                    for i in range(len(X_raw)):
                        param_values = tuple(float(X_raw[i, j]) for j in range(len(param_paths)))
                        candidate = ProgramParamCandidate(
                            base_program=programs[prog_idx],
                            param_paths=param_paths,
                            param_values=param_values,
                        )
                        all_candidates.append((prog_idx, candidate))
                        candidate_metadata.append((prog_idx, X_raw[i]))
                
                gen_time = time_module.time() - gen_start_time
                print(f"[BO] ç¬¬{iter_idx+1}è½®å€™é€‰ç”Ÿæˆå®Œæˆ: {len(all_candidates)}ä¸ªç¨‹åº | è€—æ—¶{gen_time:.1f}ç§’ (å«deepcopy)")

                # ğŸ“Š ç»Ÿè®¡å½“å‰è½®å€™é€‰ä¸­ç‹¬ç‰¹çš„ç»“æ„æ¨¡æ¿æ•°é‡ï¼ˆå¿½ç•¥å¸¸æ•°ï¼‰
                if all_candidates:
                    structure_keys = set()
                    for _, cand_prog in all_candidates:
                        base_prog = cand_prog.base_program if isinstance(cand_prog, ProgramParamCandidate) else cand_prog
                        try:
                            key = self._program_eval_key(base_prog)
                        except Exception:
                            key = None
                        if key is not None:
                            structure_keys.add(key)
                    unique_structures = len(structure_keys) if structure_keys else len(all_candidates)
                    print(f"[BO] ç¬¬{iter_idx+1}è½®ç»“æ„è¦†ç›–: {unique_structures}/{len(all_candidates)} unique templates")
                
                # 2.2 æ‰¹é‡è¯„ä¼°æ‰€æœ‰å€™é€‰
                if not all_candidates:
                    break
                    
                all_candidate_programs = [prog for _, prog in all_candidates]
                eval_start_time = time_module.time()
                
                # ğŸ”¥ BO å†…å±‚è¯„ä¼°æ—¶ï¼Œé‡ç½® SCG reward calculator ä»¥åŒ¹é…æ–°çš„æ‰¹é‡å¤§å°
                bo_batch_size = len(all_candidate_programs)
                if self.use_scg_exact_reward and self._scg_reward_calc is not None:
                    from .reward_scg_exact import SCGExactRewardCalculator
                    self._scg_reward_calc = SCGExactRewardCalculator(
                        num_envs=bo_batch_size,
                        device=self.device,
                        state_weights=self._scg_reward_calc.Q,
                        action_weight=self._scg_reward_calc.R,
                    )
                
                all_rewards = self.evaluate_batch(all_candidate_programs)
                eval_time = time_module.time() - eval_start_time
                print(f"[BO] ç¬¬{iter_idx+1}è½®è¯„ä¼°å®Œæˆ: {len(all_candidate_programs)}ä¸ªå€™é€‰ | è€—æ—¶{eval_time:.1f}ç§’")
                
                # 2.3 æ›´æ–°æ¯ä¸ªç¨‹åºçš„ GP æ¨¡å‹
                for idx, ((prog_idx, _), reward) in enumerate(zip(all_candidates, all_rewards)):
                    _, tuner, _ = program_tuners[prog_idx]
                    if tuner is None:
                        continue
                    
                    # è·å–å¯¹åº”çš„å‚æ•°å€¼
                    X_raw_row = candidate_metadata[idx][1]
                    if X_raw_row is not None:
                        X_norm_row = tuner._normalize(X_raw_row.reshape(1, -1))
                        tuner.X_history.append(X_norm_row)
                        tuner.y_history.append(np.array([reward]))
                
                # 2.4 æ‹Ÿåˆ GPï¼ˆä¸ºä¸‹ä¸€è½®åšå‡†å¤‡ï¼‰
                if iter_idx < self.bo_iterations - 1:  # æœ€åä¸€è½®ä¸éœ€è¦æ‹Ÿåˆ
                    gp_start_time = time_module.time()
                    for prog_idx, tuner, _ in program_tuners:
                        if tuner is not None and tuner.X_history:
                            X_all = np.vstack(tuner.X_history)
                            y_all = np.concatenate(tuner.y_history)
                            tuner.gp.fit(X_all, y_all)
                    gp_time = time_module.time() - gp_start_time
                    print(f"[BO] GPæ¨¡å‹æ‹Ÿåˆå®Œæˆ: {len([t for t in program_tuners if t[1] is not None])}ä¸ªæ¨¡å‹ | è€—æ—¶{gp_time:.2f}ç§’")
                
                iter_time = time_module.time() - iter_start_time
                print(f"[BO] ç¬¬{iter_idx+1}è½®å®Œæˆ | æ€»è€—æ—¶{iter_time:.1f}ç§’")
            
            # ğŸ”§ ç¬¬ä¸‰æ­¥ï¼šä¸ºæ¯ä¸ªç¨‹åºé€‰æ‹©æœ€ä½³å‚æ•°
            tuned_programs = []
            for prog_idx, tuner, params in program_tuners:
                if tuner is None or not tuner.y_history:
                    # æ— å‚æ•°æˆ–BOå¤±è´¥ï¼Œä¿ç•™åŸç¨‹åº
                    tuned_programs.append(programs[prog_idx])
                    continue
                
                # æ‰¾åˆ°æœ€ä½³å‚æ•°
                y_all = np.concatenate(tuner.y_history)
                best_idx = np.argmax(y_all)
                X_all = np.vstack(tuner.X_history)
                best_X_norm = X_all[best_idx]
                best_X_raw = tuner._denormalize(best_X_norm.reshape(1, -1))[0]
                
                # æ³¨å…¥æœ€ä½³å‚æ•°
                import copy
                tuned_prog = copy.deepcopy(programs[prog_idx])
                param_dict = {params[j][0]: best_X_raw[j] for j in range(len(params))}
                inject_tuned_params(tuned_prog, param_dict)
                tuned_programs.append(tuned_prog)
            
            bo_total_time = time_module.time() - bo_start_time
            print(f"[BatchEvaluator] âœ… çœŸå®BOå®Œæˆ: {len(tuned_programs)} ä¸ªç¨‹åºå·²é€šè¿‡GP-UCBä¼˜åŒ– | æ€»è€—æ—¶{bo_total_time:.1f}ç§’")
            
            # ğŸ”¥ BO å®Œæˆåï¼Œæ¢å¤åŸå§‹æ‰¹é‡å¤§å°çš„ SCG calculator
            if self.use_scg_exact_reward and self._scg_reward_calc is not None:
                from .reward_scg_exact import SCGExactRewardCalculator
                self._scg_reward_calc = SCGExactRewardCalculator(
                    num_envs=self.isaac_num_envs,
                    device=self.device,
                    state_weights=self._scg_reward_calc.Q,
                    action_weight=self._scg_reward_calc.R,
                )
            
            return tuned_programs
            
        finally:
            self.enable_bayesian_tuning = old_bo_flag
    
    def _tune_program_with_bo(self, program: List[Dict[str, Any]]) -> Tuple[List[Dict[str, Any]], float]:
        """å¯¹å•ä¸ªç¨‹åºä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–è°ƒæ•´å¸¸æ•°å‚æ•°
        
        Args:
            program: åŸå§‹ç¨‹åºï¼ˆåŒ…å«åˆå§‹å‚æ•°ï¼‰
            
        Returns:
            tuned_program: è°ƒä¼˜åçš„ç¨‹åº
            best_reward: å¯¹åº”çš„æœ€ä½³å¥–åŠ±
        """
        try:
            from utils.bayesian_tuner import (
                BayesianTuner, ParameterSpec, 
                extract_tunable_params, inject_tuned_params
            )
        except ImportError:
            print("[BatchEvaluator] Warning: BayesianTuner not available, skipping BO")
            return program, float('-inf')
        
        # 1. æå–å¯è°ƒå‚æ•°
        params = extract_tunable_params(program)
        if not params:
            # æ²¡æœ‰å¸¸æ•°å‚æ•°ï¼Œæ— éœ€è°ƒä¼˜
            return program, float('-inf')
        
        # 2. å®šä¹‰å‚æ•°ç©ºé—´
        param_specs = []
        for path, init_value in params:
            # æ ¹æ®åˆå§‹å€¼æˆ–å…¨å±€é…ç½®ç¡®å®šèŒƒå›´
            if 'default' in self.bo_param_ranges:
                low, high = self.bo_param_ranges['default']
            else:
                # è‡ªé€‚åº”ï¼šä»¥åˆå§‹å€¼ä¸ºä¸­å¿ƒï¼ŒÂ±2å€èŒƒå›´
                low = init_value - 2.0
                high = init_value + 2.0
            
            param_specs.append(ParameterSpec(
                name=path,
                low=low,
                high=high,
                log_scale=False
            ))
        
        # 3. å®šä¹‰è¯„ä¼°å‡½æ•°ï¼ˆğŸš€ æ‰¹é‡å¹¶è¡Œä¼˜åŒ–ï¼šä¸€æ¬¡è¯„ä¼°æ‰€æœ‰å€™é€‰å‚æ•°ï¼‰
        def eval_fn(X_batch):
            """X_batch: [bo_batch_size, n_params]"""
            import copy
            batch_size = len(X_batch)
            
            # ğŸš€ å…³é”®ä¼˜åŒ–ï¼šæ‰¹é‡æ„é€ æ‰€æœ‰å€™é€‰ç¨‹åºï¼ˆé¿å…ä¸²è¡Œå¾ªç¯ï¼‰
            all_programs = []
            for i in range(batch_size):
                prog_copy = copy.deepcopy(program)
                param_dict = {params[j][0]: X_batch[i, j] for j in range(len(params))}
                inject_tuned_params(prog_copy, param_dict)
                all_programs.append(prog_copy)
            
            # ğŸš€ ä¸€æ¬¡æ€§è¯„ä¼°æ‰€æœ‰ç¨‹åºï¼ˆåˆ©ç”¨ Isaac Gym 4096 å¹¶è¡Œç¯å¢ƒï¼‰
            # ç¦ç”¨é€’å½’ BO é¿å…æ— é™å¾ªç¯
            old_bo_flag = self.enable_bayesian_tuning
            self.enable_bayesian_tuning = False
            try:
                rewards = self.evaluate_batch(all_programs)  # âœ… æ‰¹é‡å¹¶è¡Œè¯„ä¼°
            finally:
                self.enable_bayesian_tuning = old_bo_flag
            
            return np.array(rewards)
        
        # 4. è¿è¡Œ BO
        tuner = BayesianTuner(
            param_specs=param_specs,
            batch_size=min(self.bo_batch_size, self.isaac_num_envs),
            n_iterations=self.bo_iterations,
            ucb_kappa=2.0,
            random_seed=hash(str(program)) % 2**31
        )
        
        best_params, best_reward = tuner.optimize(eval_fn, verbose=False)
        
        # 5. æ³¨å…¥æœ€ä½³å‚æ•°
        import copy
        tuned_program = copy.deepcopy(program)
        param_dict = {params[j][0]: best_params[j] for j in range(len(params))}
        inject_tuned_params(tuned_program, param_dict)
        
        return tuned_program, best_reward

    # ---------------------- DSL è¾…åŠ©ï¼šAST æ±‚å€¼ä¸åŠ¨ä½œè§£æ ----------------------
    def _ast_eval(self, node, state: Dict[str, float]) -> float:
        """æœ€å°æ±‚å€¼å™¨ï¼šæ”¯æŒ MCTS ç”Ÿæˆçš„ç®—å­é›†ï¼ˆæ•°å€¼è¡¨è¾¾å¼ï¼‰ã€‚"""
        try:
            # å»¶è¿Ÿå¯¼å…¥ DSL ç»“ç‚¹ç±»å‹
            try:
                from core.dsl import ProgramNode, TerminalNode, UnaryOpNode, BinaryOpNode, IfNode  # type: ignore
            except Exception:
                # æ·»åŠ è·¯å¾„ä»¥æ”¯æŒç›´æ¥è¿è¡Œ
                import sys, pathlib
                _parent = pathlib.Path(__file__).resolve().parent.parent
                if str(_parent) not in sys.path:
                    sys.path.insert(0, str(_parent))
                from core.dsl import ProgramNode, TerminalNode, UnaryOpNode, BinaryOpNode, IfNode  # type: ignore

            # é€’å½’æ±‚å€¼
            if isinstance(node, (int, float)):
                return float(node)
            # ç»ˆç«¯ï¼šå˜é‡åæˆ–å¸¸æ•°
            if hasattr(node, 'value') and not hasattr(node, 'op'):
                v = getattr(node, 'value', 0.0)
                if isinstance(v, str):
                    return float(state.get(v, 0.0))
                return float(v)
            # ä¸€å…ƒ
            if hasattr(node, 'op') and hasattr(node, 'child'):
                x = float(self._ast_eval(node.child, state))
                op = str(getattr(node, 'op', ''))
                if op == 'abs':
                    return abs(x)
                if op == 'sin':
                    import math
                    return float(math.sin(x))
                if op == 'cos':
                    import math
                    return float(math.cos(x))
                if op == 'tan':
                    import math
                    return float(max(-10.0, min(10.0, math.tan(x))))
                if op == 'log1p':
                    import math
                    return float(math.log1p(abs(x)))
                if op == 'sqrt':
                    import math
                    return float(math.sqrt(abs(x)))
                if op == 'sign':
                    return float(1.0 if x > 0 else (-1.0 if x < 0 else 0.0))
                return float(x)
            # äºŒå…ƒ
            if hasattr(node, 'op') and hasattr(node, 'left') and hasattr(node, 'right'):
                op = str(getattr(node, 'op', ''))
                if op in ('+', '-', '*', '/', 'max', 'min'):
                    a = float(self._ast_eval(node.left, state))
                    b = float(self._ast_eval(node.right, state))
                    if op == '+':
                        return a + b
                    if op == '-':
                        return a - b
                    if op == '*':
                        return a * b
                    if op == '/':
                        return a / b if abs(b) > 1e-9 else (a * 1.0)
                    if op == 'max':
                        return a if a >= b else b
                    if op == 'min':
                        return a if a <= b else b
                elif op in ('<', '>', '==', '!='):
                    a = float(self._ast_eval(node.left, state))
                    b = float(self._ast_eval(node.right, state))
                    if op == '<':
                        return 1.0 if a < b else 0.0
                    if op == '>':
                        return 1.0 if a > b else 0.0
                    if op == '==':
                        return 1.0 if abs(a - b) < 1e-9 else 0.0
                    if op == '!=':
                        return 1.0 if abs(a - b) >= 1e-9 else 0.0
            # IfNode
            if hasattr(node, 'condition') and hasattr(node, 'then_branch') and hasattr(node, 'else_branch'):
                c = float(self._ast_eval(node.condition, state))
                return float(self._ast_eval(node.then_branch if c > 0 else node.else_branch, state))
        except Exception:
            pass
        return 0.0

    def _program_uses_u(self, program: List[Dict[str, Any]]) -> bool:
        """æ£€æµ‹åŠ¨ä½œæ˜¯å¦ä½¿ç”¨äº† u_fz/u_tx/u_ty/u_tz é”®ã€‚"""
        try:
            for rule in program or []:
                acts = rule.get('action', []) or []
                for a in acts:
                    try:
                        # a ä¸º BinaryOpNode('set', TerminalNode(key), expr)
                        if hasattr(a, 'op') and a.op == 'set' and hasattr(a, 'left') and hasattr(a.left, 'value'):
                            key = str(getattr(a.left, 'value', ''))
                            if key in ('u_fz', 'u_tx', 'u_ty', 'u_tz'):
                                return True
                    except Exception:
                        continue
        except Exception:
            return False
        return False

    def _mirror_expand_single_axis_program(self, program: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è‹¥ç¨‹åºä»…è¾“å‡º u_txï¼Œåˆ™é•œåƒç”Ÿæˆ u_tyï¼Œå¹¶é™„å¸¦å›ºå®š yaw/thrust ç¨³å®šå™¨ã€‚

        ç›®çš„ï¼šå½“æœç´¢åœ¨å•è½´ç©ºé—´å†…è¿›è¡Œæ—¶ï¼Œä»èƒ½å¾—åˆ°å››é€šé“å¯æ‰§è¡Œçš„å®Œæ•´æ§åˆ¶å¾‹ã€‚
        """
        import copy
        try:
            from core.dsl import TerminalNode, ConstantNode, UnaryOpNode, BinaryOpNode  # type: ignore
        except Exception:
            # æ— æ³•å¯¼å…¥ DSL èŠ‚ç‚¹æ—¶ç›´æ¥è¿”å›åŸç¨‹åºï¼Œé¿å…ä¸­æ–­è®­ç»ƒ
            return copy.deepcopy(program)

        var_mapping = {
            'err_p_roll': 'err_p_pitch',
            'err_d_roll': 'err_d_pitch',
            'err_i_roll': 'err_i_pitch',
            'ang_vel_x': 'ang_vel_y',
            'pos_err_y': 'pos_err_x',  # u_txâ†’u_ty: yè½´ä½ç½®è¯¯å·®æ˜ å°„ä¸ºxè½´
            'vel_y': 'vel_x',          # u_txâ†’u_ty: yè½´é€Ÿåº¦æ˜ å°„ä¸ºxè½´
        }

        def map_expr(expr):
            """é€’å½’æ˜ å°„è¡¨è¾¾å¼ä¸­çš„è½´å‘å˜é‡ã€‚"""
            if isinstance(expr, TerminalNode):
                val = getattr(expr, 'value', None)
                if isinstance(val, str) and val in var_mapping:
                    return TerminalNode(var_mapping[val])
                return copy.deepcopy(expr)
            if isinstance(expr, ConstantNode):
                return copy.deepcopy(expr)
            if isinstance(expr, UnaryOpNode):
                return UnaryOpNode(expr.op, map_expr(expr.child), params=copy.deepcopy(getattr(expr, 'params', {})))
            if isinstance(expr, BinaryOpNode):
                return BinaryOpNode(expr.op, map_expr(expr.left), map_expr(expr.right))
            if isinstance(expr, dict):
                etype = expr.get('type')
                if etype in ('TerminalNode', 'Terminal'):
                    val = expr.get('value')
                    if isinstance(val, str) and val in var_mapping:
                        new_expr = copy.deepcopy(expr)
                        new_expr['value'] = var_mapping[val]
                        return new_expr
                    return copy.deepcopy(expr)
                if etype in ('ConstantNode', 'Constant'):
                    return copy.deepcopy(expr)
                if etype in ('UnaryOpNode', 'Unary'):
                    return {
                        'type': 'UnaryOpNode',
                        'op': expr.get('op'),
                        'child': map_expr(expr.get('child')),
                        'params': copy.deepcopy(expr.get('params')) if expr.get('params') is not None else None,
                    }
                if etype in ('BinaryOpNode', 'Binary'):
                    return {
                        'type': 'BinaryOpNode',
                        'op': expr.get('op'),
                        'left': map_expr(expr.get('left')),
                        'right': map_expr(expr.get('right')),
                    }
            return copy.deepcopy(expr)

        def extract_target(action) -> Optional[str]:
            if isinstance(action, BinaryOpNode) and getattr(action, 'op', None) == 'set':
                left = getattr(action, 'left', None)
                if isinstance(left, TerminalNode) and isinstance(getattr(left, 'value', None), str):
                    return str(left.value)
            if isinstance(action, dict) and action.get('op') == 'set':
                left = action.get('left', {})
                if isinstance(left, dict):
                    val = left.get('value')
                    if isinstance(val, str):
                        return val
            return None

        # æ±‡æ€»å½“å‰ç¨‹åºçš„è¾“å‡ºé€šé“
        targets = []
        for rule in program or []:
            for act in rule.get('action', []) or []:
                tgt = extract_target(act)
                if tgt:
                    targets.append(tgt)
        unique_targets = set(targets)
        if len(unique_targets) != 1 or 'u_tx' not in unique_targets:
            return copy.deepcopy(program)

        # æ‰¾åˆ°é¦–ä¸ª u_tx è§„åˆ™ï¼Œå…‹éš†å¹¶é•œåƒåˆ° u_ty
        base_rule = None
        base_action = None
        for rule in program or []:
            for act in rule.get('action', []) or []:
                if extract_target(act) == 'u_tx':
                    base_rule = rule
                    base_action = act
                    break
            if base_action is not None:
                break
        if base_rule is None or base_action is None:
            return copy.deepcopy(program)

        # æ„é€ ä¿®æ­£åçš„ u_tx è§„åˆ™ï¼ˆæ™ºèƒ½å–åä½ç½®è¯¯å·®å’Œé€Ÿåº¦é¡¹ï¼‰
        # ğŸ”§ ç‰©ç†æ˜ å°„åˆ†æ:
        #   +tx â†’ +roll â†’ -Y ä½ç§»
        #   +ty â†’ +pitch â†’ +X ä½ç§»
        # æ­£ç¡®æ§åˆ¶å¾‹:
        #   è¦è¿½è¸ª +Y (pos_err_y > 0): éœ€è¦ -tx â†’ u_tx = -Kp*err_y + Kd*vel_y - Kd_omega*ang_vel
        #   è¦è¿½è¸ª +X (pos_err_x > 0): éœ€è¦ +ty â†’ u_ty = +Kp*err_x - Kd*vel_x - Kd_omega*ang_vel
        # 
        # å‡è®¾åŸå§‹å•è½´ç¨‹åºä¸º:
        #   u_tx = Kp*pos_err_y - Kd*vel_y - Kd_omega*ang_vel_x  (åŸå§‹ç¬¦å·)
        # åˆ™éœ€è¦å–å pos_err å’Œ vel é¡¹ç³»æ•°ï¼Œä¿æŒ ang_vel é¡¹:
        #   u_tx = -Kp*pos_err_y + Kd*vel_y - Kd_omega*ang_vel_x (ä¿®æ­£å)
        
        # ğŸ”§ æ™ºèƒ½å–åï¼šå–å pos_err å’Œ vel ç›¸å…³é¡¹çš„ç³»æ•°ï¼Œä¿æŒ ang_vel é˜»å°¼é¡¹ä¸å˜
        def negate_pos_vel_coefficients(expr):
            """å–å pos_err å’Œ vel ç›¸å…³é¡¹çš„ç³»æ•°ï¼Œä¿æŒ ang_vel é˜»å°¼é¡¹ä¸å˜ã€‚"""
            if isinstance(expr, TerminalNode):
                return copy.deepcopy(expr)
            if isinstance(expr, ConstantNode):
                return copy.deepcopy(expr)
            if isinstance(expr, BinaryOpNode):
                op = expr.op
                # å¤„ç†ä¹˜æ³•ï¼šæ£€æŸ¥æ˜¯å¦æ¶‰åŠ pos_err æˆ– vel å˜é‡
                if op == '*':
                    left = expr.left
                    right = expr.right
                    involves_target = False
                    
                    # æ£€æŸ¥ left
                    if isinstance(left, TerminalNode):
                        val = str(getattr(left, 'value', ''))
                        if 'pos_err' in val or (val.startswith('vel_') and 'ang_vel' not in val):
                            involves_target = True
                    # æ£€æŸ¥ right
                    if isinstance(right, TerminalNode):
                        val = str(getattr(right, 'value', ''))
                        if 'pos_err' in val or (val.startswith('vel_') and 'ang_vel' not in val):
                            involves_target = True
                    
                    if involves_target:
                        # æ‰¾åˆ°å¸¸æ•°é¡¹å¹¶å–å
                        if isinstance(left, ConstantNode):
                            new_left = ConstantNode(-left.value, name=getattr(left, 'name', None))
                            return BinaryOpNode('*', new_left, copy.deepcopy(right))
                        elif isinstance(right, ConstantNode):
                            new_right = ConstantNode(-right.value, name=getattr(right, 'name', None))
                            return BinaryOpNode('*', copy.deepcopy(left), new_right)
                        else:
                            # æ²¡æœ‰å¸¸æ•°é¡¹ï¼Œç”¨ -1 * åŒ…è£¹
                            return BinaryOpNode('*', ConstantNode(-1.0), copy.deepcopy(expr))
                    else:
                        # ä¸æ¶‰åŠç›®æ ‡å˜é‡ï¼Œä¿æŒåŸæ ·ä½†é€’å½’å¤„ç†å­è¡¨è¾¾å¼
                        return BinaryOpNode(op, negate_pos_vel_coefficients(left), negate_pos_vel_coefficients(right))
                else:
                    # +, -, ç­‰è¿ç®—ï¼šé€’å½’å¤„ç†ä¸¤è¾¹
                    return BinaryOpNode(op, negate_pos_vel_coefficients(expr.left), negate_pos_vel_coefficients(expr.right))
            if isinstance(expr, UnaryOpNode):
                return UnaryOpNode(expr.op, negate_pos_vel_coefficients(expr.child), params=copy.deepcopy(getattr(expr, 'params', {})))
            return copy.deepcopy(expr)
        
        # ğŸ”§ ç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨åŸå§‹ u_tx è§„åˆ™ï¼Œä¸åšå–å
        # MCTS æœç´¢åº”è¯¥è‡ªå·±æ‰¾åˆ°æ­£ç¡®ç¬¦å·çš„æ§åˆ¶å¾‹
        # ğŸ”§ ä½†éœ€è¦æ·»åŠ å§¿æ€é˜»å°¼é¡¹æ¥ç¨³å®šç³»ç»Ÿï¼
        
        # æ·»åŠ  roll é˜»å°¼åˆ° u_txï¼šu_tx_final = u_tx_search - Kd_att * ang_vel_x
        att_damp_x = ConstantNode(0.15, name='c_att_damp_x')  # å§¿æ€é˜»å°¼
        if isinstance(base_action, BinaryOpNode) and getattr(base_action, 'op', None) == 'set':
            search_expr = copy.deepcopy(getattr(base_action, 'right', None))
            # u_tx = search_expr - 0.15 * ang_vel_x
            damped_tx_expr = BinaryOpNode('-', search_expr, BinaryOpNode('*', att_damp_x, TerminalNode('ang_vel_x')))
            corrected_tx_action = BinaryOpNode('set', TerminalNode('u_tx'), damped_tx_expr)
            corrected_tx_rule = {
                'condition': copy.deepcopy(base_rule.get('condition')),
                'action': [corrected_tx_action]
            }
        else:
            corrected_tx_rule = copy.deepcopy(base_rule)
        
        # æ„é€  u_ty è§„åˆ™ï¼ˆå˜é‡æ˜ å°„ yâ†’xï¼Œæ·»åŠ  pitch é˜»å°¼ï¼‰
        att_damp_y = ConstantNode(0.15, name='c_att_damp_y')  # å§¿æ€é˜»å°¼
        mirrored_rule = {
            'condition': copy.deepcopy(base_rule.get('condition')),
            'action': []
        }
        if isinstance(base_action, BinaryOpNode):
            # å˜é‡æ˜ å°„ + æ·»åŠ  pitch é˜»å°¼
            mapped_expr = map_expr(copy.deepcopy(getattr(base_action, 'right', None)))
            # u_ty = mapped_expr - 0.15 * ang_vel_y
            damped_ty_expr = BinaryOpNode('-', mapped_expr, BinaryOpNode('*', att_damp_y, TerminalNode('ang_vel_y')))
            mirrored_action = BinaryOpNode('set', TerminalNode('u_ty'), damped_ty_expr)
        else:
            mirrored_action = copy.deepcopy(base_action)
            if isinstance(mirrored_action, dict):
                if isinstance(mirrored_action.get('left'), dict):
                    mirrored_action['left']['value'] = 'u_ty'
                mirrored_action['right'] = map_expr(mirrored_action.get('right'))
        mirrored_rule['action'] = [mirrored_action]

        # å›ºå®š yaw é€šé“ PID
        yaw_p = ConstantNode(4.0, name='c_yaw_p', min_val=4.0, max_val=4.0)
        yaw_d = ConstantNode(0.8, name='c_yaw_d', min_val=0.8, max_val=0.8)
        yaw_expr = BinaryOpNode('-', BinaryOpNode('*', yaw_p, TerminalNode('err_p_yaw')), BinaryOpNode('*', yaw_d, TerminalNode('ang_vel_z')))
        yaw_rule = {
            'condition': None,
            'action': [BinaryOpNode('set', TerminalNode('u_tz'), yaw_expr)]
        }

        # å›ºå®š thrust é€šé“ä¸ºç®€å•é«˜åº¦PDæ§åˆ¶ï¼ˆé¿å…å è½æˆ–é£èµ°ï¼‰
        # ğŸ”§ Isaac Gym éœ€è¦æ›´ä½çš„å¢ç›Šï¼Œå› ä¸ºå·²ç»æœ‰ FZ_SCALE ç¼©æ”¾
        thrust_p = ConstantNode(0.5, name='c_thrust_p', min_val=0.5, max_val=0.5)
        thrust_d = ConstantNode(0.2, name='c_thrust_d', min_val=0.2, max_val=0.2)
        thrust_ff = ConstantNode(0.65, name='c_thrust_ff', min_val=0.65, max_val=0.65)
        thrust_expr = BinaryOpNode('+',
            BinaryOpNode('-', BinaryOpNode('*', thrust_p, TerminalNode('pos_err_z')), BinaryOpNode('*', thrust_d, TerminalNode('vel_z'))),
            thrust_ff
        )
        thrust_rule = {
            'condition': None,
            'action': [BinaryOpNode('set', TerminalNode('u_fz'), thrust_expr)]
        }

        # æ„é€ æ–°ç¨‹åºï¼šç”¨æ·»åŠ é˜»å°¼çš„ u_tx è§„åˆ™æ›¿æ¢åŸå§‹è§„åˆ™ï¼Œæ·»åŠ  u_ty/u_tz/u_fz
        new_program = []
        for rule in program or []:
            has_u_tx = False
            for act in rule.get('action', []) or []:
                if extract_target(act) == 'u_tx':
                    has_u_tx = True
                    break
            if has_u_tx:
                new_program.append(corrected_tx_rule)
            else:
                new_program.append(copy.deepcopy(rule))
        new_program.append(mirrored_rule)
        new_program.append(yaw_rule)
        new_program.append(thrust_rule)
        return new_program

    def _compute_prior_bonus(self, programs: List[List[Dict[str, Any]]]):
        if compute_prior_scores is None:
            return None
        if (abs(self.structure_prior_weight) < 1e-9 and
                abs(self.stability_prior_weight) < 1e-9):
            return None
        batch_size = len(programs)
        if batch_size == 0:
            return None
        structure_tensor = torch.zeros(batch_size, device=self.device)
        stability_tensor = torch.zeros(batch_size, device=self.device)
        for idx, prog in enumerate(programs):
            try:
                scores = compute_prior_scores(prog)
                structure_tensor[idx] = float(scores.get('structure', 0.0))
                stability_tensor[idx] = float(scores.get('stability', 0.0))
            except Exception:
                continue
        struct_component = self.structure_prior_weight * structure_tensor
        stab_component = self.stability_prior_weight * stability_tensor
        total = struct_component + stab_component
        return total, struct_component, stab_component

    def _reset_action_history(self, env_ids: Optional[torch.Tensor] = None) -> None:
        if self._last_safe_actions is None:
            return
        if env_ids is None:
            self._last_safe_actions.zero_()
        else:
            self._last_safe_actions[env_ids.long().to(self.device)] = 0.0

    def _partition_programs_by_constraints(self, programs: List[List[Dict[str, Any]]]) -> Tuple[List[List[Dict[str, Any]]], List[int], Dict[int, str]]:
        valid_programs: List[List[Dict[str, Any]]] = []
        valid_indices: List[int] = []
        invalid_info: Dict[int, str] = {}
        for idx, program in enumerate(programs):
            if isinstance(program, ProgramParamCandidate):
                valid_programs.append(program)
                valid_indices.append(idx)
                continue
            ok, reason = validate_program(program)
            if ok:
                valid_programs.append(program)
                valid_indices.append(idx)
            else:
                invalid_info[idx] = reason or "violates hard constraints"
        return valid_programs, valid_indices, invalid_info

    def _log_invalid_programs(self, invalid_info: Dict[int, str]) -> None:
        if not invalid_info:
            return
        for idx, reason in invalid_info.items():
            print(f"[HardConstraint] Skip program #{idx}: {reason}")

    def _merge_rewards_with_invalid(self,
                                    valid_indices: List[int],
                                    valid_rewards: List[float],
                                    invalid_info: Dict[int, str],
                                    total_count: int) -> List[float]:
        merged = [float(HARD_CONSTRAINT_PENALTY)] * total_count
        reward_iter = iter(valid_rewards)
        for idx in valid_indices:
            merged[idx] = float(next(reward_iter))
        self._log_invalid_programs(invalid_info)
        return merged

    def _metric_template(self) -> Dict[str, float]:
        # ä»…ä¿ç•™ä¸ SCG è®ºæ–‡ä¸€è‡´çš„ä¸¤é¡¹ï¼šçŠ¶æ€ä»£ä»·å’Œæ§åˆ¶ä»£ä»·
        return {
            'state_cost': 0.0,
            'action_cost': 0.0,
            'hard_constraint_violation': 0.0,
        }

    def _merge_metrics_with_invalid(self,
                                    valid_indices: List[int],
                                    rewards_train: List[float],
                                    rewards_true: List[float],
                                    metrics: List[Dict[str, float]],
                                    invalid_info: Dict[int, str],
                                    total_count: int) -> Tuple[List[float], List[float], List[Dict[str, float]]]:
        final_train = [float(HARD_CONSTRAINT_PENALTY)] * total_count
        final_true = [float(HARD_CONSTRAINT_PENALTY)] * total_count
        final_metrics = [self._metric_template() for _ in range(total_count)]
        train_iter = iter(rewards_train)
        true_iter = iter(rewards_true)
        metric_iter = iter(metrics)
        for idx in valid_indices:
            final_train[idx] = float(next(train_iter))
            final_true[idx] = float(next(true_iter))
            merged_metric = self._metric_template()
            merged_metric.update(next(metric_iter))
            merged_metric['hard_constraint_violation'] = 0.0
            final_metrics[idx] = merged_metric
        for idx in invalid_info:
            final_metrics[idx]['hard_constraint_violation'] = 1.0
        self._log_invalid_programs(invalid_info)
        return final_train, final_true, final_metrics

    def _apply_output_mad(self,
                          actions: torch.Tensor,
                          use_u_flags: List[bool],
                          batch_size: int) -> torch.Tensor:
        if actions is None or actions.shape[0] == 0:
            return actions
        # å…¨å±€åŠ¨ä½œç¼©æ”¾ï¼ˆè¯Šæ–­ç”¨é€”ï¼‰
        if abs(self.action_scale_multiplier - 1.0) > 1e-6:
            actions[:batch_size, 2:6] *= self.action_scale_multiplier

        if not self.enable_output_mad:
            return actions

        if not use_u_flags:
            return actions

        mask = torch.tensor(use_u_flags, device=self.device, dtype=torch.bool)
        if not mask.any():
            return actions

        idx = mask.nonzero(as_tuple=False).squeeze(-1)
        if idx.numel() == 0:
            return actions

        action_slice = actions[:batch_size, 2:6]
        current = action_slice[idx].clone()
        prev = self._last_safe_actions[idx]

        # Magnitude clampï¼ˆåŠ›/åŠ›çŸ©å¹…å€¼ï¼‰
        current[:, 0] = current[:, 0].clamp(self.mad_min_fz, self.mad_max_fz)
        lateral = current[:, 1:3]
        lat_norm = torch.linalg.norm(lateral, dim=1, keepdim=True)
        lat_scale = torch.clamp(self.mad_max_xy / (lat_norm + self._mad_eps), max=1.0)
        current[:, 1:3] = lateral * lat_scale
        current[:, 3] = current[:, 3].clamp(-self.mad_max_yaw, self.mad_max_yaw)

        # Delta clampï¼ˆç›¸é‚»æ­¥å˜åŒ–ç‡ï¼‰
        delta = current - prev
        delta[:, 0] = delta[:, 0].clamp(-self.mad_max_delta_fz, self.mad_max_delta_fz)
        delta[:, 1] = delta[:, 1].clamp(-self.mad_max_delta_xy, self.mad_max_delta_xy)
        delta[:, 2] = delta[:, 2].clamp(-self.mad_max_delta_xy, self.mad_max_delta_xy)
        delta[:, 3] = delta[:, 3].clamp(-self.mad_max_delta_yaw, self.mad_max_delta_yaw)
        safe = prev + delta

        action_slice[idx] = safe
        self._last_safe_actions.index_copy_(0, idx, safe)
        return actions

    def _compile_program_fast(self, program: List[Dict[str, Any]]) -> Tuple[float, float, float, float]:
        """
        ğŸš€ å¿«é€Ÿè·¯å¾„: é¢„ç¼–è¯‘å¸¸é‡ç¨‹åº (u_fz/u_tx/u_ty/u_tz = const)
        
        å¯¹äºç®€å•çš„å¸¸é‡æ§åˆ¶ç¨‹åº,ç›´æ¥æå–å¸¸é‡å€¼,é¿å…é‡å¤ASTæ±‚å€¼
        """
        fz = tx = ty = tz = 0.0
        for rule in program or []:
            if rule.get('op') == 'set':
                var = rule.get('var', '')
                expr = rule.get('expr', {})
                if expr.get('type') == 'const':
                    val = float(expr.get('value', 0.0))
                    if var == 'u_fz':
                        fz = val
                    elif var == 'u_tx':
                        tx = val
                    elif var == 'u_ty':
                        ty = val
                    elif var == 'u_tz':
                        tz = val
        # è£å‰ª
        fz = float(max(-5.0, min(5.0, fz)))
        tx = float(max(-0.02, min(0.02, tx)))
        ty = float(max(-0.02, min(0.02, ty)))
        tz = float(max(-0.01, min(0.01, tz)))
        return fz, tx, ty, tz
    
    def _extract_variables_from_node(self, node) -> set:
        """é€’å½’æå–èŠ‚ç‚¹ä¸­çš„æ‰€æœ‰å˜é‡å"""
        variables = set()
        if node is None:
            return variables
        return variables

    # ----- æ‰§è¡Œè·¯å¾„åˆ¤å®šï¼šä»…å½“ç¨‹åºä¸ºâ€œæ— æ¡ä»¶å¸¸é‡ set u_*â€æ—¶æ‰å…è®¸ UltraFast -----
    def _is_const_program(self, program) -> bool:
        """åˆ¤æ–­ç¨‹åºæ˜¯å¦ä¸ºä»…åŒ…å«æ— æ¡ä»¶å¸¸é‡ set u_* çš„å½¢å¼ã€‚

        æ»¡è¶³æ¡ä»¶ï¼š
        - æ¯æ¡è§„åˆ™ä¸º dict ä¸” op == 'set'
        - ä¸åŒ…å« condition æˆ– condition ä¸º None/False
        - expr ä¸º {'type': 'const', 'value': ...}
        åªè¦å‡ºç°ä»»æ„å¤æ‚è¡¨è¾¾å¼/æ¡ä»¶/éå¸¸é‡ï¼Œå°±è¿”å› Falseã€‚
        """
        try:
            for rule in program or []:
                if not isinstance(rule, dict):
                    return False
                if rule.get('op') != 'set':
                    return False
                if rule.get('condition') not in (None, False):
                    return False
                expr = rule.get('expr', None)
                if not isinstance(expr, dict) or expr.get('type') != 'const':
                    return False
                # å˜é‡åå¿…é¡»åœ¨å…è®¸é›†åˆå†…ï¼ˆu_fz/u_tx/u_ty/u_tzï¼‰ï¼Œå¦åˆ™å¿½ç•¥ä½†è§†ä¸ºéå¸¸é‡ç¨‹åº
                var = str(rule.get('var', ''))
                if var not in ('u_fz','u_tx','u_ty','u_tz'):
                    return False
            return True
        except Exception:
            return False

    def _all_programs_const(self, programs) -> bool:
        try:
            return all(self._is_const_program(p) for p in (programs or []))
        except Exception:
            return False
        
        # æ£€æŸ¥èŠ‚ç‚¹ç±»å‹
        node_type = type(node).__name__
        
        # TerminalNode: æ£€æŸ¥æ˜¯å¦æ˜¯å˜é‡ï¼ˆå­—ç¬¦ä¸²ï¼‰
        if node_type == 'TerminalNode':
            if hasattr(node, 'value') and isinstance(node.value, str):
                variables.add(node.value)
        
        # UnaryOpNode: é€’å½’æ£€æŸ¥å­èŠ‚ç‚¹
        elif node_type == 'UnaryOpNode':
            if hasattr(node, 'child'):
                variables.update(self._extract_variables_from_node(node.child))
        
        # BinaryOpNode: é€’å½’æ£€æŸ¥å·¦å³å­èŠ‚ç‚¹
        elif node_type == 'BinaryOpNode':
            if hasattr(node, 'left'):
                variables.update(self._extract_variables_from_node(node.left))
            if hasattr(node, 'right'):
                variables.update(self._extract_variables_from_node(node.right))
        
        return variables
    
    def _eval_program_forces(self, program: List[Dict[str, Any]], state: Dict[str, float]) -> Tuple[float, float, float, float]:
        """åœ¨ç»™å®šæ•°å€¼ state ä¸‹ï¼Œæ±‚è§£ç¨‹åºäº§ç”Ÿçš„ (fz, tx, ty, tz)ã€‚

        å½“å‰ç‰ˆæœ¬å°† DSL è¾“å‡ºè§†ä¸º *æ®‹å·®æ§åˆ¶* u_residualï¼Œæœ€ç»ˆæ§åˆ¶å¾‹ä¸º

            u_total = u_base(state) + u_residual(program, state)

        å…¶ä¸­ u_base ç”±åº•å±‚ Isaac æ§åˆ¶å™¨/segmented PID æä¾›ï¼Œæœ¬å‡½æ•°ä»…è´Ÿè´£è®¡ç®—
        u_residual éƒ¨åˆ†ï¼ˆå¹¶åšé€‚åº¦è£å‰ªï¼‰ï¼Œç†è®ºåˆ†æä¸Šå¯ä»¥å°†å…¶è§†ä¸ºæœ‰ç•Œæ‰°åŠ¨é¡¹ã€‚

        ç­–ç•¥ï¼šèšåˆæ‰€æœ‰æ»¡è¶³æ¡ä»¶çš„è§„åˆ™ï¼Œå°† set çš„å€¼ç´¯åŠ ï¼ˆå¯é€‚åº¦è£å‰ªï¼‰ã€‚
        æ³¨æ„ï¼šä»…å½“ç¨‹åºä¸ºâ€œæ— æ¡ä»¶å¸¸é‡ set u_*â€å½¢å¼æ—¶ï¼Œæ‰å¯ç”¨å­—å…¸åˆ¶å¼çš„å¿«é€Ÿè·¯å¾„ç¼“å­˜ï¼›
        å¯¹äº AST å½¢å¼ï¼ˆrule={'condition':..., 'action':[BinaryOpNode('set',...)]}ï¼‰ï¼Œå¿…é¡»èµ° AST æ±‚å€¼ï¼Œå¦åˆ™ä¼šè¢«é”™è¯¯åœ°å½“ä½œé›¶åŠ¨ä½œç¼“å­˜ã€‚
        """
        # ğŸš€ å¿«é€Ÿè·¯å¾„: ä»…åœ¨â€œæ— æ¡ä»¶å¸¸é‡ set u_*â€ç¨‹åºæ—¶å¯ç”¨
        if self.use_fast_path and self._is_const_program(program):
            try:
                # ä½¿ç”¨ç¨³å®šçš„é”®ï¼Œä»…é’ˆå¯¹å¸¸é‡ set è§„åˆ™
                prog_key = str([(r.get('op'), r.get('var'), r.get('expr')) for r in program])
                if prog_key in self._program_cache:
                    return self._program_cache[prog_key]
                # å¸¸é‡ç¼–è¯‘
                result = self._compile_program_fast(program)
                self._program_cache[prog_key] = result
                return result
            except Exception:
                # å›é€€åˆ° AST æ±‚å€¼
                pass
        
        # æ…¢é€Ÿè·¯å¾„: å®Œæ•´ASTæ±‚å€¼ï¼ˆAST-first ç¨‹åºæˆ–åŒ…å«æ¡ä»¶/éå¸¸é‡è¡¨è¾¾å¼ï¼‰
        # ä½¿ç”¨èŠ‚ç‚¹çš„ evaluate() æ–¹æ³•æ¥æ”¯æŒæ—¶é—´ç®—å­ï¼ˆema, rate, delay ç­‰ï¼‰
        fz = tx = ty = tz = 0.0
        try:
            for rule in program or []:
                # æ±‚å€¼æ¡ä»¶ï¼ˆä½¿ç”¨ evaluate è€Œä¸æ˜¯ _ast_evalï¼‰
                cond_node = rule.get('condition')
                if cond_node is not None and hasattr(cond_node, 'evaluate'):
                    cond = float(cond_node.evaluate(state))
                else:
                    cond = 1.0  # æ— æ¡ä»¶é»˜è®¤ä¸ºçœŸ
                    
                if cond > 0.0:
                    for a in rule.get('action', []) or []:
                        try:
                            if hasattr(a, 'op') and a.op == 'set' and hasattr(a, 'left') and hasattr(a.left, 'value'):
                                key = str(getattr(a.left, 'value', ''))
                                right_node = getattr(a, 'right', None)
                                # ä½¿ç”¨ evaluate() æ–¹æ³•æ¥æ”¯æŒæ—¶é—´ç®—å­
                                if right_node is not None and hasattr(right_node, 'evaluate'):
                                    val = float(right_node.evaluate(state))
                                else:
                                    val = 0.0
                                    
                                if key == 'u_fz':
                                    fz += val
                                elif key == 'u_tx':
                                    tx += val
                                elif key == 'u_ty':
                                    ty += val
                                elif key == 'u_tz':
                                    tz += val
                        except Exception:
                            continue
        except Exception:
            pass
        # é€‚åº¦è£å‰ªï¼ˆç‰©ç†åˆç†èŒƒå›´ï¼Œç»éªŒå€¼ï¼‰
        fz = float(max(-5.0, min(5.0, fz)))     # Nï¼ˆå‘ä¸Šä¸ºæ­£ï¼‰
        tx = float(max(-0.02, min(0.02, tx)))   # N*m
        ty = float(max(-0.02, min(0.02, ty)))   # N*m
        tz = float(max(-0.01, min(0.01, tz)))   # N*mï¼ˆæ°”åŠ¨åŠ›çŸ©è¾ƒå°ï¼‰
        # åº”ç”¨å…¨å±€åŠ¨ä½œç¼©æ”¾ç³»æ•°ï¼ˆè¯Šæ–­ä¸“ç”¨ï¼‰
        scale = float(self.action_scale_multiplier)
        return fz * scale, tx * scale, ty * scale, tz * scale

    def _ensure_tensor(self, value: Any) -> torch.Tensor:
        if isinstance(value, torch.Tensor):
            return value.to(self.device)
        if hasattr(value, 'to'):  # numpy array
            return torch.as_tensor(value, device=self.device)
        return torch.tensor(value, device=self.device)

    def _prepare_gpu_state_tensors(
        self,
        pos: torch.Tensor,
        vel: torch.Tensor,
        omega: torch.Tensor,
        quat: torch.Tensor,
        tgt: torch.Tensor,
        integral_states: List[Dict[str, float]],
    ) -> Tuple[Dict[str, torch.Tensor], torch.Tensor, torch.Tensor]:
        batch_size = pos.shape[0]
        tgt_view = tgt.view(1, 3)
        pos_err = tgt_view - pos
        pos_err_xy = torch.linalg.norm(pos_err[:, :2], dim=1)
        pos_err_mag = torch.linalg.norm(pos_err, dim=1)
        vel_err = torch.linalg.norm(vel, dim=1)
        ang_vel_mag = torch.linalg.norm(omega, dim=1)
        if self._gpu_executor is not None:
            rpy = self._gpu_executor.quat_to_rpy_gpu(quat)
        else:
            rpy = torch.zeros_like(pos)
        rpy_err_mag = torch.linalg.norm(rpy, dim=1)

        integral_tensor = torch.zeros((batch_size, 6), device=self.device)
        for idx in range(batch_size):
            buf = integral_states[idx]
            integral_tensor[idx, 0] = float(buf.get('err_i_x', 0.0))
            integral_tensor[idx, 1] = float(buf.get('err_i_y', 0.0))
            integral_tensor[idx, 2] = float(buf.get('err_i_z', 0.0))
            integral_tensor[idx, 3] = float(buf.get('err_i_roll', 0.0))
            integral_tensor[idx, 4] = float(buf.get('err_i_pitch', 0.0))
            integral_tensor[idx, 5] = float(buf.get('err_i_yaw', 0.0))

        state_tensors = {
            'pos_err_x': pos_err[:, 0],
            'pos_err_y': pos_err[:, 1],
            'pos_err_z': pos_err[:, 2],
            'pos_err': pos_err_mag,
            'pos_err_xy': pos_err_xy,
            'pos_err_z_abs': torch.abs(pos_err[:, 2]),
            'vel_x': vel[:, 0],
            'vel_y': vel[:, 1],
            'vel_z': vel[:, 2],
            'vel_err': vel_err,
            'err_p_roll': rpy[:, 0],
            'err_p_pitch': rpy[:, 1],
            'err_p_yaw': rpy[:, 2],
            'ang_err': rpy_err_mag,
            'rpy_err_mag': rpy_err_mag,
            'ang_vel_x': omega[:, 0],
            'ang_vel_y': omega[:, 1],
            'ang_vel_z': omega[:, 2],
            'ang_vel': ang_vel_mag,
            'ang_vel_mag': ang_vel_mag,
            'err_i_x': integral_tensor[:, 0],
            'err_i_y': integral_tensor[:, 1],
            'err_i_z': integral_tensor[:, 2],
            'err_i_roll': integral_tensor[:, 3],
            'err_i_pitch': integral_tensor[:, 4],
            'err_i_yaw': integral_tensor[:, 5],
            'err_d_x': -vel[:, 0],
            'err_d_y': -vel[:, 1],
            'err_d_z': -vel[:, 2],
            'err_d_roll': -omega[:, 0],
            'err_d_pitch': -omega[:, 1],
            'err_d_yaw': -omega[:, 2],
        }
        return state_tensors, pos_err, rpy

    def _update_integral_states(
        self,
        integral_states: List[Dict[str, float]],
        pos_err: torch.Tensor,
        rpy: torch.Tensor,
        done_mask: torch.Tensor,
        dt: float,
    ) -> None:
        pos_err_det = pos_err.detach()
        rpy_det = rpy.detach()
        done = done_mask.detach().bool()
        for idx, buf in enumerate(integral_states):
            if done[idx]:
                continue
            buf['err_i_x'] = float(buf.get('err_i_x', 0.0) + pos_err_det[idx, 0].item() * dt)
            buf['err_i_y'] = float(buf.get('err_i_y', 0.0) + pos_err_det[idx, 1].item() * dt)
            buf['err_i_z'] = float(buf.get('err_i_z', 0.0) + pos_err_det[idx, 2].item() * dt)
            buf['err_i_roll'] = float(buf.get('err_i_roll', 0.0) + rpy_det[idx, 0].item() * dt)
            buf['err_i_pitch'] = float(buf.get('err_i_pitch', 0.0) + rpy_det[idx, 1].item() * dt)
            buf['err_i_yaw'] = float(buf.get('err_i_yaw', 0.0) + rpy_det[idx, 2].item() * dt)

    def _apply_pid_controllers(
        self,
        controllers: List[Any],
        use_u_flags: List[bool],
        actions: torch.Tensor,
        step: int,
        pos,
        quat,
        vel,
        omega,
        tgt_np,
        integral_states: List[Dict[str, float]],
        ever_nonzero: torch.Tensor,
        debug_enabled: bool,
    ) -> None:
        if not controllers:
            return
        dt = float(getattr(self, '_control_dt', 1.0 / 48.0))
        import numpy as _np

        for i, ctrl in enumerate(controllers):
            if use_u_flags[i] or ctrl is None:
                continue
            try:
                pos_i = pos[i]
                quat_i = quat[i]
                vel_i = vel[i]
                omega_i = omega[i]
                if isinstance(pos_i, torch.Tensor):
                    pos_i = pos_i.detach().cpu().numpy()
                if isinstance(quat_i, torch.Tensor):
                    quat_i = quat_i.detach().cpu().numpy()
                if isinstance(vel_i, torch.Tensor):
                    vel_i = vel_i.detach().cpu().numpy()
                if isinstance(omega_i, torch.Tensor):
                    omega_i = omega_i.detach().cpu().numpy()
                ctrl_actions = ctrl.step(
                    time_step=step,
                    pos_x=float(pos_i[0]),
                    pos_y=float(pos_i[1]),
                    pos_z=float(pos_i[2]),
                    target_x=float(tgt_np[0]),
                    target_y=float(tgt_np[1]),
                    target_z=float(tgt_np[2]),
                )
                actions[i, 0] = float(ctrl_actions.get('fx', 0.0))
                actions[i, 1] = float(ctrl_actions.get('fy', 0.0))
                actions[i, 2] = float(ctrl_actions.get('fz', 0.0))
                actions[i, 3] = float(ctrl_actions.get('tx', 0.0))
                actions[i, 4] = float(ctrl_actions.get('ty', 0.0))
                actions[i, 5] = float(ctrl_actions.get('tz', 0.0))
                if self.strict_no_prior:
                    nz = (abs(actions[i, 2]) > 1e-6) or (abs(actions[i, 3]) > 1e-8) or \
                         (abs(actions[i, 4]) > 1e-8) or (abs(actions[i, 5]) > 1e-8)
                    if nz:
                        ever_nonzero[i] = True
                pe = _np.asarray(tgt_np, dtype=_np.float32) - _np.asarray(pos_i, dtype=_np.float32)
                integral_states[i]['err_i_x'] += float(pe[0]) * dt
                integral_states[i]['err_i_y'] += float(pe[1]) * dt
                integral_states[i]['err_i_z'] += float(pe[2]) * dt
            except Exception as exc:
                if debug_enabled:
                    print(f"[DebugReward] Controller step failed for env {i}: {exc}")
                continue

    # ---------------------- èµ„æºæ¸…ç† ----------------------
    def close(self):
        """å…³é—­åº•å±‚ç¯å¢ƒæ± ï¼Œé‡Šæ”¾GPU/PhysXèµ„æºï¼ˆä¾›åŸºå‡†æˆ–å¤šæ¬¡åˆå§‹åŒ–åœºæ™¯ä½¿ç”¨ï¼‰ã€‚"""
        try:
            if self._isaac_env_pool is not None:
                try:
                    self._isaac_env_pool.close()
                except Exception:
                    pass
                self._isaac_env_pool = None
        except Exception:
            pass

    def _rpm_to_forces_local(self, rpm: np.ndarray) -> Tuple[float, float, float, float]:
        """å°† 4 ç”µæœº RPM è½¬æ¢ä¸º (fz, tx, ty, tz)ï¼Œç³»æ•°éœ€ä¸ç¯å¢ƒä¸€è‡´ã€‚"""
        KF = 2.8e-08
        KM = 1.1e-10
        L = 0.046
        omega = np.asarray(rpm, dtype=np.float64) * (2.0 * np.pi / 60.0)
        T = KF * (omega ** 2)
        fz = float(np.sum(T))
        tx = float(L * (T[1] - T[3]))
        ty = float(L * (T[2] - T[0]))
        tz = float(KM * (omega[0] ** 2 - omega[1] ** 2 + omega[2] ** 2 - omega[3] ** 2))
        return fz, tx, ty, tz

    def _target_pos(self, t: float) -> np.ndarray:
        """æ ¹æ® trajectory_config è®¡ç®—æœŸæœ›ä½ç½® [x,y,z]"""
        cfg = self.trajectory_config or {}
        tp = cfg.get('type', 'figure8')
        params = cfg.get('params', {})
        # æ”¯æŒ initial_xyz / center ä¸¤ç§é”®å
        init = np.array(cfg.get('initial_xyz', params.get('center', [0.0, 0.0, 1.0])), dtype=np.float32)
        if tp == 'hover':
            # æ‚¬åœæ¨¡å¼ï¼šç›®æ ‡ç‚¹å›ºå®šä¸åŠ¨
            return init
        elif tp == 'circle':
            # æ”¯æŒ R / radius ä¸¤ç§é”®å
            R = float(params.get('R', params.get('radius', 0.9))); period = float(params.get('period', 10.0))
            w = 2.0 * np.pi / max(1e-6, period)
            x = R * np.cos(w * t); y = R * np.sin(w * t); z = 0.0
            return init + np.array([x, y, z], dtype=np.float32)
        elif tp == 'helix':
            R = float(params.get('R', 0.7)); period = float(params.get('period', 10.0)); vz = float(params.get('v_z', 0.15))
            w = 2.0 * np.pi / max(1e-6, period)
            x = R * np.cos(w * t); y = R * np.sin(w * t); z = vz * t
            return init + np.array([x, y, z], dtype=np.float32)
        elif tp == 'square':
            scale = float(params.get('scale', params.get('side', 0.8)))
            period = float(params.get('period', 8.0))
            plane = str(params.get('plane', 'xy')).lower()
            axis = {'x': 0, 'y': 1, 'z': 2}
            if len(plane) == 2 and plane[0] != plane[1]:
                ia = axis.get(plane[0], 0); ib = axis.get(plane[1], 1)
            else:
                ia, ib = 0, 1
            seg_period = max(period / 4.0, 1e-6)
            traverse_speed = scale / seg_period
            cycle = 0.0
            if period > 0:
                cycle = float(np.fmod(t, period))
            seg_idx = int(cycle // seg_period) % 4
            seg_time = cycle - seg_idx * seg_period
            seg_pos = traverse_speed * seg_time
            coord_a = 0.0
            coord_b = 0.0
            if seg_idx == 0:
                coord_a = 0.0
                coord_b = seg_pos
            elif seg_idx == 1:
                coord_a = -seg_pos
                coord_b = scale
            elif seg_idx == 2:
                coord_a = -scale
                coord_b = scale - seg_pos
            else:
                coord_a = -scale + seg_pos
                coord_b = 0.0
            delta = np.zeros(3, dtype=np.float32)
            delta[ia] = coord_a
            delta[ib] = coord_b
            return init + delta
        else:  # figure8
            # ä¸¥æ ¼å¯¹é½ safe-control-gym quadrotor_3D_track: åœ¨ç»™å®šå¹³é¢å†…ç”» 8 å­—
            A = float(params.get('A', 1.0))
            B = float(params.get('B', 1.0))
            period = float(params.get('period', 5.0))
            # ğŸ”§ é»˜è®¤ xy å¹³é¢ï¼šu_tx æ§åˆ¶ Yï¼Œu_ty æ§åˆ¶ Xï¼ŒåŒ¹é…å•è½´æœç´¢
            plane = str(params.get('plane', 'xy')).lower()
            w = 2.0 * np.pi / max(1e-6, period)
            a_coord = A * np.sin(w * t)
            b_coord = B * np.sin(w * t) * np.cos(w * t)

            # plane é€‰æ‹©å“ªä¸ªåæ ‡è½´æ‰¿è½½ 8 å­—è½¨è¿¹ï¼ˆä¾‹å¦‚ xzï¼‰
            axis = {'x': 0, 'y': 1, 'z': 2}
            if len(plane) == 2 and plane[0] != plane[1]:
                ia = axis.get(plane[0], 0)
                ib = axis.get(plane[1], 2)
            else:
                ia, ib = 0, 1  # å›é€€ xy

            delta = np.zeros(3, dtype=np.float32)
            delta[ia] = a_coord
            delta[ib] = b_coord
            return init + delta
    
    def evaluate_batch(self, programs: List[List[Dict[str, Any]]]) -> List[float]:
        """
        ä½¿ç”¨Isaac Gymæ‰¹é‡è¯„ä¼°ç¨‹åº
        
        Args:
            programs: ç¨‹åºåˆ—è¡¨ï¼Œæ¯ä¸ªç¨‹åºæ˜¯è§„åˆ™åˆ—è¡¨
        
        Returns:
            rewards: æ¯ä¸ªç¨‹åºçš„å¥–åŠ±ï¼ˆè´Ÿå€¼=è¯¯å·®ï¼Œè¶Šå¤§è¶Šå¥½ï¼‰
        """
        total_requested = len(programs)

        # å…ˆæŒ‰ç¡¬çº¦æŸè¿‡æ»¤
        valid_programs, valid_indices, invalid_info = self._partition_programs_by_constraints(programs)
        if not valid_programs:
            self._log_invalid_programs(invalid_info)
            return [float(HARD_CONSTRAINT_PENALTY)] * total_requested
        programs = valid_programs

        # åˆå§‹åŒ–ç¯å¢ƒæ± ï¼ˆåœ¨BOä¹‹å‰ï¼Œé¿å…BOç¬¬1è½®è§¦å‘åˆå§‹åŒ–å¼€é”€ï¼‰
        if self._isaac_env_pool is None:
            self._init_isaac_gym_pool()

        # ğŸ”¥ è´å¶æ–¯ä¼˜åŒ–è°ƒå‚ï¼ˆğŸš€ æ‰¹é‡å¹¶è¡Œä¼˜åŒ–ï¼šæ‰€æœ‰ç¨‹åºçš„BOå€™é€‰å‚æ•°ä¸€èµ·è¯„ä¼°ï¼‰
        if self.enable_bayesian_tuning:
            programs = self._batch_tune_programs_with_bo(programs)

        # å»¶è¿Ÿå¯¼å…¥ torchï¼šç¡®ä¿åœ¨ isaacgym æˆåŠŸå¯¼å…¥ä¹‹å
        import torch  # type: ignore

        # è¯„ä¼°ç¼“å­˜ï¼šä¸ºæ¯ä¸ªæœ‰æ•ˆç¨‹åºç”Ÿæˆé”®ï¼Œæ‹†åˆ†ç¼“å­˜å‘½ä¸­ä¸å¾…è¯„ä¼°å­é›†
        cache_keys: List[Optional[str]] = []
        cached_rewards: Dict[int, float] = {}
        indices_to_eval: List[int] = []
        for idx, prog in enumerate(programs):
            try:
                key = self._program_eval_key(prog)
            except Exception:
                key = None
            cache_keys.append(key)
            if key is not None and key in self._eval_cache:
                cached_rewards[idx] = float(self._eval_cache[key])
            else:
                indices_to_eval.append(idx)

        # ğŸ‘€ è½»é‡çº§ç¼“å­˜å‘½ä¸­ç‡æ—¥å¿—ï¼ˆä¸»è¦ç”¨äºè§‚å¯Ÿ BO å†…éƒ¨å¤ç”¨æƒ…å†µï¼‰
        num_valid = len(programs)
        num_cached = len(cached_rewards)
        num_new = len(indices_to_eval)
        if num_valid > 0 and (num_cached > 0 or num_new > 0):
            hit_rate = num_cached / float(num_valid)
            print(f"[EvalCache] valid={num_valid}, cached={num_cached}, new={num_new}, hit={hit_rate:.3f}")

        if len(indices_to_eval) == 0:
            # å…¨éƒ¨å‘½ä¸­ç¼“å­˜ï¼Œç›´æ¥åˆå¹¶æ— æ•ˆç¨‹åºå¹¶è¿”å›
            cached_list = [cached_rewards[i] for i in range(len(programs))]
            return self._merge_rewards_with_invalid(valid_indices, cached_list, invalid_info, total_requested)

        # æ„é€ å¾…çœŸå®è¯„ä¼°çš„å­åˆ—è¡¨
        programs_to_eval = [programs[i] for i in indices_to_eval]

        # å¯¹ä»éœ€çœŸå®ä»¿çœŸçš„å€™é€‰ï¼Œå»¶è¿Ÿæ„é€ å®é™… DSL ç¨‹åº
        programs_to_eval = [
            prog.materialize() if isinstance(prog, ProgramParamCandidate) else prog
            for prog in programs_to_eval
        ]

        # ğŸ”§ é•œåƒå±•å¼€ï¼šå¦‚æœç¨‹åºåªæœ‰ u_txï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆ u_tyï¼ˆå–åï¼‰åŠ yaw/thrust ç¨³å®šå™¨
        programs_to_eval = [
            self._mirror_expand_single_axis_program(prog) for prog in programs_to_eval
        ]

        num_programs_original = len(programs_to_eval)
        
        # ğŸ”§ æ‰©å±•replicas: æ¯ä¸ªç¨‹åºå¤åˆ¶ replicas_per_program æ¬¡
        if self.replicas_per_program > 1:
            programs_expanded = []
            for prog in programs_to_eval:
                programs_expanded.extend([prog] * self.replicas_per_program)
            programs_to_eval = programs_expanded

        num_programs = len(programs_to_eval)
        rewards = []
        
        start_time = time.time()
        
        # åˆ†æ‰¹è¯„ä¼°ï¼ˆè€ƒè™‘replicas: æ¯æ‰¹æœ€å¤š isaac_num_envs // replicas_per_program ä¸ªç¨‹åºï¼‰
        programs_per_batch = max(1, self.isaac_num_envs // self.replicas_per_program)
        
        for batch_start in range(0, num_programs, programs_per_batch):
            batch_end = min(batch_start + programs_per_batch, num_programs)
            batch_programs = programs_to_eval[batch_start:batch_end]
            batch_size = len(batch_programs)

            
            # âœ… ç¡®å®šæ€§è¯„ä¼°ï¼šå¼ºåˆ¶æ¯æ‰¹è¯„ä¼°å‰å®Œå…¨é‡ç½®ç¯å¢ƒï¼ˆç¡®ä¿ç›¸åŒç¨‹åºå¾—åˆ°ç›¸åŒå¥–åŠ±ï¼‰
            # åŸå› ï¼šç¯å¢ƒæ± å¤ç”¨ä¼šå¯¼è‡´æ–°ç¨‹åºä»ä¸Šä¸€ä¸ªç¨‹åºçš„ç»“æŸçŠ¶æ€å¼€å§‹ï¼Œå¼•å…¥ä¸å¯æ§çš„éšæœºæ€§
            # ä¿®å¤ï¼šæ°¸è¿œæ‰§è¡Œ reset()ï¼Œä¿è¯æ¯ä¸ªç¨‹åºéƒ½ä»å›ºå®šåˆå§‹çŠ¶æ€ (0,0,h) å¼€å§‹è¯„ä¼°
            
            # è½»é‡çº§ç¡®å®šæ€§é‡ç½®ï¼šä¿ç•™ç¯å¢ƒæ± ï¼Œåªé‡ç½®çŠ¶æ€
            # ğŸ”§ è®¡ç®—åˆå§‹ä½ç½®ï¼šç­‰äº t=0 æ—¶çš„ç›®æ ‡ä½ç½®
            initial_pos_np = self._target_pos(0.0)
            initial_pos_tensor = torch.tensor(initial_pos_np, device=self.device, dtype=torch.float32)
            if not self._envs_ready:
                # é¦–æ¬¡ï¼šå®Œæ•´åˆå§‹åŒ–ç¯å¢ƒæ± 
                # æ‰©å±• initial_pos ä¸º [num_envs, 3]
                initial_pos_batch = initial_pos_tensor.unsqueeze(0).expand(self.isaac_num_envs, -1).clone()
                obs = self._isaac_env_pool.reset(initial_pos=initial_pos_batch)
                self._envs_ready = True
                self._last_reset_size = self.isaac_num_envs
                self._reset_action_history()
            else:
                # åç»­ï¼šåªé‡ç½®å‰ batch_size ä¸ªç¯å¢ƒåˆ°åˆå§‹çŠ¶æ€ (å¿«é€Ÿï¼Œæ— é‡å»ºå¼€é”€)
                env_ids_to_reset = torch.arange(batch_size, dtype=torch.long, device=self.device)
                initial_pos_batch = initial_pos_tensor.unsqueeze(0).expand(batch_size, -1).clone()
                obs = self._isaac_env_pool.reset(env_ids=env_ids_to_reset, initial_pos=initial_pos_batch)
                self._reset_action_history(env_ids_to_reset)
            
            # è¿è¡Œä»¿çœŸï¼ˆç¯å¢ƒæ± å¤§å°å¯èƒ½å¤§äºæœ¬æ‰¹å¤§å°ï¼ŒæŒ‰å‰ batch_size ä¸ªæ§½ä½ä½¿ç”¨ï¼‰
            total_rewards = torch.zeros(self.isaac_num_envs, device=self.device)
            done_flags = torch.zeros(self.isaac_num_envs, dtype=torch.bool, device=self.device)
            # ä¸ºå½“å‰æ‰¹æ¬¡åˆ›å»ºä¸“å± done æ ‡å¿—å’Œ stepwise å¥–åŠ±è®¡ç®—å™¨ï¼ˆåŒ¹é… batch_sizeï¼‰
            done_flags_batch = torch.zeros(batch_size, dtype=torch.bool, device=self.device)
            if self._step_reward_calc is not None:
                try:
                    weights, ks = get_reward_profile(self.reward_profile) if get_reward_profile else ({}, {})
                    self._step_reward_calc = StepwiseRewardCalculator(weights, ks, dt=self._step_dt, num_envs=batch_size, device=self.device)
                except Exception:
                    self._step_reward_calc = None
            
            # ğŸ”¥ ä¸ºå½“å‰æ‰¹æ¬¡é‡å»º SCG reward calculatorï¼ˆåŒ¹é… batch_sizeï¼‰
            if self.use_scg_exact_reward and self._scg_reward_calc is not None:
                from .reward_scg_exact import SCGExactRewardCalculator
                self._scg_reward_calc = SCGExactRewardCalculator(
                    num_envs=batch_size,
                    device=self.device,
                    state_weights=self._scg_reward_calc.Q,
                    action_weight=self._scg_reward_calc.R,
                )
            # è®°å½•æ¯ä¸ªç¯å¢ƒç´¯è®¡äº†å¤šå°‘ä¸ªæœ‰æ•ˆæ­¥ï¼ˆç”¨äº mean å½’çº¦ï¼‰
            steps_count = torch.zeros(self.isaac_num_envs, device=self.device)
            # è®°å½•æ˜¯å¦æ›¾ç»äº§ç”Ÿè¿‡éé›¶åŠ¨ä½œï¼ˆä»…é’ˆå¯¹å‰ batch_sizeï¼‰
            ever_nonzero = torch.zeros(batch_size, dtype=torch.bool, device=self.device)
            
            # åˆå§‹åŒ–ç§¯åˆ†çŠ¶æ€ï¼ˆæŒä¹…åŒ–è·¨æ­¥ï¼‰
            integral_states = [
                {
                    'err_i_x': 0.0, 'err_i_y': 0.0, 'err_i_z': 0.0,
                    'err_i_roll': 0.0, 'err_i_pitch': 0.0, 'err_i_yaw': 0.0
                }
                for i in range(batch_size)
            ]

            # è°ƒè¯•å¼€å…³ï¼ˆéœ€å°½æ—©å£°æ˜ï¼Œé¿å…æœªå®šä¹‰å¼•ç”¨ï¼‰
            debug_enabled = bool(int(os.getenv('DEBUG_STEPWISE', '0')))

            # æ‰€æœ‰ç¨‹åºç»Ÿä¸€ä½¿ç”¨ u_* ç›´æ¥è¾“å‡ºè·¯å¾„ï¼ˆä¸å†ä¾èµ– PID å°è£…ï¼‰
            controllers = [None for _ in range(batch_size)]
            use_u_flags = [True for _ in range(batch_size)]  # å…¨éƒ¨ä½¿ç”¨ç›´æ¥åŠ›/åŠ›çŸ©è¾“å‡º
            gpu_batch_token = None
            
            # ğŸ”§ é‡ç½®æ¯ä¸ªç¨‹åºçš„æ—¶é—´ç®—å­çŠ¶æ€ï¼ˆema/delay/diff/rateï¼‰
            # ç¡®ä¿æ¯æ¬¡è¯„ä¼°ä»é›¶çŠ¶æ€å¼€å§‹ï¼Œä¿è¯è®­ç»ƒä¸æµ‹è¯•ä¸€è‡´æ€§
            if reset_program_state is not None:
                for prog in batch_programs:
                    reset_program_state(prog)
            
            if debug_enabled:
                print("[DebugReward] All programs use direct u_* (force/torque) output path")

            # ğŸ”§ ä¿®å¤: gpu_batch_token åˆå§‹åŒ–åº”è¯¥åœ¨ debug_enabled æ¡ä»¶å¤–
            if (self._gpu_executor is not None and self.use_gpu_expression_executor and any(use_u_flags)):
                try:
                    gpu_batch_token = self._gpu_executor.prepare_batch(batch_programs)
                except Exception as gpu_batch_exc:
                    gpu_batch_token = None
                    if debug_enabled:
                        print(f"[GPUExecutor] âš ï¸ æ‰¹æ¬¡ç»‘å®šå¤±è´¥ï¼Œä½¿ç”¨CPUè·¯å¾„: {gpu_batch_exc}")

            # æ§åˆ¶æ­¥æ•°ï¼ˆä»¥æ§åˆ¶é¢‘ç‡è®¡ï¼Œä¸å†æŒ‰ç‰©ç†é¢‘ç‡ï¼‰
            max_steps = int(self.duration * float(getattr(self, '_control_freq', 48)))
            min_steps = int(max_steps * self.min_steps_frac)
            
            # è°ƒè¯•è¾…åŠ©ï¼šè®°å½•é¦–æœ«ä½ç½®è¯¯å·®ï¼ˆä»…åœ¨å¼€å¯ DEBUG_STEPWISE æ—¶ï¼‰
            first_pos_err = None
            last_pos_err = None
            
            # ç»Ÿè®¡æ•´ä¸ª Episode çš„åŠ¨ä½œå¹…åº¦
            episode_stats = {
                'sum_fz': 0.0, 'max_fz': 0.0,
                'sum_tx': 0.0, 'max_tx': 0.0,
                'count': 0
            }

            # é¢„å…ˆåˆ†é…åŠ¨ä½œå¼ é‡ï¼Œå¾ªç¯å†…å¤ç”¨ä»¥å‡å°‘åå¤åˆ†é…
            actions = torch.zeros((self.isaac_num_envs, 6), device=self.device)

            for step in range(max_steps):
                # è®¡ç®—ç›®æ ‡ç‚¹ï¼ˆæ‰€æœ‰ env ç›¸åŒç›®æ ‡è½¨è¿¹ï¼Œä½¿ç”¨åŠ¨æ€è½¨è¿¹è€Œä¸æ˜¯é™æ€ cfg.targetï¼‰
                t = step * float(getattr(self, '_control_dt', 1.0/48.0))
                tgt_np = self._target_pos(t)  # numpy array [3]
                tgt_tensor = torch.tensor(tgt_np, device=self.device, dtype=torch.float32)

                # ç”ŸæˆåŠ¨ä½œï¼ˆç»Ÿä¸€ä¸º [fx,fy,fz,tx,ty,tz] 6 ç»´æ ¼å¼ï¼Œä¾¿äºæ··ç”¨ï¼‰
                actions.zero_()
                pos = obs['position'][:batch_size]
                quat = obs['orientation'][:batch_size]
                vel = obs['velocity'][:batch_size]
                omega = obs['angular_velocity'][:batch_size]
                gpu_actions_applied = False
                if gpu_batch_token is not None and (not hasattr(self, '_cuda_executor') or self._cuda_executor is None or not hasattr(self, '_compiled_forces_gpu')):
                    try:
                        pos_tensor = self._ensure_tensor(pos)
                        vel_tensor = self._ensure_tensor(vel)
                        omega_tensor = self._ensure_tensor(omega)
                        quat_tensor = self._ensure_tensor(quat)
                        gpu_use_mask = torch.tensor(use_u_flags, dtype=torch.bool, device=self.device)
                        if self._use_gpu_control_loop:
                            gpu_outputs, pos_err_tensor, rpy_tensor = self._gpu_executor.evaluate_from_raw_obs(
                                gpu_batch_token,
                                pos_tensor,
                                vel_tensor,
                                omega_tensor,
                                quat_tensor,
                                tgt_tensor,
                                integral_states,
                                gpu_use_mask,
                                active_mask=(~done_flags_batch)
                            )
                        else:
                            state_tensors, pos_err_tensor, rpy_tensor = self._prepare_gpu_state_tensors(
                                pos_tensor, vel_tensor, omega_tensor, quat_tensor, tgt_tensor, integral_states
                            )
                            gpu_outputs = self._gpu_executor.evaluate(
                                gpu_batch_token,
                                state_tensors,
                                gpu_use_mask,
                                active_mask=(~done_flags_batch)
                            )
                        actions[:batch_size, 2:6] = torch.where(
                            gpu_use_mask.unsqueeze(-1),
                            gpu_outputs,
                            actions[:batch_size, 2:6]
                        )
                        if self.strict_no_prior:
                            nz_mask = (
                                gpu_outputs[:, 0].abs() > 1e-6
                            ) | (
                                gpu_outputs[:, 1].abs() > 1e-8
                            ) | (
                                gpu_outputs[:, 2].abs() > 1e-8
                            ) | (
                                gpu_outputs[:, 3].abs() > 1e-8
                            )
                            ever_nonzero |= (gpu_use_mask & nz_mask)
                        self._update_integral_states(
                            integral_states,
                            pos_err_tensor,
                            rpy_tensor,
                            done_flags_batch,
                            float(getattr(self, '_control_dt', 1.0 / 48.0))
                        )
                        if not self.strict_no_prior:
                            self._apply_pid_controllers(
                                controllers,
                                use_u_flags,
                                actions,
                                step,
                                pos_tensor,
                                quat_tensor,
                                vel_tensor,
                                omega_tensor,
                                tgt_np,
                                integral_states,
                                ever_nonzero,
                                debug_enabled,
                            )
                        gpu_actions_applied = True
                    except Exception as gpu_step_exc:
                        gpu_actions_applied = False
                        if debug_enabled:
                            print(f"[GPUExecutor] âš ï¸ step{step} å›é€€CPU: {gpu_step_exc}")
                
                # ğŸš€ğŸš€ğŸš€ CUDAè¶…é«˜æ€§èƒ½è·¯å¾„: å®Œå…¨GPUæ‰§è¡Œ (step 0æ—¶åˆå§‹åŒ–)
                if not gpu_actions_applied and self.use_fast_path and step == 0:
                    try:
                        # ä¼˜å…ˆå°è¯•CUDAæ‰§è¡Œå™¨ (é›¶CPUä¼ è¾“)
                        if not hasattr(self, '_cuda_executor_initialized'):
                            self._cuda_executor_initialized = True
                            try:
                                from .cuda_program_executor import CUDAProgramExecutor
                                self._cuda_executor = CUDAProgramExecutor(device=str(self.device))
                                print(f"[CUDA] ğŸš€ åˆå§‹åŒ–CUDAæ‰§è¡Œå™¨ (è®¾å¤‡: {self.device})")
                            except Exception as e:
                                print(f"[CUDA] âš ï¸ CUDAæ‰§è¡Œå™¨ä¸å¯ç”¨: {e}")
                                self._cuda_executor = None
                        
                        # CUDAç¼–è¯‘
                        if self._cuda_executor is not None and not hasattr(self, '_compiled_forces_gpu'):
                            if self._all_programs_const(batch_programs):
                                t0 = time.time()
                                self._compiled_forces_gpu = self._cuda_executor.compile_constant_programs(batch_programs)
                                compile_time = (time.time() - t0) * 1000
                                
                                if self._compiled_forces_gpu is not None:
                                    print(f"[CUDA] âœ… GPUé¢„ç¼–è¯‘{len(batch_programs)}ç¨‹åº ({compile_time:.2f}ms)")
                                    print(f"[CUDA] ğŸ’¾ Forces shape: {self._compiled_forces_gpu.shape}, device: {self._compiled_forces_gpu.device}")
                                else:
                                    print(f"[CUDA] âš ï¸ åŒ…å«éå¸¸é‡ç¨‹åºï¼Œå›é€€åˆ°CPUè·¯å¾„")
                                    self._cuda_executor = None
                            else:
                                print(f"[CUDA] âš ï¸ å­˜åœ¨æ¡ä»¶/è¡¨è¾¾å¼ç¨‹åºï¼Œå›é€€åˆ°CPUè·¯å¾„")
                                self._cuda_executor = None
                    except Exception as e:
                        print(f"[CUDA] âŒ ç¼–è¯‘å¤±è´¥: {e}, å›é€€åˆ°CPUè·¯å¾„")
                        self._cuda_executor = None
                
                # ğŸš€ğŸš€ è¶…é«˜æ€§èƒ½è·¯å¾„: å®Œå…¨å‘é‡åŒ– + JIT (CPU fallback)
                if not gpu_actions_applied and self.use_fast_path and self._ultra_executor is not None and step == 0:
                    # åªæœ‰å½“CUDAä¸å¯ç”¨æ—¶æ‰ä½¿ç”¨CPU UltraFast
                    if not hasattr(self, '_cuda_executor') or self._cuda_executor is None:
                        # é¦–æ¬¡æ­¥éª¤: é¢„ç¼–è¯‘æ‰€æœ‰ç¨‹åº (åªåšä¸€æ¬¡)
                        try:
                            if not hasattr(self, '_compiled_forces'):
                                # ä»…å½“æ‰€æœ‰ç¨‹åºçš†ä¸ºâ€œæ— æ¡ä»¶å¸¸é‡ set u_*â€æ—¶ï¼Œæ‰å¯ç”¨ UltraFast
                                if self._all_programs_const(batch_programs):
                                    self._compiled_forces = self._ultra_executor.compile_programs(batch_programs)
                                    print(f"[UltraFast CPU] âœ… é¢„ç¼–è¯‘{len(batch_programs)}ç¨‹åº â†’ ç¼“å­˜{len(self._ultra_executor.program_cache)}ä¸ªå”¯ä¸€ç¨‹åº")
                                # è‹¥å…¨éƒ¨å¸¸é‡ç»“æœå‡ ä¹ä¸ºé›¶ï¼Œä¸”ä¸¥æ ¼æ— å…ˆéªŒï¼Œåˆ™æ”¾å¼ƒ UltraFast ä»¥é¿å…é•¿æœŸé›¶åŠ¨ä½œé€€åŒ–
                                try:
                                    import numpy as _np
                                    if _np.all(_np.abs(self._compiled_forces) < 1e-8) and self.strict_no_prior:
                                        print("[UltraFast] âš ï¸ å…¨å¸¸é‡ä¸ºé›¶ï¼Œç¦ç”¨UltraFastä»¥é¿å…é›¶åŠ¨ä½œé€€åŒ–")
                                        self._ultra_executor = None
                                        if hasattr(self, '_compiled_forces'):
                                            delattr(self, '_compiled_forces')
                                except Exception:
                                    pass
                            else:
                                # å­˜åœ¨æ¡ä»¶/éå¸¸é‡è¡¨è¾¾å¼ï¼šç¦ç”¨ UltraFastï¼Œå›é€€åˆ°é€æ­¥ASTè¯„ä¼°ï¼Œç¡®ä¿åŠ¨ä½œä¾èµ–çŠ¶æ€
                                self._ultra_executor = None
                        except Exception as e:
                            print(f"[UltraFast] âš ï¸ é¢„ç¼–è¯‘å¤±è´¥: {e}, å›é€€åˆ°æ ‡å‡†å¿«é€Ÿè·¯å¾„")
                            self._ultra_executor = None
                
                # ğŸš€ğŸš€ğŸš€ å®Œå…¨GPUè·¯å¾„: é›¶CPUä¼ è¾“ (CUDAåŠ é€Ÿ)
                if not gpu_actions_applied and self.use_fast_path and hasattr(self, '_cuda_executor') and self._cuda_executor is not None:
                    try:
                        # 100% GPUæ‰§è¡Œ: æ— CPUâ†”GPUä¼ è¾“!
                        if hasattr(self, '_compiled_forces_gpu'):
                            # âœ… CUDAæ‰§è¡Œå™¨å·²ç»è¿”å›æ­£ç¡®å¤§å°çš„tensor [batch_size, 6]
                            actions[:batch_size] = self._cuda_executor.apply_constant_forces_vectorized(
                                self._compiled_forces_gpu,
                                batch_size,
                                self.isaac_num_envs
                            )
                    except Exception as e:
                        print(f"[CUDA Fast Path] âš ï¸ GPUæ‰§è¡Œå¤±è´¥: {e}, å›é€€åˆ°CPUè·¯å¾„")
                        self._cuda_executor = None
                
                # ğŸš€ å¿«é€Ÿè·¯å¾„: æ‰¹é‡å¤„ç† u_* è·¯å¾„ (CPU fallback)
                if not gpu_actions_applied and self.use_fast_path and (not hasattr(self, '_cuda_executor') or self._cuda_executor is None):
                    # é¢„å…ˆå¯¼å…¥scipyï¼ˆé¿å…å¾ªç¯å†…é‡å¤å¯¼å…¥ï¼‰
                    try:
                        from scipy.spatial.transform import Rotation
                    except ImportError:
                        Rotation = None
                    
                    # æ‰¹é‡è®¡ç®—ä½ç½®è¯¯å·® [batch_size, 3]
                    # æ³¨æ„: Isaac Gymçš„obså¯èƒ½æ˜¯torch tensoræˆ–numpy array
                    if isinstance(pos, torch.Tensor):
                        pos_np = pos.cpu().numpy()
                        quat_np = quat.cpu().numpy()
                        vel_np = vel.cpu().numpy()
                        omega_np = omega.cpu().numpy()
                    else:
                        pos_np = np.asarray(pos)
                        quat_np = np.asarray(quat)
                        vel_np = np.asarray(vel)
                        omega_np = np.asarray(omega)
                    
                    tgt_batch = np.tile(tgt_np, (batch_size, 1))  # [batch_size, 3]
                    pe_batch = tgt_batch - pos_np  # [batch_size, 3]
                    
                    # æ‰¹é‡è®¡ç®—RPY
                    if Rotation is not None:
                        try:
                            rpy_batch = Rotation.from_quat(quat_np).as_euler('XYZ', degrees=False)  # [batch_size, 3]
                        except Exception:
                            rpy_batch = np.zeros((batch_size, 3), dtype=np.float32)
                    else:
                        rpy_batch = np.zeros((batch_size, 3), dtype=np.float32)
                    
                    # ğŸš€ğŸš€ è¶…é«˜æ€§èƒ½æ‰§è¡Œ: æ‰¹é‡åº”ç”¨é¢„ç¼–è¯‘çš„åŠ›
                    if self._ultra_executor is not None and hasattr(self, '_compiled_forces'):
                        try:
                            # æ‰¹é‡æ‰§è¡Œ (æ¶ˆé™¤Pythonå¾ªç¯)
                            try:
                                from .ultra_fast_executor import apply_forces_jit, update_integral_jit
                            except ImportError:
                                from ultra_fast_executor import apply_forces_jit, update_integral_jit
                            
                            use_u_array = np.array(use_u_flags, dtype=np.bool_)
                            actions_np = np.zeros((batch_size, 6), dtype=np.float32)
                            apply_forces_jit(actions_np, self._compiled_forces, use_u_array)
                            
                            # è½¬ä¸ºtensor
                            actions[:batch_size] = torch.from_numpy(actions_np).to(self.device)
                            
                            # æ›´æ–°ç§¯åˆ†é¡¹ (JITåŠ é€Ÿ)
                            if not all(done_flags[:batch_size].cpu().numpy()):
                                err_i = np.array([
                                    [s['err_i_x'], s['err_i_y'], s['err_i_z'],
                                     s['err_i_roll'], s['err_i_pitch'], s['err_i_yaw']]
                                    for s in integral_states
                                ], dtype=np.float32)
                                done_array = done_flags[:batch_size].cpu().numpy().astype(np.bool_)
                                dt = float(getattr(self, '_control_dt', 1.0/48.0))
                                update_integral_jit(err_i, pe_batch, rpy_batch, done_array, dt)
                                
                                # å†™å›integral_states
                                for i in range(batch_size):
                                    integral_states[i]['err_i_x'] = float(err_i[i, 0])
                                    integral_states[i]['err_i_y'] = float(err_i[i, 1])
                                    integral_states[i]['err_i_z'] = float(err_i[i, 2])
                                    integral_states[i]['err_i_roll'] = float(err_i[i, 3])
                                    integral_states[i]['err_i_pitch'] = float(err_i[i, 4])
                                    integral_states[i]['err_i_yaw'] = float(err_i[i, 5])
                            
                            # æ£€æŸ¥ever_nonzero (å‘é‡åŒ–)
                            if self.strict_no_prior:
                                nonzero_mask = (np.abs(actions_np[:, 2]) > 1e-6) | \
                                               (np.abs(actions_np[:, 3]) > 1e-8) | \
                                               (np.abs(actions_np[:, 4]) > 1e-8) | \
                                               (np.abs(actions_np[:, 5]) > 1e-8)
                                for i in range(batch_size):
                                    if use_u_flags[i] and nonzero_mask[i]:
                                        ever_nonzero[i] = True
                            
                            # å¤„ç†éu_*è·¯å¾„ï¼ˆPIDæ§åˆ¶å™¨ï¼‰
                            for i in range(batch_size):
                                if not use_u_flags[i]:
                                    ctrl = controllers[i]
                                    try:
                                        if ctrl is not None:
                                            pe = pe_batch[i]
                                            ctrl_actions = ctrl.step(
                                                time_step=step,
                                                pos_x=float(pos[i][0]),
                                                pos_y=float(pos[i][1]),
                                                pos_z=float(pos[i][2]),
                                                target_x=float(tgt_np[0]),
                                                target_y=float(tgt_np[1]),
                                                target_z=float(tgt_np[2]),
                                            )
                                            actions[i, 0] = float(ctrl_actions.get('fx', 0.0))
                                            actions[i, 1] = float(ctrl_actions.get('fy', 0.0))
                                            actions[i, 2] = float(ctrl_actions.get('fz', 0.0))
                                            actions[i, 3] = float(ctrl_actions.get('tx', 0.0))
                                            actions[i, 4] = float(ctrl_actions.get('ty', 0.0))
                                            actions[i, 5] = float(ctrl_actions.get('tz', 0.0))
                                            if self.strict_no_prior:
                                                if (abs(actions[i, 2]) > 1e-6) or (abs(actions[i, 3]) > 1e-8) or \
                                                   (abs(actions[i, 4]) > 1e-8) or (abs(actions[i, 5]) > 1e-8):
                                                    ever_nonzero[i] = True
                                            
                                            # æ›´æ–°ç§¯åˆ†é¡¹
                                            dt = float(getattr(self, '_control_dt', 1.0/48.0))
                                            integral_states[i]['err_i_x'] += pe[0] * dt
                                            integral_states[i]['err_i_y'] += pe[1] * dt
                                            integral_states[i]['err_i_z'] += pe[2] * dt
                                    except Exception as e:
                                        if debug_enabled:
                                            print(f"[DebugReward] Controller step failed for env {i}: {e}")
                                        pass
                            
                        except Exception as e:
                            if step == 0:
                                import traceback
                                print(f"[UltraFast] âš ï¸ æ‰§è¡Œå¤±è´¥: {e}")
                                traceback.print_exc()
                            print(f"[UltraFast] å›é€€åˆ°æ ‡å‡†è·¯å¾„")
                            # å›é€€åˆ°ä¸‹é¢çš„æ ‡å‡†å¿«é€Ÿè·¯å¾„
                            self._ultra_executor = None
                    
                    # æ ‡å‡†å¿«é€Ÿè·¯å¾„ (å¦‚æœè¶…é«˜æ€§èƒ½è·¯å¾„æœªæ¿€æ´»)
                    if self._ultra_executor is None or not hasattr(self, '_compiled_forces'):
                        # å‘é‡åŒ–å¤„ç†æ‰€æœ‰ä½¿ç”¨u_*çš„ç¨‹åº
                        for i in range(batch_size):
                            if use_u_flags[i]:
                                pe = pe_batch[i]
                                rpy = rpy_batch[i]
                                
                                state = {
                                'pos_err_x': float(pe[0]),
                                'pos_err_y': float(pe[1]),
                                'pos_err_z': float(pe[2]),
                                'pos_err': float(np.linalg.norm(pe)),
                                'pos_err_xy': float(np.linalg.norm(pe[:2])),
                                'pos_err_z_abs': float(abs(pe[2])),
                                'vel_x': float(vel_np[i][0]),
                                'vel_y': float(vel_np[i][1]),
                                'vel_z': float(vel_np[i][2]),
                                'vel_err': float(np.linalg.norm(vel_np[i])),
                                'err_p_roll': float(rpy[0]),
                                'err_p_pitch': float(rpy[1]),
                                'err_p_yaw': float(rpy[2]),
                                'ang_err': float(np.linalg.norm(rpy)),
                                'rpy_err_mag': float(np.linalg.norm(rpy)),
                                'ang_vel_x': float(omega_np[i][0]),
                                'ang_vel_y': float(omega_np[i][1]),
                                'ang_vel_z': float(omega_np[i][2]),
                                'ang_vel': float(np.linalg.norm(omega_np[i])),
                                'ang_vel_mag': float(np.linalg.norm(omega_np[i])),
                                'err_i_x': float(integral_states[i]['err_i_x']),
                                'err_i_y': float(integral_states[i]['err_i_y']),
                                'err_i_z': float(integral_states[i]['err_i_z']),
                                'err_i_roll': float(integral_states[i]['err_i_roll']),
                                'err_i_pitch': float(integral_states[i]['err_i_pitch']),
                                'err_i_yaw': float(integral_states[i]['err_i_yaw']),
                                'err_d_x': float(-vel_np[i][0]),
                                'err_d_y': float(-vel_np[i][1]),
                                'err_d_z': float(-vel_np[i][2]),
                                    'err_d_roll': float(-omega_np[i][0]),
                                    'err_d_pitch': float(-omega_np[i][1]),
                                    'err_d_yaw': float(-omega_np[i][2]),
                                }
                                fz, tx, ty, tz = self._eval_program_forces(batch_programs[i], state)
                                actions[i, 0] = 0.0
                                actions[i, 1] = 0.0
                                actions[i, 2] = float(fz)
                                actions[i, 3] = float(tx)
                                actions[i, 4] = float(ty)
                                actions[i, 5] = float(tz)
                                if self.strict_no_prior:
                                    if (abs(fz) > 1e-6) or (abs(tx) > 1e-8) or (abs(ty) > 1e-8) or (abs(tz) > 1e-8):
                                        ever_nonzero[i] = True
                                
                                # æ›´æ–°ç§¯åˆ†é¡¹
                                dt = float(getattr(self, '_control_dt', 1.0/48.0))
                                integral_states[i]['err_i_x'] += pe[0] * dt
                                integral_states[i]['err_i_y'] += pe[1] * dt
                                integral_states[i]['err_i_z'] += pe[2] * dt
                                integral_states[i]['err_i_roll'] += rpy[0] * dt
                                integral_states[i]['err_i_pitch'] += rpy[1] * dt
                                integral_states[i]['err_i_yaw'] += rpy[2] * dt
                    
                    # å¤„ç†éu_*è·¯å¾„ï¼ˆPIDæ§åˆ¶å™¨ï¼‰
                    for i in range(batch_size):
                        if not use_u_flags[i]:
                            ctrl = controllers[i]
                            try:
                                if ctrl is not None:
                                    pe = pe_batch[i]
                                    ctrl_actions = ctrl.step(
                                        time_step=step,
                                        pos_x=float(pos[i][0]),
                                        pos_y=float(pos[i][1]),
                                        pos_z=float(pos[i][2]),
                                        target_x=float(tgt_np[0]),
                                        target_y=float(tgt_np[1]),
                                        target_z=float(tgt_np[2]),
                                    )
                                    actions[i, 0] = float(ctrl_actions.get('fx', 0.0))
                                    actions[i, 1] = float(ctrl_actions.get('fy', 0.0))
                                    actions[i, 2] = float(ctrl_actions.get('fz', 0.0))
                                    actions[i, 3] = float(ctrl_actions.get('tx', 0.0))
                                    actions[i, 4] = float(ctrl_actions.get('ty', 0.0))
                                    actions[i, 5] = float(ctrl_actions.get('tz', 0.0))
                                    if self.strict_no_prior:
                                        if (abs(actions[i, 2]) > 1e-6) or (abs(actions[i, 3]) > 1e-8) or \
                                           (abs(actions[i, 4]) > 1e-8) or (abs(actions[i, 5]) > 1e-8):
                                            ever_nonzero[i] = True
                                    
                                    # æ›´æ–°ç§¯åˆ†é¡¹
                                    dt = float(getattr(self, '_control_dt', 1.0/48.0))
                                    integral_states[i]['err_i_x'] += pe[0] * dt
                                    integral_states[i]['err_i_y'] += pe[1] * dt
                                    integral_states[i]['err_i_z'] += pe[2] * dt
                            except Exception as e:
                                if debug_enabled:
                                    print(f"[DebugReward] Controller step failed for env {i}: {e}")
                                pass
                elif not gpu_actions_applied:
                    # æ…¢é€Ÿè·¯å¾„: åŸå§‹ä¸²è¡Œå¤„ç†
                    for i in range(batch_size):
                        ctrl = controllers[i]
                        try:
                            if use_u_flags[i]:
                                # æ„é€ å®Œæ•´ä¸‰è½´ stateï¼ˆæ”¯æŒç²¾ç»† PIDï¼‰
                                pe = np.asarray(tgt_np, dtype=np.float32) - np.asarray(pos[i], dtype=np.float32)
                                # è·å–å››å…ƒæ•° â†’ RPYï¼ˆç®€åŒ–ï¼šä»…ç”¨äºå§¿æ€è¯¯å·®ä¼°ç®—ï¼‰
                                try:
                                    from scipy.spatial.transform import Rotation
                                    rpy = Rotation.from_quat(quat[i]).as_euler('XYZ', degrees=False)
                                except Exception:
                                    # æ—  scipy æ—¶é€€åŒ–ä¸ºé›¶
                                    rpy = np.zeros(3, dtype=np.float32)
                                
                                # TODO: ç§¯åˆ†é¡¹éœ€è¦è·¨æ­¥ç´¯ç§¯ï¼ˆå½“å‰ç®€åŒ–ä¸ºé›¶ï¼‰
                                state = {
                                # ä½ç½®è¯¯å·®ï¼ˆä¸‰è½´ï¼‰
                                'pos_err_x': float(pe[0]),
                                'pos_err_y': float(pe[1]),
                                'pos_err_z': float(pe[2]),
                                'pos_err': float(np.linalg.norm(pe)),
                                'pos_err_xy': float(np.linalg.norm(pe[:2])),
                                'pos_err_z_abs': float(abs(pe[2])),
                                # é€Ÿåº¦ï¼ˆä¸‰è½´ + æ¨¡é•¿ï¼‰
                                'vel_x': float(vel[i][0]),
                                'vel_y': float(vel[i][1]),
                                'vel_z': float(vel[i][2]),
                                'vel_err': float(np.linalg.norm(vel[i])),
                                # å§¿æ€è¯¯å·®ï¼ˆRPYï¼Œç›®æ ‡å‡è®¾ä¸º 0ï¼‰
                                'err_p_roll': float(rpy[0]),
                                'err_p_pitch': float(rpy[1]),
                                'err_p_yaw': float(rpy[2]),
                                'ang_err': float(np.linalg.norm(rpy)),
                                'rpy_err_mag': float(np.linalg.norm(rpy)),
                                # è§’é€Ÿåº¦ï¼ˆä¸‰è½´ + æ¨¡é•¿ï¼‰
                                'ang_vel_x': float(omega[i][0]),
                                'ang_vel_y': float(omega[i][1]),
                                'ang_vel_z': float(omega[i][2]),
                                'ang_vel': float(np.linalg.norm(omega[i])),
                                'ang_vel_mag': float(np.linalg.norm(omega[i])),
                                # ç§¯åˆ†é¡¹ï¼ˆç´¯ç§¯ï¼‰
                                'err_i_x': float(integral_states[i]['err_i_x']),
                                'err_i_y': float(integral_states[i]['err_i_y']),
                                'err_i_z': float(integral_states[i]['err_i_z']),
                                'err_i_roll': float(integral_states[i]['err_i_roll']),
                                'err_i_pitch': float(integral_states[i]['err_i_pitch']),
                                'err_i_yaw': float(integral_states[i]['err_i_yaw']),
                                # å¾®åˆ†é¡¹ï¼ˆè¿‘ä¼¼ä¸ºé€Ÿåº¦/è§’é€Ÿåº¦çš„è´Ÿå€¼ï¼‰
                                'err_d_x': float(-vel[i][0]),
                                'err_d_y': float(-vel[i][1]),
                                'err_d_z': float(-vel[i][2]),
                                'err_d_roll': float(-omega[i][0]),
                                'err_d_pitch': float(-omega[i][1]),
                                'err_d_yaw': float(-omega[i][2]),
                                }
                                fz, tx, ty, tz = self._eval_program_forces(batch_programs[i], state)
                                actions[i, 0] = 0.0
                                actions[i, 1] = 0.0
                                actions[i, 2] = float(fz)
                                actions[i, 3] = float(tx)
                                actions[i, 4] = float(ty)
                                actions[i, 5] = float(tz)
                                # è®°å½•æ˜¯å¦äº§ç”Ÿéé›¶åŠ¨ä½œ
                                if self.strict_no_prior:
                                    if (abs(fz) > 1e-6) or (abs(tx) > 1e-8) or (abs(ty) > 1e-8) or (abs(tz) > 1e-8):
                                        ever_nonzero[i] = True
                                # æ›´æ–°ç§¯åˆ†çŠ¶æ€ï¼ˆä»…å¯¹æœªå®Œæˆçš„ç¯å¢ƒï¼‰
                                if not done_flags[i]:
                                    dt = float(self._control_dt)
                                    integral_states[i]['err_i_x'] += float(pe[0]) * dt
                                    integral_states[i]['err_i_y'] += float(pe[1]) * dt
                                    integral_states[i]['err_i_z'] += float(pe[2]) * dt
                                    integral_states[i]['err_i_roll'] += float(rpy[0]) * dt
                                    integral_states[i]['err_i_pitch'] += float(rpy[1]) * dt
                                    integral_states[i]['err_i_yaw'] += float(rpy[2]) * dt
                            else:
                                if ctrl is None:
                                    continue
                                rpm, _pos_e, _rpy_e = ctrl.computeControl(
                                    self._control_dt,
                                    cur_pos=pos[i],
                                    cur_quat=quat[i],
                                    cur_vel=vel[i],
                                    cur_ang_vel=omega[i],
                                    target_pos=tgt_np,
                                )
                                rpm = np.clip(np.asarray(rpm, dtype=np.float32), 0.0, 25000.0)
                                fz, tx, ty, tz = self._rpm_to_forces_local(rpm)
                                actions[i, 2] = float(fz)
                                actions[i, 3] = float(tx)
                                actions[i, 4] = float(ty)
                                actions[i, 5] = float(tz)
                        except Exception:
                            # å¤±è´¥åˆ™ä¿æŒé›¶åŠ¨ä½œ
                            pass
                
                # è¾“å‡ºå®‰å…¨å£³ (MAD) + æ­¥è¿›ä»¿çœŸ
                actions = self._apply_output_mad(actions, use_u_flags, batch_size)
                
                # æ›´æ–°ç»Ÿè®¡
                if debug_enabled or batch_start == 0:
                    try:
                        fz_vals = actions[:batch_size, 2].abs()
                        tx_vals = actions[:batch_size, 3].abs()
                        episode_stats['sum_fz'] += float(fz_vals.sum().item())
                        episode_stats['max_fz'] = max(episode_stats['max_fz'], float(fz_vals.max().item()))
                        episode_stats['sum_tx'] += float(tx_vals.sum().item())
                        episode_stats['max_tx'] = max(episode_stats['max_tx'], float(tx_vals.max().item()))
                        episode_stats['count'] += batch_size
                    except Exception:
                        pass

                obs, step_rewards_env, dones, infos = self._isaac_env_pool.step(actions)

                # ç›´æ¥ä» Isaac Gym è·å– GPU å¼ é‡å¿«ç…§ï¼Œé¿å… CPUâ†”GPU å¾€è¿”
                tensor_obs = self._isaac_env_pool.get_states_batch()
                pos_gpu = tensor_obs['pos']
                vel_gpu = tensor_obs['vel']
                omega_gpu = tensor_obs['omega']
                quat_gpu = tensor_obs['quat']  # å§¿æ€å››å…ƒæ•° [qx, qy, qz, qw]
                # ç›®æ ‡ï¼ˆæ‚¬åœæˆ–è½¨è¿¹ï¼‰
                if self.trajectory_config.get('type') == 'hover':
                    tgt = np.array([0.0, 0.0, self.trajectory_config.get('height', 1.0)], dtype=np.float32)
                else:
                    tgt = np.array(self.trajectory_config.get('target', [0.0, 0.0, 1.0]), dtype=np.float32)
                
                # è®¡ç®— Reward
                if self.use_scg_exact_reward and self._scg_reward_calc is not None:
                    # ğŸ¯ ç²¾ç¡® SCG rewardï¼ˆäºŒæ¬¡ä»£ä»·ï¼Œæ—  shapingï¼‰
                    step_reward = self._scg_reward_calc.compute_step(
                        pos_gpu[:batch_size, :],
                        vel_gpu[:batch_size, :],
                        quat_gpu[:batch_size, :],
                        omega_gpu[:batch_size, :],
                        tgt_tensor,
                        actions[:batch_size, 2:6],  # [fz, tx, ty, tz]
                        done_mask=done_flags_batch
                    )
                elif self._step_reward_calc is not None:
                    # Stepwise å¥–åŠ±ï¼ˆå¸¦ shapingï¼‰
                    step_total = self._step_reward_calc.compute_step(
                        pos_gpu[:batch_size, :],
                        tgt_tensor,
                        vel_gpu[:batch_size, :],
                        omega_gpu[:batch_size, :],
                        actions[:batch_size, :],
                        done_flags_batch,
                        quat=quat_gpu[:batch_size, :],  # ğŸ”§ ä¿®å¤: ä¼ é€’ quat å‚æ•°
                    )
                    step_reward = step_total
                else:
                    # é€€å›æ—§é€»è¾‘
                    if self.trajectory_config.get('type') == 'hover':
                        w_pos, w_vel = 2.0, 0.3  # æ‚¬åœï¼šæ›´çœ‹é‡ç²¾ç¡®å®šç‚¹å’Œé™æ­¢
                    else:
                        w_pos, w_vel = 1.0, 0.1  # è½¨è¿¹è·Ÿè¸ªï¼šå…è®¸ä¸€å®šé€Ÿåº¦
                    pos_err = pos_gpu[:batch_size, :] - tgt_tensor
                    step_reward = - w_pos * torch.norm(pos_err, dim=1)
                    step_reward -= w_vel * torch.norm(vel_gpu[:batch_size, :], dim=1)
                    act_pen = 1e-7 * torch.sum(actions[:batch_size, :] ** 2, dim=1)
                    step_reward -= act_pen
                    crashed = pos_gpu[:batch_size, 2] < 0.1
                    step_reward[crashed] -= 5.0

                # è°ƒè¯•ï¼šè®°å½•é¦–æœ«ä½ç½®è¯¯å·®ï¼ˆä½¿ç”¨åŠ¨æ€ç›®æ ‡ï¼‰
                if debug_enabled:
                    # è®¡ç®—å½“å‰æ­¥çš„ç»å¯¹ä½ç½®è¯¯å·®æ¨¡é•¿
                    cur_pos_err = torch.norm(pos_gpu[:batch_size, :] - tgt_tensor.view(1, 3), dim=1)
                    if step == 0:
                        first_pos_err = cur_pos_err.detach()[:min(8, batch_size)].cpu()
                    last_pos_err = cur_pos_err.detach()[:min(8, batch_size)].cpu()
                # ç´¯ç§¯å¥–åŠ±
                active_mask = (~done_flags_batch).float()
                total_rewards[:batch_size] += step_reward * active_mask
                steps_count[:batch_size] += active_mask
                # æ›´æ–°æ‰¹æ¬¡ done æ ‡å¿—ï¼ˆä»…å‰ batch_size æœ‰æ•ˆï¼‰
                done_flags_batch |= dones[:batch_size]
                done_flags[:batch_size] = done_flags_batch
                if step >= min_steps and done_flags_batch.all():
                    break
            # é¢å¤–çš„ episode æœ«å°¾å¥–åŠ±ï¼ˆä»… Stepwise æ¨¡å¼ï¼‰
            if self._step_reward_calc is not None and not self.use_scg_exact_reward:
                bonus = self._step_reward_calc.finalize()[:batch_size]
                total_rewards[:batch_size] += bonus
            # åœ¨ä¸¥æ ¼æ— å…ˆéªŒæ¨¡å¼ä¸‹ï¼šå¯¹æ•´é›†å§‹ç»ˆé›¶åŠ¨ä½œçš„ç¨‹åºæ–½åŠ æƒ©ç½š
            if self.strict_no_prior and self.zero_action_penalty > 0:
                zero_mask = (~ever_nonzero).float()
                total_rewards[:batch_size] -= self.zero_action_penalty * zero_mask
                if debug_enabled:
                    try:
                        zero_cnt = int((~ever_nonzero).sum().item())
                        print(f"[DebugReward] zero-action programs in batch: {zero_cnt}/{batch_size}")
                    except Exception:
                        pass

            if gpu_batch_token is not None:
                self._gpu_executor.release_batch(gpu_batch_token)
            
            # ğŸ” åŠ¨ä½œå¹…åº¦ç»Ÿè®¡ï¼ˆè¯Šæ–­ç”¨ï¼‰ï¼šè®¡ç®—æœ¬æ‰¹åŠ¨ä½œè¾“å‡ºçš„å¹³å‡å¹…åº¦ä¸æœ€å¤§å€¼
            # æ³¨é‡Šæ‰ä»¥å‡å°‘æ—¥å¿—è¾“å‡ºå™ªéŸ³
            # if debug_enabled or batch_start == 0:
            #     try:
            #         count = max(1, episode_stats['count'])
            #         avg_fz = episode_stats['sum_fz'] / count
            #         max_fz = episode_stats['max_fz']
            #         avg_tx = episode_stats['sum_tx'] / count
            #         max_tx = episode_stats['max_tx']
            #         print(f"[ActionAmp] Batch{batch_start//programs_per_batch}: avg_fz={avg_fz:.4f}, max_fz={max_fz:.4f}, avg_tx={avg_tx:.6f}, max_tx={max_tx:.6f}")
            #     except Exception:
            #         pass
            
            # å¤æ‚åº¦æ¿€åŠ±å’Œå…ˆéªŒï¼šä»…å½±å“è®­ç»ƒå¥–åŠ±ï¼Œä¸æ”¹çœŸå®ç¯å¢ƒå¥–åŠ±
            complexity_rewards = torch.zeros(batch_size, device=self.device)
            if self.complexity_bonus > 0:
                for i in range(batch_size):
                    prog = batch_programs[i]
                    unique_vars = set()
                    for rule in prog:
                        node = rule.get('node', None)
                        if node is not None:
                            vars_in_node = self._extract_variables_from_node(node)
                            unique_vars.update(vars_in_node)
                    num_rules = sum(1 for rule in prog if rule.get('node', None) is not None)
                    bonus = self.complexity_bonus * len(unique_vars) + 0.5 * self.complexity_bonus * num_rules
                    complexity_rewards[i] = bonus
                if debug_enabled:
                    try:
                        print(f"[DebugReward] complexity bonuses: {complexity_rewards[:min(8, batch_size)].cpu().numpy()}")
                    except Exception:
                        pass

            prior_bonus = self._compute_prior_bonus(batch_programs)
            prior_struct = torch.zeros(batch_size, device=self.device)
            prior_stab = torch.zeros(batch_size, device=self.device)
            if prior_bonus is not None:
                # prior_bonus: (total, struct, stab)
                prior_struct = prior_bonus[1]
                prior_stab = prior_bonus[2]

            # å½’çº¦
            if self.reward_reduction == 'mean':
                denom = torch.clamp(steps_count[:batch_size], min=1.0)
                batch_scores = (total_rewards[:batch_size] / denom).cpu().numpy().tolist()
            else:
                batch_scores = total_rewards[:batch_size].cpu().numpy().tolist()
            rewards.extend(batch_scores)

            # è°ƒè¯•è¾“å‡ºï¼ˆä»…é¦–æ‰¹ & å¼€å¯æ—¶ï¼‰
            if debug_enabled and batch_start == 0:
                try:
                    print("[DebugReward] batch_size={} mean_final_reward={:.4f}".format(
                        batch_size, float(np.mean(batch_scores))))
                    if first_pos_err is not None and last_pos_err is not None:
                        diff = (last_pos_err - first_pos_err).numpy()
                        print("[DebugReward] first_pos_err[:8] =", [f"{x:.3f}" for x in first_pos_err.numpy()])
                        print("[DebugReward] last_pos_err[:8]  =", [f"{x:.3f}" for x in last_pos_err.numpy()])
                        print("[DebugReward] Î”pos_err[:8]      =", [f"{x:.3f}" for x in diff])
                except Exception:
                    pass
        
        elapsed = time.time() - start_time
        # æ˜¾ç¤ºåŸå§‹ç¨‹åºæ•°(æœªæ‰©å±•replicaså‰)
        display_count = num_programs_original if self.replicas_per_program > 1 else num_programs
        # æ³¨é‡Šæ‰è¯¦ç»†è¯„ä¼°æ—¥å¿—ï¼Œå‡å°‘è¾“å‡ºå™ªéŸ³
        # print(f"[BatchEvaluator] âœ… è¯„ä¼°å®Œæˆ: {display_count} ç¨‹åº (Ã—{self.replicas_per_program} replicas), {elapsed:.2f}ç§’ ({elapsed/display_count*1000:.1f}ms/ç¨‹åº)")
        
        # å…ˆå°†æ–°è¯„ä¼°ç»“æœå†™å…¥ç¼“å­˜ï¼ˆä»¥â€œå•ç¨‹åºâ€ç²’åº¦ï¼Œè€Œé replicasï¼‰
        # rewards å½“å‰é•¿åº¦ä¸º num_programs_originalÃ—replicas_per_programï¼ˆæˆ–æ— replicasæ—¶ä¸º num_programs_originalï¼‰
        # å…ˆå¾—åˆ°æ¯ä¸ªåŸå§‹ç¨‹åºçš„å¹³å‡å¥–åŠ±ï¼Œç”¨äºç¼“å­˜å’Œåç»­åˆå¹¶
        per_program_rewards: List[float]
        if self.replicas_per_program > 1:
            per_program_rewards = []
            for i in range(num_programs_original):
                start_idx = i * self.replicas_per_program
                end_idx = start_idx + self.replicas_per_program
                avg_reward = float(np.mean(rewards[start_idx:end_idx]))
                per_program_rewards.append(avg_reward)
        else:
            per_program_rewards = [float(r) for r in rewards]

        # å†™å…¥ eval cache
        for local_idx, prog_reward in zip(indices_to_eval, per_program_rewards):
            key = cache_keys[local_idx]
            if key is None:
                continue
            self._eval_cache[key] = float(prog_reward)
        if len(self._eval_cache) > self._eval_cache_limit:
            remove_n = max(1, int(self._eval_cache_limit * 0.2))
            for _ in range(remove_n):
                try:
                    self._eval_cache.pop(next(iter(self._eval_cache)))
                except Exception:
                    break

        # å°†ç¼“å­˜å‘½ä¸­ä¸æ–°è¯„ä¼°ç»“æœç»„åˆæˆâ€œä»…æœ‰æ•ˆç¨‹åºâ€çš„å®Œæ•´åˆ—è¡¨
        merged_valid_rewards: List[float] = []
        eval_iter = iter(per_program_rewards)
        for idx in range(len(programs)):
            if idx in cached_rewards:
                merged_valid_rewards.append(cached_rewards[idx])
            else:
                merged_valid_rewards.append(float(next(eval_iter)))

        if len(valid_indices) == total_requested:
            return merged_valid_rewards
        return self._merge_rewards_with_invalid(valid_indices, merged_valid_rewards, invalid_info, total_requested)

    def evaluate_batch_with_metrics(self, programs: List[List[Dict[str, Any]]]) -> Tuple[List[float], List[float], List[Dict[str, float]]]:
        """ä¸ evaluate_batch ç±»ä¼¼ï¼Œä½†é¢å¤–è¿”å›é€åˆ†é‡å¥–åŠ±æ±‡æ€»ï¼ˆåŠ æƒåï¼‰ç”¨äºåˆ†æ/è®°å½•ã€‚

        Returns:
            rewards_train: æ¯ä¸ªç¨‹åºçš„è®­ç»ƒå¥–åŠ±ï¼ˆå«é›¶åŠ¨ä½œæƒ©ç½šï¼Œå¯¹ replicas å–å¹³å‡åï¼‰
            rewards_true: æ¯ä¸ªç¨‹åºçš„çœŸå®å¥–åŠ±ï¼ˆä¸å«æƒ©ç½šï¼Œå¯¹ replicas å–å¹³å‡åï¼‰
            metrics: æ¯ä¸ªç¨‹åºçš„ç»„ä»¶å­—å…¸ï¼ˆåŒæ ·å¯¹ replicas å¹³å‡ï¼‰ï¼Œé”®åŒ…å«ï¼š
                     ['position_rmse','settling_time','control_effort','smoothness_jerk',
                      'gain_stability','saturation','peak_error','high_freq','finalize_bonus',
                      'zero_action_penalty','structure_prior','stability_prior']
        """
        total_requested = len(programs)
        valid_programs, valid_indices, invalid_info = self._partition_programs_by_constraints(programs)
        if not valid_programs:
            self._log_invalid_programs(invalid_info)
            penalty = [float(HARD_CONSTRAINT_PENALTY)] * total_requested
            metrics = [self._metric_template() for _ in range(total_requested)]
            for idx in invalid_info:
                metrics[idx]['hard_constraint_violation'] = 1.0
            return penalty, penalty[:], metrics
        programs = valid_programs

        # ğŸ”§ é•œåƒå±•å¼€ï¼šå¦‚æœç¨‹åºåªæœ‰ u_txï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆ u_tyï¼ˆå–åï¼‰åŠ yaw/thrust ç¨³å®šå™¨
        programs = [
            self._mirror_expand_single_axis_program(prog) for prog in programs
        ]

        # åˆå§‹åŒ–ç¯å¢ƒæ± 
        if self._isaac_env_pool is None:
            self._init_isaac_gym_pool()

        import torch  # type: ignore

        num_programs_original = len(programs)
        # æ‰©å±• replicas
        if self.replicas_per_program > 1:
            programs_expanded = []
            for prog in programs:
                programs_expanded.extend([prog] * self.replicas_per_program)
            programs = programs_expanded

        num_programs = len(programs)
        rewards: List[float] = []  # è®­ç»ƒå¥–åŠ±ï¼ˆå«æƒ©ç½šï¼‰
        rewards_true: List[float] = []  # çœŸå®å¥–åŠ±ï¼ˆä¸å«æƒ©ç½šï¼‰
        metrics_all: List[Dict[str, float]] = []  # ä¸ rewards é¡ºåºä¸€ä¸€å¯¹åº”ï¼ˆæ‰©å±•åï¼‰

        start_time = time.time()
        programs_per_batch = max(1, self.isaac_num_envs // self.replicas_per_program)

        for batch_start in range(0, num_programs, programs_per_batch):
            batch_end = min(batch_start + programs_per_batch, num_programs)
            batch_programs = programs[batch_start:batch_end]
            batch_size = len(batch_programs)

            # è½»é‡çº§ç¡®å®šæ€§é‡ç½®ï¼šä¿ç•™ç¯å¢ƒæ± ï¼Œåªé‡ç½®çŠ¶æ€ (fast_pathç‰ˆæœ¬)
            num_needed = batch_size
            
            # ğŸ”§ è®¡ç®—åˆå§‹ä½ç½®ï¼šç­‰äº t=0 æ—¶çš„ç›®æ ‡ä½ç½®
            initial_pos_np = self._target_pos(0.0)
            initial_pos_tensor = torch.tensor(initial_pos_np, device=self.device, dtype=torch.float32)
            
            if not self._envs_ready:
                initial_pos_batch = initial_pos_tensor.unsqueeze(0).expand(self.isaac_num_envs, -1).clone()
                obs = self._isaac_env_pool.reset(initial_pos=initial_pos_batch)
                self._envs_ready = True
                self._last_reset_size = self.isaac_num_envs
                self._reset_action_history()
            else:
                env_ids_to_reset = torch.arange(batch_size, dtype=torch.long, device=self.device)
                initial_pos_batch = initial_pos_tensor.unsqueeze(0).expand(batch_size, -1).clone()
                obs = self._isaac_env_pool.reset(env_ids=env_ids_to_reset, initial_pos=initial_pos_batch)
                self._reset_action_history(env_ids_to_reset)

            if self.use_scg_exact_reward and self._scg_reward_calc is not None:
                self._scg_reward_calc.reset(num_envs=batch_size)

            total_rewards = torch.zeros(self.isaac_num_envs, device=self.device)
            done_flags = torch.zeros(self.isaac_num_envs, dtype=torch.bool, device=self.device)
            done_flags_batch = torch.zeros(batch_size, dtype=torch.bool, device=self.device)
            # åˆå§‹åŒ–é€åˆ†é‡è®¡ç®—å™¨ï¼ˆåŒ¹é… batch_sizeï¼‰
            if self._step_reward_calc is not None:
                try:
                    weights, ks = get_reward_profile(self.reward_profile) if get_reward_profile else ({}, {})
                    self._step_reward_calc = StepwiseRewardCalculator(weights, ks, dt=self._step_dt, num_envs=batch_size, device=self.device)
                except Exception:
                    self._step_reward_calc = None
            # è®°å½•æ¯ä¸ªç¯å¢ƒç´¯è®¡æ­¥æ•°
            steps_count = torch.zeros(self.isaac_num_envs, device=self.device)
            ever_nonzero = torch.zeros(batch_size, dtype=torch.bool, device=self.device)
            integral_states = [
                {
                    'err_i_x': 0.0, 'err_i_y': 0.0, 'err_i_z': 0.0,
                    'err_i_roll': 0.0, 'err_i_pitch': 0.0, 'err_i_yaw': 0.0
                }
                for _ in range(batch_size)
            ]
            debug_enabled = bool(int(os.getenv('DEBUG_STEPWISE', '0')))

            # æ‰€æœ‰ç¨‹åºç»Ÿä¸€ä½¿ç”¨ u_* ç›´æ¥è¾“å‡ºè·¯å¾„ï¼ˆä¸å†ä¾èµ– PID å°è£…ï¼‰
            gpu_batch_token = None
            controllers = [None for _ in range(batch_size)]
            use_u_flags = [True for _ in range(batch_size)]  # å…¨éƒ¨ä½¿ç”¨ç›´æ¥åŠ›/åŠ›çŸ©è¾“å‡º
            
            # ğŸ”§ é‡ç½®æ¯ä¸ªç¨‹åºçš„æ—¶é—´ç®—å­çŠ¶æ€ï¼ˆema/delay/diff/rateï¼‰
            # ç¡®ä¿æ¯æ¬¡è¯„ä¼°ä»é›¶çŠ¶æ€å¼€å§‹ï¼Œä¿è¯è®­ç»ƒä¸æµ‹è¯•ä¸€è‡´æ€§
            if reset_program_state is not None:
                for prog in batch_programs:
                    reset_program_state(prog)
            
            # UltraFast ä»…åœ¨æ‰€æœ‰ç¨‹åºä¸ºå¸¸é‡ set æƒ…å†µä¸‹å¯ç”¨ï¼ˆmetrics è¯„ä¼°åŒç†ï¼‰
            if self.use_fast_path and self._ultra_executor is not None:
                try:
                    if not self._all_programs_const(batch_programs):
                        self._ultra_executor = None
                except Exception:
                    self._ultra_executor = None

            # ğŸ”§ ä¿®å¤: gpu_batch_token åˆå§‹åŒ–åº”è¯¥åœ¨ try/except å—å¤–
            if (self._gpu_executor is not None and self.use_gpu_expression_executor and any(use_u_flags)):
                try:
                    gpu_batch_token = self._gpu_executor.prepare_batch(batch_programs)
                except Exception as gpu_batch_exc:
                    gpu_batch_token = None
                    if batch_start == 0:
                        print(f"[GPUExecutor] âš ï¸ metricsæ‰¹æ¬¡ç»‘å®šå¤±è´¥ï¼Œä½¿ç”¨CPUè·¯å¾„: {gpu_batch_exc}")

            max_steps = int(self.duration * float(getattr(self, '_control_freq', 48)))
            min_steps = int(max_steps * self.min_steps_frac)
            bonus_vec = None

            for step in range(max_steps):
                t = step * float(getattr(self, '_control_dt', 1.0/48.0))
                tgt_np = self._target_pos(t)
                tgt_tensor = torch.tensor(tgt_np, device=self.device, dtype=torch.float32)

                actions = torch.zeros((self.isaac_num_envs, 6), device=self.device)
                pos = obs['position'][:batch_size]
                quat = obs['orientation'][:batch_size]
                vel = obs['velocity'][:batch_size]
                omega = obs['angular_velocity'][:batch_size]
                gpu_actions_applied = False
                if gpu_batch_token is not None:
                    try:
                        pos_tensor = self._ensure_tensor(pos)
                        vel_tensor = self._ensure_tensor(vel)
                        omega_tensor = self._ensure_tensor(omega)
                        quat_tensor = self._ensure_tensor(quat)
                        gpu_use_mask = torch.tensor(use_u_flags, dtype=torch.bool, device=self.device)
                        if self._use_gpu_control_loop:
                            gpu_outputs, pos_err_tensor, rpy_tensor = self._gpu_executor.evaluate_from_raw_obs(
                                gpu_batch_token,
                                pos_tensor,
                                vel_tensor,
                                omega_tensor,
                                quat_tensor,
                                tgt_tensor,
                                integral_states,
                                gpu_use_mask,
                                active_mask=(~done_flags_batch)
                            )
                        else:
                            state_tensors, pos_err_tensor, rpy_tensor = self._prepare_gpu_state_tensors(
                                pos_tensor, vel_tensor, omega_tensor, quat_tensor, tgt_tensor, integral_states
                            )
                            gpu_outputs = self._gpu_executor.evaluate(
                                gpu_batch_token,
                                state_tensors,
                                gpu_use_mask,
                                active_mask=(~done_flags_batch)
                            )
                        actions[:batch_size, 2:6] = torch.where(
                            gpu_use_mask.unsqueeze(-1),
                            gpu_outputs,
                            actions[:batch_size, 2:6]
                        )
                        if self.strict_no_prior:
                            nz_mask = (
                                gpu_outputs[:, 0].abs() > 1e-6
                            ) | (
                                gpu_outputs[:, 1].abs() > 1e-8
                            ) | (
                                gpu_outputs[:, 2].abs() > 1e-8
                            ) | (
                                gpu_outputs[:, 3].abs() > 1e-8
                            )
                            ever_nonzero |= (gpu_use_mask & nz_mask)
                        self._update_integral_states(
                            integral_states,
                            pos_err_tensor,
                            rpy_tensor,
                            done_flags_batch,
                            float(getattr(self, '_control_dt', 1.0 / 48.0))
                        )
                        if not self.strict_no_prior:
                            self._apply_pid_controllers(
                                controllers,
                                use_u_flags,
                                actions,
                                step,
                                pos_tensor,
                                quat_tensor,
                                vel_tensor,
                                omega_tensor,
                                tgt_np,
                                integral_states,
                                ever_nonzero,
                                debug_enabled,
                            )
                        gpu_actions_applied = True
                    except Exception as gpu_metrics_exc:
                        gpu_actions_applied = False
                        if batch_start == 0:
                            print(f"[GPUExecutor] âš ï¸ metrics step å›é€€CPU: {gpu_metrics_exc}")

                # ä¸ºç®€åŒ–ï¼Œè¿™é‡Œå¤ç”¨ evaluate_batch çš„æ ‡å‡†å¿«é€Ÿè·¯å¾„ï¼ˆä¸å±•å¼€å…¨éƒ¨è¶…å¿«è·¯å¾„ç»†èŠ‚ï¼‰ï¼Œ
                # ä½†ä¿ç•™æ­£ç¡®æ€§ï¼šé€ç¨‹åºæ±‚å€¼ç”Ÿæˆ u_*ã€‚
                if not gpu_actions_applied:
                    try:
                        from scipy.spatial.transform import Rotation
                    except ImportError:
                        Rotation = None
                    if isinstance(pos, torch.Tensor):
                        pos_np = pos.cpu().numpy(); quat_np = quat.cpu().numpy(); vel_np = vel.cpu().numpy(); omega_np = omega.cpu().numpy()
                    else:
                        pos_np = np.asarray(pos); quat_np = np.asarray(quat); vel_np = np.asarray(vel); omega_np = np.asarray(omega)
                    tgt_batch = np.tile(tgt_np, (batch_size, 1))
                    pe_batch = tgt_batch - pos_np
                    if Rotation is not None:
                        try:
                            rpy_batch = Rotation.from_quat(quat_np).as_euler('XYZ', degrees=False)
                        except Exception:
                            rpy_batch = np.zeros((batch_size, 3), dtype=np.float32)
                    else:
                        rpy_batch = np.zeros((batch_size, 3), dtype=np.float32)

                    for i in range(batch_size):
                        if use_u_flags[i]:
                            pe = pe_batch[i]; rpy = rpy_batch[i]
                            state = {
                                'pos_err_x': float(pe[0]), 'pos_err_y': float(pe[1]), 'pos_err_z': float(pe[2]),
                                'pos_err': float(np.linalg.norm(pe)), 'pos_err_xy': float(np.linalg.norm(pe[:2])), 'pos_err_z_abs': float(abs(pe[2])),
                                'vel_x': float(vel_np[i][0]), 'vel_y': float(vel_np[i][1]), 'vel_z': float(vel_np[i][2]), 'vel_err': float(np.linalg.norm(vel_np[i])),
                                'err_p_roll': float(rpy[0]), 'err_p_pitch': float(rpy[1]), 'err_p_yaw': float(rpy[2]), 'ang_err': float(np.linalg.norm(rpy)), 'rpy_err_mag': float(np.linalg.norm(rpy)),
                                'ang_vel_x': float(omega_np[i][0]), 'ang_vel_y': float(omega_np[i][1]), 'ang_vel_z': float(omega_np[i][2]), 'ang_vel': float(np.linalg.norm(omega_np[i])), 'ang_vel_mag': float(np.linalg.norm(omega_np[i])),
                                'err_i_x': float(integral_states[i]['err_i_x']), 'err_i_y': float(integral_states[i]['err_i_y']), 'err_i_z': float(integral_states[i]['err_i_z']),
                                'err_i_roll': float(integral_states[i]['err_i_roll']), 'err_i_pitch': float(integral_states[i]['err_i_pitch']), 'err_i_yaw': float(integral_states[i]['err_i_yaw']),
                                'err_d_x': float(-vel_np[i][0]), 'err_d_y': float(-vel_np[i][1]), 'err_d_z': float(-vel_np[i][2]), 'err_d_roll': float(-omega_np[i][0]), 'err_d_pitch': float(-omega_np[i][1]), 'err_d_yaw': float(-omega_np[i][2]),
                            }
                            fz, tx, ty, tz = self._eval_program_forces(batch_programs[i], state)
                            actions[i, 2] = float(fz); actions[i, 3] = float(tx); actions[i, 4] = float(ty); actions[i, 5] = float(tz)
                            if self.strict_no_prior:
                                if (abs(fz) > 1e-6) or (abs(tx) > 1e-8) or (abs(ty) > 1e-8) or (abs(tz) > 1e-8):
                                    ever_nonzero[i] = True
                            if not done_flags[i]:
                                dt = float(getattr(self, '_control_dt', 1.0/48.0))
                                integral_states[i]['err_i_x'] += float(pe[0]) * dt
                                integral_states[i]['err_i_y'] += float(pe[1]) * dt
                                integral_states[i]['err_i_z'] += float(pe[2]) * dt
                                integral_states[i]['err_i_roll'] += float(rpy[0]) * dt
                                integral_states[i]['err_i_pitch'] += float(rpy[1]) * dt
                                integral_states[i]['err_i_yaw'] += float(rpy[2]) * dt
                        else:
                            ctrl = controllers[i]
                            if ctrl is not None:
                                rpm, _pos_e, _rpy_e = ctrl.computeControl(
                                    self._control_dt,
                                    cur_pos=pos[i], cur_quat=quat[i], cur_vel=vel[i], cur_ang_vel=omega[i], target_pos=tgt_np,
                                )
                                rpm = np.clip(np.asarray(rpm, dtype=np.float32), 0.0, 25000.0)
                                fz, tx, ty, tz = self._rpm_to_forces_local(rpm)
                                actions[i, 2] = float(fz); actions[i, 3] = float(tx); actions[i, 4] = float(ty); actions[i, 5] = float(tz)
                            if self.strict_no_prior:
                                if (abs(actions[i, 2]) > 1e-6) or (abs(actions[i, 3]) > 1e-8) or (abs(actions[i, 4]) > 1e-8) or (abs(actions[i, 5]) > 1e-8):
                                    ever_nonzero[i] = True

                # ç¯å¢ƒæ­¥è¿›å‰åº”ç”¨ MAD å®‰å…¨å£³
                actions = self._apply_output_mad(actions, use_u_flags, batch_size)
                obs, step_rewards_env, dones, infos = self._isaac_env_pool.step(actions)

                tensor_obs = self._isaac_env_pool.get_states_batch()
                pos_t = tensor_obs['pos']
                vel_t = tensor_obs['vel']
                omega_t = tensor_obs['omega']
                quat_t = tensor_obs['quat']  # å§¿æ€å››å…ƒæ•°
                
                # è®¡ç®— Reward
                if self.use_scg_exact_reward and self._scg_reward_calc is not None:
                    # ğŸ¯ ç²¾ç¡® SCG reward
                    step_reward = self._scg_reward_calc.compute_step(
                        pos_t[:batch_size, :],
                        vel_t[:batch_size, :],
                        quat_t[:batch_size, :],
                        omega_t[:batch_size, :],
                        tgt_tensor,
                        actions[:batch_size, 2:6],
                        done_mask=done_flags_batch
                    )
                elif self._step_reward_calc is not None:
                    # Stepwise å¥–åŠ±
                    step_total = self._step_reward_calc.compute_step(
                        pos_t[:batch_size, :],
                        tgt_tensor,
                        vel_t[:batch_size, :],
                        omega_t[:batch_size, :],
                        actions[:batch_size, :],
                        done_flags_batch,
                        quat=quat_t[:batch_size, :],  # ğŸ”§ ä¿®å¤: ä¼ é€’ quat å‚æ•°
                    )
                    step_reward = step_total
                else:
                    pos_err = pos_t[:batch_size, :] - tgt_tensor
                    w_pos, w_vel = (2.0, 0.3) if self.trajectory_config.get('type') == 'hover' else (1.0, 0.1)
                    step_reward = - w_pos * torch.norm(pos_err, dim=1)
                    step_reward -= w_vel * torch.norm(vel_t[:batch_size, :], dim=1)
                    act_pen = 1e-7 * torch.sum(actions[:batch_size, :] ** 2, dim=1)
                    step_reward -= act_pen
                    crashed = pos_t[:batch_size, 2] < 0.1
                    step_reward[crashed] -= 5.0

                active_mask = (~done_flags_batch).float()
                total_rewards[:batch_size] += step_reward * active_mask
                steps_count[:batch_size] += active_mask
                done_flags_batch |= dones[:batch_size]
                done_flags[:batch_size] = done_flags_batch
                if step >= min_steps and done_flags_batch.all():
                    break

            # finalize & é¢å¤–å¥–æƒ©
            if self.use_scg_exact_reward and self._scg_reward_calc is not None:
                # SCG ç²¾ç¡®æ¨¡å¼ï¼šæ—  finalize bonus
                bonus_vec = torch.zeros(batch_size, device=self.device)
                comp_totals = self._scg_reward_calc.get_components()
            elif self._step_reward_calc is not None:
                bonus = self._step_reward_calc.finalize()[:batch_size]
                total_rewards[:batch_size] += bonus
                bonus_vec = bonus
                comp_totals = self._step_reward_calc.get_component_totals()
            else:
                bonus_vec = torch.zeros(batch_size, device=self.device)
                comp_totals = {k: torch.zeros(batch_size, device=self.device) for k in [
                    'position_rmse','settling_time','control_effort','smoothness_jerk',
                    'gain_stability','saturation','peak_error','high_freq']}

            # åˆå§‹åŒ–å¤æ‚åº¦å’Œå…ˆéªŒå¥–åŠ±ï¼ˆmetricsæ¨¡å¼ä¸‹é»˜è®¤ä¸º0ï¼‰
            complexity_rewards = torch.zeros(batch_size, device=self.device)
            prior_struct = torch.zeros(batch_size, device=self.device)
            prior_stab = torch.zeros(batch_size, device=self.device)

            # ğŸ” åˆ†ç¦»çœŸå®å¥–åŠ±å’Œè®­ç»ƒå¥–åŠ±
            # reward_true: çº¯ç¯å¢ƒå¥–åŠ±ï¼ˆä»… SCG ä»£ä»·ï¼Œä¸å«ä»»ä½• shapingï¼‰
            # reward_train: è®­ç»ƒä¿¡å·ï¼ˆåœ¨çœŸå®å¥–åŠ±åŸºç¡€ä¸Šå åŠ å¤æ‚åº¦ã€å…ˆéªŒã€é›¶åŠ¨ä½œæƒ©ç½šç­‰ï¼‰
            batch_rewards_true = total_rewards[:batch_size].clone()
            batch_rewards_train = total_rewards[:batch_size].clone()
            # å¤æ‚åº¦å’Œå…ˆéªŒï¼šåªåŠ åˆ°è®­ç»ƒå¥–åŠ±ï¼Œä¸æ”¹çœŸå®å¥–åŠ±
            batch_rewards_train += complexity_rewards
            batch_rewards_train += prior_struct
            batch_rewards_train += prior_stab
            
            # é›¶åŠ¨ä½œæƒ©ç½šï¼šä»…åŠ åˆ°è®­ç»ƒå¥–åŠ±ä¸Š
            zero_penalty_applied = torch.zeros(batch_size, device=self.device)
            if self.strict_no_prior and self.zero_action_penalty > 0:
                zero_mask = (~ever_nonzero).float()
                zero_penalty_applied = self.zero_action_penalty * zero_mask
                batch_rewards_train -= zero_penalty_applied

            # å½’çº¦ï¼ˆå¯¹ä¸¤ä¸ªå¥–åŠ±åˆ†åˆ«å¤„ç†ï¼‰
            if self.reward_reduction == 'mean':
                denom = torch.clamp(steps_count[:batch_size], min=1.0)
                batch_scores_true = (batch_rewards_true / denom).cpu().numpy().tolist()
                batch_scores_train = (batch_rewards_train / denom).cpu().numpy().tolist()
            else:
                batch_scores_true = batch_rewards_true.cpu().numpy().tolist()
                batch_scores_train = batch_rewards_train.cpu().numpy().tolist()
            
            # rewardsåˆ—è¡¨å­˜å‚¨è®­ç»ƒå¥–åŠ±ï¼ˆç”¨äºNNè®­ç»ƒï¼‰
            rewards.extend(batch_scores_train)
            # rewards_trueåˆ—è¡¨å­˜å‚¨çœŸå®å¥–åŠ±ï¼ˆç”¨äºä¿å­˜ã€è¾“å‡ºã€å¯¹æ¯”ï¼‰
            rewards_true.extend(batch_scores_true)

            # é€ç¯å¢ƒç»„ä»¶å­—å…¸ï¼šåªå¯¼å‡º SCG å¯¹é½æŒ‡æ ‡
            for i in range(batch_size):
                d: Dict[str, float] = {}
                # ç›´æ¥ä» SCG ç»„ä»¶ä¸­è¯»å– state_cost / action_cost
                state_tensor = comp_totals.get('state_cost')
                action_tensor = comp_totals.get('action_cost')
                d['state_cost'] = float(state_tensor[i].item()) if state_tensor is not None else 0.0
                d['action_cost'] = float(action_tensor[i].item()) if action_tensor is not None else 0.0
                metrics_all.append(d)

        elapsed = time.time() - start_time
        display_count = num_programs_original if self.replicas_per_program > 1 else num_programs
        # æ³¨é‡Šæ‰è¯¦ç»†è¯„ä¼°æ—¥å¿—ï¼Œå‡å°‘è¾“å‡ºå™ªéŸ³
        # print(f"[BatchEvaluator] âœ… è¯„ä¼°å®Œæˆ: {display_count} ç¨‹åº (Ã—{self.replicas_per_program} replicas), {elapsed:.2f}ç§’ ({elapsed/display_count*1000:.1f}ms/ç¨‹åº)")

        # æ±‡æ€» replicasï¼šå¯¹æ¯ä¸ªåŸå§‹ç¨‹åºçš„ç»„ä»¶é€é”®å–å¹³å‡
        if self.replicas_per_program > 1:
            averaged_rewards: List[float] = []
            averaged_rewards_true: List[float] = []
            averaged_metrics: List[Dict[str, float]] = []
            for i in range(num_programs_original):
                start_idx = i * self.replicas_per_program
                end_idx = start_idx + self.replicas_per_program
                avg_reward = float(np.mean(rewards[start_idx:end_idx]))
                avg_reward_true = float(np.mean(rewards_true[start_idx:end_idx]))
                averaged_rewards.append(avg_reward)
                averaged_rewards_true.append(avg_reward_true)
                # å¹³å‡ç»„ä»¶
                keys = list(metrics_all[start_idx].keys())
                avg_dict = {k: float(np.mean([metrics_all[j][k] for j in range(start_idx, end_idx)])) for k in keys}
                averaged_metrics.append(avg_dict)
            if len(valid_indices) == total_requested:
                return averaged_rewards, averaged_rewards_true, averaged_metrics
            return self._merge_metrics_with_invalid(
                valid_indices,
                averaged_rewards,
                averaged_rewards_true,
                averaged_metrics,
                invalid_info,
                total_requested,
            )

        if len(valid_indices) == total_requested:
            return rewards, rewards_true, metrics_all
        return self._merge_metrics_with_invalid(
            valid_indices,
            rewards,
            rewards_true,
            metrics_all,
            invalid_info,
            total_requested,
        )

    def evaluate_single_with_metrics(self, program: List[Dict[str, Any]]) -> Tuple[float, float, Dict[str, float]]:
        """è¯„ä¼°å•ä¸ªç¨‹åºï¼ˆæ”¯æŒ replicasï¼‰ï¼Œè¿”å›è®­ç»ƒå¥–åŠ±ã€çœŸå®å¥–åŠ±ä¸ç»„ä»¶å­—å…¸ã€‚
        
        Returns:
            reward_train: è®­ç»ƒå¥–åŠ±ï¼ˆå«æƒ©ç½šï¼‰
            reward_true: çœŸå®å¥–åŠ±ï¼ˆä¸å«æƒ©ç½šï¼‰
            components: ç»„ä»¶å­—å…¸
        """
        rewards_train, rewards_true, metrics = self.evaluate_batch_with_metrics([program])
        return rewards_train[0], rewards_true[0], metrics[0]
    
    def _compute_action_from_program(self, program: List[Dict[str, Any]], 
                                      obs: np.ndarray, step: int) -> np.ndarray:
        """
        ä»ç¨‹åºè®¡ç®—æ§åˆ¶è¾“å…¥ï¼ˆç®€åŒ–ç‰ˆï¼‰
        
        Args:
            program: DSLç¨‹åºè§„åˆ™åˆ—è¡¨
            obs: è§‚æµ‹ [obs_dim]
            step: å½“å‰æ­¥æ•°
        
        Returns:
            action: [4] = [thrust, roll_rate, pitch_rate, yaw_rate]
        
        Note: ç°åœ¨æ‰€æœ‰ç¨‹åºç›´æ¥è¾“å‡º u_fz/u_tx/u_ty/u_tzï¼Œä¸å†ä½¿ç”¨ PID å°è£…
        """
        # å½“å‰è¿”å›æ‚¬åœæ§åˆ¶ï¼ˆå ä½ç¬¦ï¼‰
        # å®é™…åº”è¯¥ï¼š
        # 1. ä»obsæå–çŠ¶æ€ï¼ˆä½ç½®ã€é€Ÿåº¦ç­‰ï¼‰
        # 2. è®¡ç®—è½¨è¿¹ç›®æ ‡ç‚¹
        # 3. ä½¿ç”¨programè§„åˆ™è®¡ç®—PIDè¾“å‡º
        # 4. è½¬æ¢ä¸ºç”µæœºæŒ‡ä»¤
        
        return np.array([0.5, 0.0, 0.0, 0.0], dtype=np.float32)
    
    def evaluate_single(self, program: List[Dict[str, Any]]) -> float:
        """è¯„ä¼°å•ä¸ªç¨‹åºï¼šå¯å¹¶è¡Œå¤åˆ¶å¤šä¸ªå‰¯æœ¬å¹¶å–å¹³å‡ï¼Œæå‡GPUåˆ©ç”¨ç‡/ç¨³å®šæ€§"""
        # evaluate_batch ä¼šè‡ªåŠ¨å¤„ç† replicasï¼Œä¸éœ€è¦åœ¨è¿™é‡Œå¤åˆ¶
        rewards = self.evaluate_batch([program])
        return float(np.mean(rewards))
    
    def evaluate_batch_programs(self, programs: List[List[Dict[str, Any]]]) -> List[float]:
        """æ‰¹é‡è¯„ä¼°å¤šä¸ªç¨‹åºï¼ˆç”¨äº MCTS å¶èŠ‚ç‚¹å¹¶è¡ŒåŒ–ï¼‰
        
        è¿™ä¸ªæ–¹æ³•ä¸“é—¨ä¸º MCTS å¹¶è¡ŒåŒ–è®¾è®¡ï¼Œæ”¯æŒä¸€æ¬¡è¯„ä¼°å¤šä¸ªä¸åŒçš„ç¨‹åºã€‚
        æ¯ä¸ªç¨‹åºä»ç„¶ä½¿ç”¨å®Œæ•´çš„ isaac_num_envs ç¯å¢ƒè¯„ä¼°ï¼Œä½†é€šè¿‡è¿ç»­è°ƒç”¨
        å‡å°‘ Python/Isaac Gym çš„å¼€é”€ã€‚
        
        Args:
            programs: ç¨‹åºåˆ—è¡¨ï¼Œæ¯ä¸ªç¨‹åºæ˜¯ List[Dict[str, Any]]
            
        Returns:
            rewards_train: è®­ç»ƒå¥–åŠ±åˆ—è¡¨ï¼ˆå«æƒ©ç½šï¼‰
            
        Example:
            >>> programs = [program1, program2, program3]
            >>> rewards = evaluator.evaluate_batch_programs(programs)
            >>> # rewards = [-1.5, -2.3, -0.8]
        """
        if not programs:
            return []
        
        # è¿ç»­è¯„ä¼°æ¯ä¸ªç¨‹åºï¼ˆä»ä½¿ç”¨å®Œæ•´çš„ isaac_num_envsï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œä¸æ˜¯çœŸæ­£çš„"å¹¶è¡Œ"ï¼Œè€Œæ˜¯å‡å°‘è°ƒç”¨å¼€é”€
        rewards_train = []
        for program in programs:
            reward_train, _, _ = self.evaluate_single_with_metrics(program)
            rewards_train.append(reward_train)
        
        return rewards_train


# æµ‹è¯•ä»£ç 
if __name__ == '__main__':
    print("=" * 80)
    print("æµ‹è¯•Isaac Gymæ‰¹é‡è¯„ä¼°å™¨")
    print("=" * 80)
    
    if not ISAAC_GYM_AVAILABLE:
        print("âŒ Isaac Gymæœªå®‰è£…ï¼Œæ— æ³•æµ‹è¯•")
        exit(1)
    
    trajectory = {
        'type': 'figure8',
        'initial_xyz': [0, 0, 1.0],
        'params': {'A': 0.8, 'B': 0.5, 'period': 12}
    }
    
    evaluator = BatchEvaluator(
        trajectory_config=trajectory,
        duration=5,
        isaac_num_envs=64,
        device='cuda:0'
    )
    
    # åˆ›å»ºæµ‹è¯•ç¨‹åº
    test_programs = [
        [{'name': 'rule1', 'condition': None, 'action': [], 'multiplier': [1, 1, 1]}]
    ] * 8
    
    print(f"\nè¯„ä¼° {len(test_programs)} ä¸ªç¨‹åº...")
    rewards = evaluator.evaluate_batch(test_programs)
    print(f"å¥–åŠ±: {[f'{r:.3f}' for r in rewards]}")
    print("\nâœ… æµ‹è¯•å®Œæˆ")
