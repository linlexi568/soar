"""A/B Benchmark for GNN v2 with different prior levels

è¿è¡Œæ–¹å¼ (ç¤ºä¾‹):

  /home/linlexi/æ¡Œé¢/soar/.venv/bin/python ab_benchmark.py \
    --iters 120 --mcts 300 --traj figure8 --isaac-num-envs 128 \
    --prior-levels 2 3

è„šæœ¬ä¼šé¡ºåºè¿è¡Œä¸åŒå…ˆéªŒçº§åˆ«çš„çŸ­è®­ç»ƒå¹¶è¾“å‡ºæ‘˜è¦:
- æœ€ä½³å¥–åŠ±
- æ”¶æ•›æ›²çº¿çš„å‰è‹¥å¹²ç‚¹ (æ¯10è½®)
- å‚æ•°é‡å¯¹æ¯”

æ³¨æ„: ç»Ÿä¸€ä½¿ç”¨GNN v2åˆ†å±‚æ¶æ„ï¼Œæ¯”è¾ƒä¸åŒå…ˆéªŒçº§åˆ«çš„æ•ˆæœã€‚
"""
from __future__ import annotations
import argparse, time, json, random, os, sys, pathlib
import numpy as np

# ç›®å½•å¤„ç†
ROOT = pathlib.Path(__file__).resolve().parent
PKG = ROOT / '01_soar'
if str(PKG) not in sys.path:
    sys.path.insert(0, str(PKG))

# ç›´æ¥å¯¼å…¥ï¼ŒPKGå·²åœ¨sys.path
import train_online
OnlineTrainer = train_online.OnlineTrainer
from argparse import Namespace


def run_short_training(prior_level: int, base_args, iters: int, mcts: int, seed: int):
    # æ„é€ æœ€å°å¿…è¦å‚æ•°å¯¹è±¡ï¼Œä¸è°ƒç”¨è®­ç»ƒè„šæœ¬çš„å‘½ä»¤è¡Œè§£æé¿å…å†²çª
    args = Namespace(
        total_iters=iters,
        mcts_simulations=mcts,
        update_freq=max(10, iters // 12),
        train_steps_per_update=5,
        batch_size=128,
        replay_capacity=20000,
        use_gnn=True,
        prior_level=prior_level,
        nn_hidden=256,
        learning_rate=1e-3,
        value_loss_weight=0.5,
        exploration_weight=1.4,
        puct_c=1.5,
        max_depth=20,
        real_sim_frac=0.8,
        traj=base_args.traj,
        duration=base_args.duration,
        isaac_num_envs=base_args.isaac_num_envs,
        eval_replicas_per_program=1,
        min_steps_frac=0.0,
        reward_reduction='sum',
        use_fast_path=bool(getattr(base_args, 'fast_path', False)),
        save_path=f"01_soar/results/ab_best_program_prior{prior_level}.json",
        checkpoint_freq=10**9,
        warm_start=None,
    )

    np.random.seed(seed)
    random.seed(seed)

    trainer = OnlineTrainer(args)

    rewards = []
    best = -1e9
    for i in range(args.total_iters):
        children, visit_counts = trainer.mcts_search(trainer._generate_random_program(), args.mcts_simulations)
        if not children:
            rewards.append(best)
            continue
        # choose best
        idx = int(np.argmax(visit_counts))
        prog = children[idx].program
        reward = trainer.evaluator.evaluate_single(prog)
        if reward > best:
            best = reward
        rewards.append(best)
    return {
        'prior_level': prior_level,
        'best_reward': best,
        'curve': rewards,
        'param_count': sum(p.numel() for p in trainer.nn_model.parameters())
    }


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument('--short-iters', type=int, default=120, help='æ¯ä¸ªçº§åˆ«çŸ­è®­ç»ƒè¿­ä»£æ•°')
    ap.add_argument('--short-mcts', type=int, default=300, help='æ¯è¿­ä»£MCTSæ¨¡æ‹Ÿæ•°')
    ap.add_argument('--traj', type=str, default='figure8')
    ap.add_argument('--duration', type=int, default=6)
    ap.add_argument('--isaac-num-envs', type=int, default=128)
    ap.add_argument('--seed', type=int, default=42)
    ap.add_argument('--fast-path', action='store_true', help='å¯ç”¨ç¨‹åºæ±‚å€¼å¿«é€Ÿè·¯å¾„ä»¥æå‡çœŸå®è¯„ä¼°é€Ÿåº¦')
    ap.add_argument('--prior-levels', type=int, nargs='+', default=[2, 3], help='æµ‹è¯•çš„å…ˆéªŒçº§åˆ«åˆ—è¡¨')
    args = ap.parse_args()

    print("==== A/B Benchmark å¼€å§‹ (GNN v2 + ä¸åŒå…ˆéªŒçº§åˆ«) ====")
    print(f"é…ç½®: iters={args.short_iters}, mcts={args.short_mcts}, traj={args.traj}, envs={args.isaac_num_envs}")
    print(f"å…ˆéªŒçº§åˆ«: {args.prior_levels}")

    results = {}
    times = {}
    t_start = time.time()
    
    for level in args.prior_levels:
        print(f"\n>>> æµ‹è¯•å…ˆéªŒçº§åˆ« {level} ...")
        t0 = time.time()
        results[level] = run_short_training(level, args, args.short_iters, args.short_mcts, args.seed)
        times[level] = time.time() - t0

    def summarize(r):
        curve = r['curve']
        points = [curve[i] for i in range(0, len(curve), max(1, len(curve)//10))]
        return points

    print("\n==== ç»“æœæ‘˜è¦ ====")
    for level in args.prior_levels:
        r = results[level]
        print(f"\nå…ˆéªŒçº§åˆ« {level}:")
        print(f"  æœ€ä½³å¥–åŠ±: {r['best_reward']:.4f} | å‚æ•°é‡: {r['param_count']:,}")
        print(f"  æ”¶æ•›ç‰‡æ®µ: {summarize(r)}")
        print(f"  è€—æ—¶: {times[level]:.1f}s")

    # æ¯”è¾ƒ
    if len(args.prior_levels) == 2:
        diff = results[args.prior_levels[1]]['best_reward'] - results[args.prior_levels[0]]['best_reward']
        print(f"\nÎ”(best_reward level{args.prior_levels[1]} - level{args.prior_levels[0]}) = {diff:.4f}")
        if diff > 0.0:
            print(f"âœ… çº§åˆ«{args.prior_levels[1]}åœ¨æ­¤çŸ­åŸºå‡†ä¸­è¡¨ç°æ›´å¥½")
        else:
            print(f"âš ï¸ çº§åˆ«{args.prior_levels[0]}åœ¨æ­¤çŸ­åŸºå‡†ä¸­è¡¨ç°æ›´å¥½æˆ–ç›¸å½“")

    # ä¿å­˜ JSON
    out = {
        'config': vars(args),
        'results': {str(k): v for k, v in results.items()},
        'times': times,
        'total_time_s': time.time() - t_start
    }
    with open('01_soar/results/ab_summary.json', 'w') as f:
        json.dump(out, f, indent=2)
    print("\nğŸ“„ å·²ä¿å­˜ç»“æœåˆ° 01_soar/results/ab_summary.json")

if __name__ == '__main__':
    main()
