# MCTS搜索停滞分析

## 当前配置

### 搜索参数
- **MCTS模拟次数**: 200次/轮
- **探索权重**: exploration_weight = 1.2
- **渐进式扩展**: pw_alpha=0.6, pw_c=1.5
- **最大深度**: max_depth = 20
- **转置表**: 已启用（缓存重复状态）

### UCT选择公式
```
UCT = mean_reward + exploration_weight * sqrt(ln(parent_visits) / child_visits)
     = mean_reward + 1.2 * sqrt(ln(N) / n)
```

## 问题诊断

### 1. 初始程序极差 → 树根锁定
- **根节点reward ≈ -7.37e5**（极低）
- MCTS从这个差根开始，所有变异的子节点也很可能很差
- 即使偶尔生成好程序，也被埋没在大量差节点中

### 2. 表达式生成偏差
**终端概率=10%** 看似很低，但实际上：
- depth=0: 10%终端
- depth=1: 每个子树又有10%终端
- 两层后都是终端的概率: 10%×10% = 1%
- **但！** 如果depth=0就10%终端，直接返回单变量/常数

**问题：** 没有强制包含**位置误差变量**：
- `u_tx`的白名单有6个变量：`pos_err_y, vel_y, err_i_y, err_p_roll, err_d_roll, ang_vel_x`
- 随机选择时，`pos_err_y`只有**1/6 ≈ 17%**概率被选中
- 随机二元组合时，两边都不包含`pos_err_y`的概率很高

### 3. 变异操作不够激进
当前变异类型：
- `mutate_action`: 重新生成整个action（但仍是随机生成）
- `tweak_multiplier`: 微调常数（±8%）
- `micro_tweak`: 更小步长
- `add_rule/remove_rule`: 单规则模式已禁用

**问题：** 没有**结构化变异**，如：
- 强制插入`pos_err`项
- 强制生成`+/-`组合（PD结构）
- 禁止多重乘法嵌套

### 4. 探索-利用失衡
- **exploration_weight=1.2** 较低
- 当root极差时，所有子节点reward都很负
- UCT公式：`-7e5 + 1.2*sqrt(...) ≈ -7e5`
- **探索项完全被淹没**，MCTS退化为贪婪搜索

### 5. 奖励尺度问题
- 好程序: reward ≈ -100 ~ -1000
- 差程序: reward ≈ -700,000
- **动态范围 ≈ 1000倍**
- UCT的探索项(≈几十)相对于奖励差异太小

## 为什么搜不到有用程序？

### 典型搜索路径

**迭代1**: 
- 根节点：随机程序A（reward=-737k）
- MCTS 200次模拟：
  - 生成200个变异 → 大部分也是-700k级别
  - 偶尔1-2个稍好（-600k）→ 被选中
  - 但仍然很差，无法跟踪轨迹

**迭代2**:
- 根节点：上次最好的程序B（reward=-600k）
- MCTS 200次模拟：
  - 继续变异 → 大部分-600k
  - 偶尔更好（-500k）→ 被选中

**问题**：陷入"缓慢爬坡"
- 每次迭代只改善几万
- 从-700k爬到-100需要数百次迭代
- 而且可能困在局部最优（如当前的常数+乘积结构）

### 为什么PD结构很难被发现？

理想PD控制器：
```python
u_tx = kp * pos_err_y + kd * vel_y
```

随机生成概率：
1. 选择`+`算子：33%
2. 左子树选`*`：22%
3. 左子树的左孩子是常数：30%
4. 左子树的右孩子选中`pos_err_y`：1/6
5. 右子树选`*`：22%
6. 右子树的左孩子是常数：30%
7. 右子树的右孩子选中`vel_y`：1/6

**总概率** ≈ 0.33 × (0.22×0.3×0.17) × (0.22×0.3×0.17) ≈ **0.00005 = 0.005%**

在200次模拟中，生成PD结构的期望次数 ≈ 0.01次！

## 解决方案

### 状态空间缩减（优先级最高）
- **重新定义可行算子集**：仅保留对飞行控制最关键的`+, -, *`与有限常数表（如\[-5, -1, -0.2, 0.2, 1, 5\]），禁用`/`、`pow`等造成爆炸深度的算子，可直接把状态空间从~1e11压到1e7量级。
- **模板化宏动作**：为`pos_err`, `vel`, `attitude`组合设计3-5种“宏节点”（PD、PID、前馈补偿等），MCTS节点扩展时优先使用宏模板，再在模板内部微调系数；相当于把原子符号树提升为宏结构树，大幅降低宽度。
- **强制包含关键状态变量**：例如`u_tx`节点必须含`pos_err_y`，`u_ty`必须含`pos_err_x`；对积分/微分项设置最多一次出现限制，避免指数级组合。
- **进阶渐进式扩展(PW)**：把`pw_alpha`从0.6降到0.3，同时给每个操作符设置单独的访问阈值，当访问次数未到阈值时禁开新子节点，仅在高价值节点处逐步放宽，保证有效分支数始终在可控范围（~1e4）。
- **哈希等价裁剪**：对交换律（`a+b`与`b+a`）和多重乘法排序后哈希，命中后直接共享子节点；实践上可再砍掉1-2个数量级的冗余状态。
- **分层/多阶段搜索**：先在低维子问题（1D高度/速度跟踪）上搜索，得到的优质结构作为上层MCTS的初始节点或先验分布，避免整套动作一次性暴露全部自由度。

### 短期（立即见效）
1. **PD模板引导**：50%概率直接生成PD结构
2. **强制变量约束**：u_tx必须包含pos_err_y，u_ty必须包含pos_err_x
3. **限制乘法深度**：禁止连续3个以上乘法

### 中期（改进搜索）
1. **奖励归一化**：reward = (raw_reward + 1e6) / 1e6，映射到[-1, 10]区间
2. **提高探索权重**：exploration_weight = 5.0 或更高
3. **重启机制**：每100轮若无改善，重新随机初始化

### 长期（算法优化）
1. **遗传算法**：维护种群，交叉+变异
2. **梯度引导**：通过符号微分评估变量重要性
3. **课程学习**：先学简单轨迹（直线），再学复杂轨迹（figure8）
