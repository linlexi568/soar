#!/usr/bin/env python3
"""PID Parameter Tuning for Benchmark"""
import os
import sys
import argparse
import json
from pathlib import Path

ROOT = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(ROOT))

# Isaac Gym è·¯å¾„ - ä½¿ç”¨ä¸Šå±‚ç›®å½•çš„ soar
_ISAAC_GYM_PATH = Path(__file__).resolve().parents[3] / "soar" / "isaacgym" / "python"
if _ISAAC_GYM_PATH.exists():
    sys.path.insert(0, str(_ISAAC_GYM_PATH))
    _ISAAC_BINDINGS = _ISAAC_GYM_PATH / "isaacgym" / "_bindings" / "linux-x86_64"
    if _ISAAC_BINDINGS.exists():
        os.environ.setdefault("LD_LIBRARY_PATH", str(_ISAAC_BINDINGS) + os.pathsep + os.environ.get("LD_LIBRARY_PATH", ""))

try:
    from isaacgym import gymapi
except Exception:
    pass

import numpy as np

BENCHMARK_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(BENCHMARK_DIR))

from baselines.controllers import build_controller_eval, local_random_search


# PID åŸºå‡†å‚æ•°
BASE_PARAMS = {
    'kp_xy': 8.0,
    'kd_xy': 4.0,
    'ki_xy': 0.02,
    'kp_z': 14.0,
    'kd_z': 6.0,
    'ki_z': 0.05,
    'kp_att': 12.0,
    'kd_att': 2.0,
    'kp_yaw': 4.0,
    'kd_yaw': 0.8,
    'att_scale': 0.2,
}

# æœç´¢èŒƒå›´
BOUNDS = {
    'kp_xy': (4.0, 20.0),
    'kd_xy': (2.0, 8.0),
    'ki_xy': (0.0, 0.2),
    'kp_z': (10.0, 25.0),
    'kd_z': (4.0, 10.0),
    'ki_z': (0.0, 0.2),
    'kp_att': (8.0, 25.0),
    'kd_att': (1.0, 4.0),
    'kp_yaw': (0.0, 8.0),
    'kd_yaw': (0.0, 2.0),
    'att_scale': (0.05, 0.4),
}


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--task', type=str, required=True,
                        help='Trajectory type: hover/circle/figure8/square/helix')
    parser.add_argument('--trials', type=int, default=15,
                        help='Number of random search trials')
    parser.add_argument('--num-envs', type=int, default=1024,
                        help='Number of parallel environments')
    parser.add_argument('--duration', type=float, default=5.0,
                        help='Evaluation duration in seconds')
    parser.add_argument('--seed', type=int, default=0,
                        help='Random seed')
    args = parser.parse_args()

    np.random.seed(args.seed)

    # åˆ›å»ºç»“æœç›®å½•
    results_dir = BENCHMARK_DIR / "results" / "pid"
    results_dir.mkdir(parents=True, exist_ok=True)
    output_path = results_dir / f"pid_{args.task}.json"

    print(f"ğŸ¯ Tuning PID for {args.task} task")
    print(f"   Trials: {args.trials}")
    print(f"   Num envs: {args.num_envs}")

    # æ„å»ºè¯„ä¼°å‡½æ•°
    eval_fn = build_controller_eval('pid', pid_mode='cascade', num_envs=args.num_envs)

    # éšæœºæœç´¢
    best_params, metrics = local_random_search(
        BASE_PARAMS,
        BOUNDS,
        args.trials,
        eval_fn,
        args.task,
        args.duration,
        episodes_per_eval=1,
    )

    # ä¿å­˜ç»“æœ
    result = {
        'task': args.task,
        'duration_sec': args.duration,
        'controller': 'pid',
        'seed': args.seed,
        'trials': args.trials,
        'episodes_per_eval': 1,
        'best_params': best_params,
        'metrics': metrics,
    }

    with open(output_path, 'w') as f:
        json.dump(result, f, indent=2)

    print("\n" + "=" * 70)
    print("PID Tuning Complete")
    print(f" Task: {args.task}, Duration: {args.duration}s")
    print(f" Best mean reward: {metrics['mean_true_reward']:.2f}")
    print(f" Position RMSE: {metrics['rmse_pos']:.4f} m")
    print(" Best params:")
    for k, v in best_params.items():
        print(f"   {k}: {v:.4f}")
    print(f"\nâœ… Results saved to {output_path}")
    print("=" * 70)


if __name__ == '__main__':
    main()
