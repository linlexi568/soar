#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®é›†åŠ è½½å™¨ - ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤º
===================================

å¦‚æœè¿˜æ²¡æœ‰ä¸‹è½½çœŸå®æ•°æ®é›†,æ­¤è„šæœ¬ä¼šåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•ã€‚
"""

import numpy as np
import pandas as pd
from pathlib import Path
import json
import sys


def create_mock_dataset(output_dir='./mock_dataset'):
    """åˆ›å»ºæ¨¡æ‹Ÿçš„Agile Autonomyæ ¼å¼æ•°æ®é›†ç”¨äºæµ‹è¯•ã€‚"""
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print("ğŸ”§ åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†...")
    
    # åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•ç›®å½•
    train_dir = output_path / 'train'
    test_dir = output_path / 'test'
    train_dir.mkdir(exist_ok=True)
    test_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆå‡ ä¸ªæ¨¡æ‹Ÿè½¨è¿¹
    for split, split_dir in [('train', train_dir), ('test', test_dir)]:
        num_rollouts = 5 if split == 'train' else 2
        
        for i in range(num_rollouts):
            rollout_dir = split_dir / f'rollout_mock_{i:03d}'
            rollout_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆä¸€æ¡åœ†å½¢é£è¡Œè½¨è¿¹
            duration = 4.0  # ç§’
            dt = 0.02  # 50Hz
            t = np.arange(0, duration, dt)
            
            # åœ†å½¢è½¨è¿¹å‚æ•°
            radius = 2.0 + i * 0.5
            omega = 2 * np.pi / duration
            height = 1.5
            
            # ä½ç½®
            px = radius * np.cos(omega * t)
            py = radius * np.sin(omega * t)
            pz = height + 0.2 * np.sin(2 * omega * t)  # ä¸Šä¸‹æ³¢åŠ¨
            
            # é€Ÿåº¦ (è§£æå¯¼æ•°)
            vx = -radius * omega * np.sin(omega * t)
            vy = radius * omega * np.cos(omega * t)
            vz = 0.4 * omega * np.cos(2 * omega * t)
            
            # å§¿æ€ (ç®€åŒ–ä¸ºå¹³é£,åªæœ‰yawå˜åŒ–)
            yaw = omega * t
            qw = np.cos(yaw / 2)
            qx = np.zeros_like(t)
            qy = np.zeros_like(t)
            qz = np.sin(yaw / 2)
            
            # è§’é€Ÿåº¦
            wx = np.zeros_like(t)
            wy = np.zeros_like(t)
            wz = omega * np.ones_like(t)
            
            # åˆ›å»ºçŠ¶æ€DataFrame
            states = pd.DataFrame({
                't': t,
                'px': px, 'py': py, 'pz': pz,
                'qw': qw, 'qx': qx, 'qy': qy, 'qz': qz,
                'vx': vx, 'vy': vy, 'vz': vz,
                'wx': wx, 'wy': wy, 'wz': wz
            })
            
            # ä¿å­˜çŠ¶æ€
            states.to_csv(rollout_dir / 'states.csv', index=False)
            
            # å‚è€ƒè½¨è¿¹ (ç¨å¾®è¶…å‰çš„ä½ç½®)
            ref_df = pd.DataFrame({
                't': t,
                'ref_px': np.roll(px, -5),
                'ref_py': np.roll(py, -5),
                'ref_pz': np.roll(pz, -5)
            })
            ref_df.to_csv(rollout_dir / 'reference.csv', index=False)
            
            print(f"  âœ… åˆ›å»º {split}/rollout_mock_{i:03d} ({len(t)} æ­¥)")
    
    print(f"\nâœ… æ¨¡æ‹Ÿæ•°æ®é›†åˆ›å»ºå®Œæˆ: {output_path}")
    return str(output_path)


def test_dataset_loader(dataset_root):
    """æµ‹è¯•æ•°æ®é›†åŠ è½½å™¨ã€‚"""
    
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•æ•°æ®é›†åŠ è½½å™¨")
    print("=" * 60)
    
    # å¯¼å…¥åŠ è½½å™¨ - æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
    project_root = Path(__file__).parent.parent
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    from utilities.dataset_loader import (
        AgileAutonomyDataset, 
        TrajectoryAdapter,
        load_benchmark_dataset
    )
    
    # æµ‹è¯•1: åŸºç¡€åŠ è½½
    print("\n[æµ‹è¯• 1] åŸºç¡€æ•°æ®é›†åŠ è½½")
    dataset = AgileAutonomyDataset(dataset_root)
    print(f"  å‘ç° {len(dataset.rollouts)} ä¸ªè½¨è¿¹")
    
    # æµ‹è¯•2: åŠ è½½å•ä¸ªrollout
    print("\n[æµ‹è¯• 2] åŠ è½½å•ä¸ªè½¨è¿¹")
    data = dataset.load_rollout(0)
    print(f"  çŠ¶æ€å½¢çŠ¶: {data['states'].shape}")
    print(f"  æ—¶é•¿: {data['timestamps'][-1]:.2f} ç§’")
    if 'references' in data:
        print(f"  å‚è€ƒå½¢çŠ¶: {data['references'].shape}")
    
    # æµ‹è¯•3: åˆ†æ®µ
    print("\n[æµ‹è¯• 3] è½¨è¿¹åˆ†æ®µ")
    segments = dataset.get_trajectory_segments(0, segment_length=2.0, overlap=0.5)
    print(f"  ç”Ÿæˆ {len(segments)} ä¸ªæ®µ")
    print(f"  ç¬¬ä¸€æ®µå½¢çŠ¶: {segments[0]['states'].shape}")
    
    # æµ‹è¯•4: æ ¼å¼è½¬æ¢
    print("\n[æµ‹è¯• 4] æ ¼å¼è½¬æ¢")
    adapter = TrajectoryAdapter()
    ref_pos, ref_vel, ref_yaw = adapter.to_reference_trajectory(
        segments[0]['states'],
        segments[0]['timestamps']
    )
    print(f"  å‚è€ƒä½ç½®: {ref_pos.shape}")
    print(f"  å‚è€ƒé€Ÿåº¦: {ref_vel.shape}")
    print(f"  å‚è€ƒåèˆª: {ref_yaw.shape}")
    
    # æµ‹è¯•5: ä»»åŠ¡ç”Ÿæˆ
    print("\n[æµ‹è¯• 5] ä»»åŠ¡ç”Ÿæˆ")
    task = adapter.create_tracking_task(segments[0])
    print(f"  ä»»åŠ¡ç±»å‹: {task['type']}")
    print(f"  æ—¶é•¿: {task['duration']:.2f} ç§’")
    print(f"  å¹³å‡é€Ÿåº¦: {task['metadata']['avg_speed']:.2f} m/s")
    print(f"  æœ€å¤§é€Ÿåº¦: {task['metadata']['max_speed']:.2f} m/s")
    
    # æµ‹è¯•6: ä¾¿æ·æ¥å£
    print("\n[æµ‹è¯• 6] ä¾¿æ·åŠ è½½æ¥å£")
    tasks = load_benchmark_dataset(
        dataset_name='agile_autonomy',
        data_root=dataset_root,
        num_segments=10,
        segment_length=2.0
    )
    print(f"  ç”Ÿæˆ {len(tasks)} ä¸ªè®­ç»ƒä»»åŠ¡")
    
    # ä¿å­˜ç¤ºä¾‹ä»»åŠ¡
    output_file = Path('test_tasks_output.json')
    with open(output_file, 'w') as f:
        json.dump(tasks[:3], f, indent=2)  # åªä¿å­˜å‰3ä¸ª
    print(f"  ç¤ºä¾‹ä»»åŠ¡å·²ä¿å­˜åˆ°: {output_file}")
    
    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯
    print("\n[ç¤ºä¾‹ä»»åŠ¡]")
    print(json.dumps(tasks[0], indent=2))
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    print("=" * 60)


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='æµ‹è¯•æ•°æ®é›†åŠ è½½å™¨')
    parser.add_argument('--dataset_root', default=None,
                       help='æ•°æ®é›†æ ¹ç›®å½• (å¦‚æœä¸ºç©º,å°†åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®)')
    parser.add_argument('--create_mock', action='store_true',
                       help='å¼ºåˆ¶åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†')
    
    args = parser.parse_args()
    
    if args.create_mock or args.dataset_root is None:
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        mock_dir = './mock_agile_dataset'
        dataset_root = create_mock_dataset(mock_dir)
    else:
        dataset_root = args.dataset_root
        
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not Path(dataset_root).exists():
            print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_root}")
            print(f"\næç¤º: ä½¿ç”¨ --create_mock åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•")
            return 1
    
    # è¿è¡Œæµ‹è¯•
    try:
        test_dataset_loader(dataset_root)
        return 0
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())
