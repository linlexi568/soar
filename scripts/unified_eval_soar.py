#!/usr/bin/env python3
"""
ç»Ÿä¸€è¯„ä¼°è„šæœ¬ï¼šç”¨å®Œå…¨ç›¸åŒçš„é…ç½®é‡æ–°è¯„ä¼° Soar å’Œä¼ ç»Ÿæ§åˆ¶å™¨
ç¡®ä¿å¥–åŠ±è®¡ç®—æ–¹å¼ä¸€è‡´
"""
import sys
import json
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT / '01_soar'))
sys.path.insert(0, str(ROOT))

print("=" * 70)
print("ğŸ”¬ ç»Ÿä¸€è¯„ä¼°ï¼šSoar vs ä¼ ç»Ÿæ§åˆ¶å™¨")
print("=" * 70)

# ç»Ÿä¸€é…ç½®
CONFIG = {
    'task': 'square',
    'duration': 5.0,
    'isaac_num_envs': 1024,  # è¶³å¤Ÿç»Ÿè®¡
    'replicas_per_program': 1,  # ä¸éœ€è¦é¢å¤–replicas
    'reward_reduction': 'sum',  # ç´¯åŠ ï¼Œä¸å–å¹³å‡
    'reward_profile': 'safe_control_tracking',
    'device': 'cuda:0',
}

print(f"\nã€ç»Ÿä¸€è¯„ä¼°é…ç½®ã€‘")
for k, v in CONFIG.items():
    print(f"  {k}: {v}")

# å¯¼å…¥è¯„ä¼°å™¨
try:
    from utils.batch_evaluation import BatchEvaluator
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = BatchEvaluator(
        trajectory_config={'type': CONFIG['task']},
        duration=int(CONFIG['duration']),
        isaac_num_envs=CONFIG['isaac_num_envs'],
        device=CONFIG['device'],
        replicas_per_program=CONFIG['replicas_per_program'],
        reward_reduction=CONFIG['reward_reduction'],
        reward_profile=CONFIG['reward_profile'],
        use_scg_exact_reward=True,
        strict_no_prior=True,
        zero_action_penalty=0.0,  # ä¸æƒ©ç½šé›¶åŠ¨ä½œ
        use_fast_path=True,
        use_gpu_expression_executor=True,
    )
    
    print("\nâœ“ è¯„ä¼°å™¨åˆå§‹åŒ–æˆåŠŸ")
    print(f"  reward_reduction: {evaluator.reward_reduction}")
    print(f"  isaac_num_envs: {evaluator.isaac_num_envs}")
    
    # 1. è¯„ä¼°Soar
    print("\n" + "=" * 70)
    print("ã€1. è¯„ä¼° Soar best ç¨‹åºã€‘")
    print("=" * 70)
    
    soar_file = ROOT / 'results/soar_train/square_safe_control_tracking_best.json'
    with open(soar_file) as f:
        soar_data = json.load(f)
    
    program = soar_data['rules']
    print(f"\n  ç¨‹åºè§„åˆ™æ•°: {len(program)}")
    print(f"  è®­ç»ƒæ—¶å¥–åŠ±: {soar_data['meta']['reward']:.2f}")
    
    print("\n  å¼€å§‹è¯„ä¼°...")
    reward_train, reward_true, components = evaluator.evaluate_single_with_metrics(program)
    
    print(f"\n  é‡æ–°è¯„ä¼°ç»“æœ:")
    print(f"    reward_train: {reward_train:.2f}")
    print(f"    reward_true: {reward_true:.2f}")
    print(f"    state_cost: {components.get('state_cost', 0):.2f}")
    print(f"    action_cost: {components.get('action_cost', 0):.6f}")
    
    print(f"\n  å¯¹æ¯”:")
    print(f"    è®­ç»ƒæ—¶: {soar_data['meta']['reward']:.2f}")
    print(f"    é‡æ–°è¯„ä¼°: {reward_true:.2f}")
    print(f"    å·®å¼‚: {abs(reward_true - soar_data['meta']['reward']):.2f}")
    
except Exception as e:
    print(f"\nâŒ è¯„ä¼°å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "=" * 70)
print("è¯´æ˜ï¼š")
print("  å¦‚æœé‡æ–°è¯„ä¼°ç»“æœæ¥è¿‘PID (-520)ï¼Œè¯´æ˜è®­ç»ƒæ—¶çš„å¥–åŠ±è®¡ç®—æœ‰bug")
print("  å¦‚æœé‡æ–°è¯„ä¼°ç»“æœä»ç„¶å¾ˆå° (-73)ï¼Œè¯´æ˜ç¨‹åºæœ¬èº«æ€§èƒ½ä¸ä½³")
print("=" * 70)
